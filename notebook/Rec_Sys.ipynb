{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d29f8d-13fb-4094-ac45-cf49ef5e22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from imp import reload\n",
    "from dataaccessframeworks.read_data import get_movielens, user_filter, training_testing, get_yelp, get_douban, training_testing_XY\n",
    "from dataaccessframeworks.data_preprocessing import get_one_hot_feature, generate_eval_array\n",
    "from models.collaborative_filtering import get_user_item_matrix, predict\n",
    "from models.evaluation import recall_k\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import ndcg_score\n",
    "import configparser\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from util.mywandb import WandbLog\n",
    "import util.utility as util\n",
    "import itertools\n",
    "from random import sample\n",
    "from IPython.display import clear_output\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.join(os.path.dirname(os.getcwd()), 'config.ini'))\n",
    "LIBFM_PATH = '/home/baron/libfm/bin/'\n",
    "os.environ['LIBFM_PATH'] = LIBFM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1bd60d8-f070-4b2b-b73a-34d25167da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data input:\n",
    "[[user, item, rank], .....]\n",
    "'''\n",
    "def get_uij(data, users, items, sample_rate=1000):\n",
    "    for ii, user in enumerate(users):\n",
    "        items_data = data[data[:, 0]==user]\n",
    "        item_compare = list()\n",
    "        item_neg = list()\n",
    "        neg_count = 0\n",
    "        items_iter =[i for i in itertools.combinations(items, 2)]\n",
    "        items_iter = sample(items_iter, sample_rate)\n",
    "        for i, j in items_iter:\n",
    "            # if i exist items, but j not exsit items, i>j\n",
    "            if i in items_data[:, 1] and j not in items_data[:, 1]:\n",
    "                item_compare.append([user, i, j, 1])\n",
    "            # if j exist items, but i not exsit items, j>i\n",
    "            elif i not in items_data[:, 1] and j in items_data[:, 1]:\n",
    "                item_compare.append([user, j, i, 1])\n",
    "            # if i exist items, and also j exsit items, compare i and j\n",
    "            elif i in items_data[:, 1] and j in items_data[:, 1]:\n",
    "                ri = items_data[(items_data[:, 0]==user) & (items_data[:, 1]==i)][0, 2]\n",
    "                rj = items_data[(items_data[:, 0]==user) & (items_data[:, 1]==j)][0, 2]\n",
    "                if ri > rj:\n",
    "                    item_compare.append([user, i, j, 1])\n",
    "                elif ri < rj:\n",
    "                    item_compare.append([user, j, i, 1])\n",
    "                else:\n",
    "                    if neg_count < len(item_compare)//2:\n",
    "                        item_neg.append([user, j, i, 0])\n",
    "                        item_neg.append([user, i, j, 0])\n",
    "                        neg_count+=1\n",
    "            else:\n",
    "                if neg_count < len(item_compare)//2:\n",
    "                    item_neg.append([user, j, i, 0])\n",
    "                    item_neg.append([user, i, j, 0])\n",
    "                    neg_count+=1\n",
    "        if ii==0:\n",
    "            uij = np.array(item_compare)\n",
    "            uij_neg = np.array(item_neg)\n",
    "        else:\n",
    "            if len(item_compare)!= 0:\n",
    "                uij = np.vstack((uij, np.array(item_compare)))\n",
    "            if len(item_neg)!= 0 and uij_neg.shape[0]!=0:\n",
    "                uij_neg = np.vstack((uij_neg, np.array(item_neg)))\n",
    "        \n",
    "        if ii%300==0:\n",
    "            print(\"[{}/{}] uij_pos: {}, uij_neg: {}\".format(ii, len(users), uij.shape, uij_neg.shape))\n",
    "    \n",
    "    return uij, uij_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4011be-f3e9-46b9-a80e-ae726fc3e542",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc7fb39-e567-42b6-b8a5-b5fdb61739b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataaccessframeworks.data_preprocessing import get_feature_map, generate_with_feature, get_norating_data\n",
    "\n",
    "def get_uij_one_hot_feature(data, user_item_col, uij_data, y_col=3, time_col=3, batch_size=10000):\n",
    "    # 取得user及items feature map \n",
    "    users_dict, items_dict, features = get_feature_map(data, user_item_col)\n",
    "\n",
    "    # 將user item 數值轉為integer\n",
    "    # user_items = np.array([list(map(int, data))for data in data[user_item_col]])\n",
    "    # 使用者評分次數小於三筆則剔除\n",
    "    filter_data = user_filter(uij_data, 0)\n",
    "    print(filter_data.shape)\n",
    "    print(filter_data[:5])\n",
    "    # user label encoder\n",
    "    le = LabelEncoder()\n",
    "    filter_data[:, 0] = le.fit_transform(filter_data[:, 0])\n",
    "    # item label encoder\n",
    "    ile = LabelEncoder()\n",
    "    filter_data[:, 1] = ile.fit_transform(filter_data[:, 1])\n",
    "    filter_data[:, 2] = ile.fit_transform(filter_data[:, 2])\n",
    "    \n",
    "    # 做特徵的onehot encoding \n",
    "    one_hot_encoder_data, y, concat_data = get_uij_onehot_encoding(filter_data, users_dict, items_dict, features, le, ile, batch_size, y_col)\n",
    "\n",
    "    return one_hot_encoder_data, y, concat_data\n",
    "\n",
    "# 取得user及items的one hot encoding map\n",
    "def get_uij_onehot_encoding(data, users_dict, items_dict, features, le, ile, batch_size, y_col):\n",
    "    #users_onehot = get_users_onehot(data)\n",
    "    sparse_, dense = get_uij_feature_onehot(data, users_dict, items_dict, features, le, ile, batch_size)\n",
    "    \n",
    "    # 取得y\n",
    "    y = data[:,y_col].reshape(-1,1)\n",
    "    \n",
    "    # return np.concatenate((sparse_, dense), axis=1), y, concat_data\n",
    "    return sparse.hstack((sparse_, dense), format='csr'), y, data\n",
    "\n",
    "# 取得feature one hot\n",
    "def get_uij_feature_onehot(data, users_feature, items_feature, features_map, le, ile, batch_size):\n",
    "    # 取得user & item個數\n",
    "    user_number = np.max(data[:,0]) + 1\n",
    "    item_number = np.max(data[:,1]) + 1\n",
    "    i_feature = items_feature[1].keys()\n",
    "    # one hot encoding\n",
    "    for b in range(0, data.shape[0], batch_size):\n",
    "        user_one_hot = np.eye(user_number)[data[b:b+batch_size,0]]\n",
    "        itemi_one_hot = np.eye(item_number)[data[b:b+batch_size,1]]\n",
    "        itemj_one_hot = np.eye(item_number)[data[b:b+batch_size,2]]\n",
    "        sparse_ = np.concatenate((user_one_hot, itemi_one_hot, itemj_one_hot), axis=1)\n",
    "        dense = np.empty((user_one_hot.shape[0], 1), int)\n",
    "\n",
    "        # create items feature \n",
    "        i_feature = items_feature[1].keys()\n",
    "        for fe in i_feature:\n",
    "            # sparse\n",
    "            if fe.split(\"_\")[1] != 'year':\n",
    "                f_map = features_map[fe]\n",
    "                feature_lengh = f_map[list(f_map.keys())[0]].shape[1]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), feature_lengh*2))\n",
    "                for i, item_ij in enumerate(data[b:b+batch_size, 1:3]):\n",
    "                    item_i, item_j = item_ij\n",
    "                    item_i = ile.inverse_transform(np.array([item_i])).item()\n",
    "                    item_j = ile.inverse_transform(np.array([item_j])).item()\n",
    "                    if item_i not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, :feature_lengh] = features_map[fe][item_i].toarray()\n",
    "                    if item_j not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, feature_lengh:] = features_map[fe][item_j].toarray()\n",
    "                # sparse_ = np.concatenate((sparse_, tmp), axis=1)\n",
    "                sparse_ = np.hstack((sparse_, tmp))\n",
    "            # dense\n",
    "            else:\n",
    "                # i = 0\n",
    "                f_map = features_map[fe]\n",
    "                feature_lengh = f_map[list(f_map.keys())[0]].shape[1]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), feature_lengh*2))\n",
    "                for i, item_ij in enumerate(data[b:b+batch_size, 1:3]):\n",
    "                    item_i, item_j = item_ij\n",
    "                    item_i = ile.inverse_transform(np.array([item_i])).item()\n",
    "                    item_j = ile.inverse_transform(np.array([item_j])).item()\n",
    "                    if item_i not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, :feature_lengh] = features_map[fe][item_i].toarray()\n",
    "                    if item_j not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, feature_lengh:] = features_map[fe][item_j].toarray()\n",
    "                # dense = np.concatenate((dense, tmp), axis=1)\n",
    "                dense = np.hstack((dense, tmp))\n",
    "\n",
    "        # create user feature\n",
    "        u_feature = users_feature[1].keys()\n",
    "        for fe in u_feature:\n",
    "            # sparse\n",
    "            if fe.split(\"_\")[1] != 'age':\n",
    "                f_map = features_map[fe]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                for i, user in enumerate(data[b:b+batch_size, 0]):\n",
    "                    # i = 0\n",
    "                    user = le.inverse_transform(np.array([user])).item()\n",
    "                    if user not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # user_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        tmp[i] = features_map[fe][user].toarray()\n",
    "                # sparse_ = np.concatenate((sparse_, tmp), axis=1)\n",
    "                sparse_ = np.hstack((sparse_, tmp))\n",
    "                \n",
    "            # dense\n",
    "            else:\n",
    "                f_map = features_map[fe]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                for i, user in enumerate(data[b:b+batch_size, 0]):\n",
    "                    # i = 0\n",
    "                    user = le.inverse_transform(np.array([user])).item()\n",
    "                    if user not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # user_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        tmp[i] = features_map[fe][user].toarray()\n",
    "                # dense = np.concatenate((dense, tmp), axis=1)\n",
    "                dense = np.hstack((dense, tmp))\n",
    "        if b==0:\n",
    "            sparse_matrix = csr_matrix(sparse_)\n",
    "            dense_matrix = dense\n",
    "        else:\n",
    "            sparse_matrix = sparse.vstack((sparse_matrix, csr_matrix(sparse_)))\n",
    "            dense_matrix = np.vstack((dense_matrix, dense))\n",
    "        print(\"[{}/{}] sparse_matrix shape is {}\".format(b, data.shape[0], sparse_matrix.shape))\n",
    "    \n",
    "    return sparse_matrix, dense_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682edb3-cccb-4711-b0da-fa7754ae3070",
   "metadata": {},
   "source": [
    "### MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de72e1bc-5f21-45ac-aeb9-272d3b19aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_movie:[['196' '242' '3']\n",
      " ['186' '302' '3']\n",
      " ['22' '377' '1']]\n",
      "movie_genre:[['1' '3']\n",
      " ['1' '4']\n",
      " ['1' '5']]\n",
      "user_age:[['1' '3']\n",
      " ['2' '6']\n",
      " ['3' '3']]\n",
      "user_occupation:[['1' '1']\n",
      " ['2' '2']\n",
      " ['3' '3']]\n",
      "使用者評分大於三次的共有：(100000, 3)\n",
      "users:  943\n",
      "items:  1682\n",
      "(100000, 3)\n",
      "[0/194300] sparse_matrix shape is (100000, 2666)\n",
      "[100000/194300] sparse_matrix shape is (194300, 2666)\n",
      "(155440, 2676) (38860, 2676)\n",
      "(194300, 2676)\n"
     ]
    }
   ],
   "source": [
    "data = get_movielens()\n",
    "# str to int\n",
    "user_movie = np.array([list(map(int, data)) for data in data['user_movie']])\n",
    "# 濾除使用者評分小於三筆的資料\n",
    "filter_data = user_filter(user_movie, 0)\n",
    "print(f\"使用者評分大於三次的共有：{filter_data.shape}\")\n",
    "# 是否加上假資料\n",
    "fake=True\n",
    "if fake:\n",
    "    # 取得加上使用者未評分的sample假資料\n",
    "    filter_data = get_norating_data(filter_data)\n",
    "    \n",
    "# 取得電影個數及電影個數\n",
    "len_users, movies = np.unique(filter_data[:,0]), np.unique(filter_data[:,1])\n",
    "# 取得訓練資料及測試資料\n",
    "training_data,  testing_data = training_testing(filter_data)\n",
    "\n",
    "users_dict, items_dict, features = get_feature_map(data, 'user_movie')\n",
    "movielens_training_df = generate_with_feature(training_data, users_dict, items_dict, init_col=[\"user\", \"movie\", \"rating\"])\n",
    "movielens_testing_df = generate_with_feature(testing_data, users_dict, items_dict, init_col=[\"user\", \"movie\", \"rating\"])\n",
    "\n",
    "\n",
    "# normalize rating value\n",
    "# training_data[:, 2:3] = normalize(training_data[:, 2:3], axis=0)\n",
    "# testing_data[:, 2:3] = normalize(testing_data[:, 2:3], axis=0)\n",
    "# train_min = training_data[:, 2:3].min()\n",
    "# train_max = training_data[:, 2:3].max()\n",
    "# training_rating = (training_data[:, 2] - train_min)/(train_max-train_min)\n",
    "# test_min = testing_data[:, 2:3].min()\n",
    "# test_max = testing_data[:, 2:3].max()\n",
    "# testing_rating = (testing_data[:, 2:3] - test_min)/(test_max-test_min)\n",
    "print(\"users: \", len(len_users))\n",
    "print(\"items: \", len(movies))\n",
    "\n",
    "# generarte one hot encoding\n",
    "bpr = False\n",
    "if bpr:\n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(training_data, len_users, movies)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    train_uij = np.vstack((uij_pos, uij_neg))\n",
    "    test_uij_pos, test_uij_neg = get_uij(testing_data, len_users, movies)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "    one_hot_x, y, add_fake_data = get_uij_one_hot_feature(data,  'user_movie', train_uij, batch_size=100000)\n",
    "else:\n",
    "    one_hot_x, y, add_fake_data = get_one_hot_feature(data,  'user_movie', batch_size=100000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = training_testing_XY(one_hot_x, y, random_state=int(config['model']['random_state']))\n",
    "training_index, test_index, _, _ = training_testing_XY(add_fake_data, y, random_state=int(config['model']['random_state']))\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(one_hot_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140b967-0b12-4efb-8752-75b341b6018f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9291be6-6e04-47d6-af61-f92487ace79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_category:[['1', '334', '1'], ['1', '426', '1'], ['2', '211', '1']]\n",
      "business_city:[['1', '31', '1'], ['2', '35', '1'], ['3', '35', '1']]\n",
      "user_business:[['1', '8391', '5'], ['1', '8971', '5'], ['2', '186', '5']]\n",
      "user_compliment:[['2', '1', '1'], ['2', '2', '1'], ['2', '3', '1']]\n",
      "使用者評分大於三次的共有：(184835, 3)\n",
      "users:  7326\n",
      "items:  14127\n",
      "(184835, 3)\n",
      "[0/917435] sparse_matrix shape is (10000, 22025)\n",
      "[10000/917435] sparse_matrix shape is (20000, 22025)\n",
      "[20000/917435] sparse_matrix shape is (30000, 22025)\n",
      "[30000/917435] sparse_matrix shape is (40000, 22025)\n",
      "[40000/917435] sparse_matrix shape is (50000, 22025)\n",
      "[50000/917435] sparse_matrix shape is (60000, 22025)\n",
      "[60000/917435] sparse_matrix shape is (70000, 22025)\n",
      "[70000/917435] sparse_matrix shape is (80000, 22025)\n",
      "[80000/917435] sparse_matrix shape is (90000, 22025)\n",
      "[90000/917435] sparse_matrix shape is (100000, 22025)\n",
      "[100000/917435] sparse_matrix shape is (110000, 22025)\n",
      "[110000/917435] sparse_matrix shape is (120000, 22025)\n",
      "[120000/917435] sparse_matrix shape is (130000, 22025)\n",
      "[130000/917435] sparse_matrix shape is (140000, 22025)\n",
      "[140000/917435] sparse_matrix shape is (150000, 22025)\n",
      "[150000/917435] sparse_matrix shape is (160000, 22025)\n",
      "[160000/917435] sparse_matrix shape is (170000, 22025)\n",
      "[170000/917435] sparse_matrix shape is (180000, 22025)\n",
      "[180000/917435] sparse_matrix shape is (190000, 22025)\n",
      "[190000/917435] sparse_matrix shape is (200000, 22025)\n",
      "[200000/917435] sparse_matrix shape is (210000, 22025)\n",
      "[210000/917435] sparse_matrix shape is (220000, 22025)\n",
      "[220000/917435] sparse_matrix shape is (230000, 22025)\n",
      "[230000/917435] sparse_matrix shape is (240000, 22025)\n",
      "[240000/917435] sparse_matrix shape is (250000, 22025)\n",
      "[250000/917435] sparse_matrix shape is (260000, 22025)\n",
      "[260000/917435] sparse_matrix shape is (270000, 22025)\n",
      "[270000/917435] sparse_matrix shape is (280000, 22025)\n",
      "[280000/917435] sparse_matrix shape is (290000, 22025)\n",
      "[290000/917435] sparse_matrix shape is (300000, 22025)\n",
      "[300000/917435] sparse_matrix shape is (310000, 22025)\n",
      "[310000/917435] sparse_matrix shape is (320000, 22025)\n",
      "[320000/917435] sparse_matrix shape is (330000, 22025)\n",
      "[330000/917435] sparse_matrix shape is (340000, 22025)\n",
      "[340000/917435] sparse_matrix shape is (350000, 22025)\n",
      "[350000/917435] sparse_matrix shape is (360000, 22025)\n",
      "[360000/917435] sparse_matrix shape is (370000, 22025)\n",
      "[370000/917435] sparse_matrix shape is (380000, 22025)\n",
      "[380000/917435] sparse_matrix shape is (390000, 22025)\n",
      "[390000/917435] sparse_matrix shape is (400000, 22025)\n",
      "[400000/917435] sparse_matrix shape is (410000, 22025)\n",
      "[410000/917435] sparse_matrix shape is (420000, 22025)\n",
      "[420000/917435] sparse_matrix shape is (430000, 22025)\n",
      "[430000/917435] sparse_matrix shape is (440000, 22025)\n",
      "[440000/917435] sparse_matrix shape is (450000, 22025)\n",
      "[450000/917435] sparse_matrix shape is (460000, 22025)\n",
      "[460000/917435] sparse_matrix shape is (470000, 22025)\n",
      "[470000/917435] sparse_matrix shape is (480000, 22025)\n",
      "[480000/917435] sparse_matrix shape is (490000, 22025)\n",
      "[490000/917435] sparse_matrix shape is (500000, 22025)\n",
      "[500000/917435] sparse_matrix shape is (510000, 22025)\n",
      "[510000/917435] sparse_matrix shape is (520000, 22025)\n",
      "[520000/917435] sparse_matrix shape is (530000, 22025)\n",
      "[530000/917435] sparse_matrix shape is (540000, 22025)\n",
      "[540000/917435] sparse_matrix shape is (550000, 22025)\n",
      "[550000/917435] sparse_matrix shape is (560000, 22025)\n",
      "[560000/917435] sparse_matrix shape is (570000, 22025)\n",
      "[570000/917435] sparse_matrix shape is (580000, 22025)\n",
      "[580000/917435] sparse_matrix shape is (590000, 22025)\n",
      "[590000/917435] sparse_matrix shape is (600000, 22025)\n",
      "[600000/917435] sparse_matrix shape is (610000, 22025)\n",
      "[610000/917435] sparse_matrix shape is (620000, 22025)\n",
      "[620000/917435] sparse_matrix shape is (630000, 22025)\n",
      "[630000/917435] sparse_matrix shape is (640000, 22025)\n",
      "[640000/917435] sparse_matrix shape is (650000, 22025)\n",
      "[650000/917435] sparse_matrix shape is (660000, 22025)\n",
      "[660000/917435] sparse_matrix shape is (670000, 22025)\n",
      "[670000/917435] sparse_matrix shape is (680000, 22025)\n",
      "[680000/917435] sparse_matrix shape is (690000, 22025)\n",
      "[690000/917435] sparse_matrix shape is (700000, 22025)\n",
      "[700000/917435] sparse_matrix shape is (710000, 22025)\n",
      "[710000/917435] sparse_matrix shape is (720000, 22025)\n",
      "[720000/917435] sparse_matrix shape is (730000, 22025)\n",
      "[730000/917435] sparse_matrix shape is (740000, 22025)\n",
      "[740000/917435] sparse_matrix shape is (750000, 22025)\n",
      "[750000/917435] sparse_matrix shape is (760000, 22025)\n",
      "[760000/917435] sparse_matrix shape is (770000, 22025)\n",
      "[770000/917435] sparse_matrix shape is (780000, 22025)\n",
      "[780000/917435] sparse_matrix shape is (790000, 22025)\n",
      "[790000/917435] sparse_matrix shape is (800000, 22025)\n",
      "[800000/917435] sparse_matrix shape is (810000, 22025)\n",
      "[810000/917435] sparse_matrix shape is (820000, 22025)\n",
      "[820000/917435] sparse_matrix shape is (830000, 22025)\n",
      "[830000/917435] sparse_matrix shape is (840000, 22025)\n",
      "[840000/917435] sparse_matrix shape is (850000, 22025)\n",
      "[850000/917435] sparse_matrix shape is (860000, 22025)\n",
      "[860000/917435] sparse_matrix shape is (870000, 22025)\n",
      "[870000/917435] sparse_matrix shape is (880000, 22025)\n",
      "[880000/917435] sparse_matrix shape is (890000, 22025)\n",
      "[890000/917435] sparse_matrix shape is (900000, 22025)\n",
      "[900000/917435] sparse_matrix shape is (910000, 22025)\n",
      "[910000/917435] sparse_matrix shape is (917435, 22025)\n",
      "(733948, 22026) (183487, 22026)\n",
      "(917435, 22026)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = get_yelp()\n",
    "# str to int\n",
    "user_business = np.array([list(map(int, data)) for data in data['user_business']])\n",
    "# 濾除使用者評分小於三筆的資料\n",
    "filter_data = user_filter(user_business, 0)\n",
    "# user label encoder\n",
    "le = LabelEncoder()\n",
    "filter_data[:, 0] = le.fit_transform(filter_data[:, 0])\n",
    "filter_data[:, 0] += 1\n",
    "# item label encoder\n",
    "ile = LabelEncoder()\n",
    "filter_data[:, 1] = ile.fit_transform(filter_data[:, 1])\n",
    "filter_data[:, 1] += 1\n",
    "# if want to inverse label \n",
    "# le.inverse_transform(yelp_training_encoder)\n",
    "print(f\"使用者評分大於三次的共有：{filter_data.shape}\")\n",
    "# 是否加上假資料\n",
    "fake=True\n",
    "if fake:\n",
    "    # 取得加上使用者未評分的sample假資料\n",
    "    filter_data = get_norating_data(filter_data)\n",
    "\n",
    "# 取得business個數及users個數\n",
    "yelp_users, business = np.unique(filter_data[:,0]), np.unique(filter_data[:,1])\n",
    "# 取得訓練資料及測試資料\n",
    "yelp_training_data,  yelp_testing_data = training_testing(filter_data)\n",
    "users_dict, items_dict, features = get_feature_map(data, 'user_business')\n",
    "yelp_training_df = generate_with_feature(yelp_training_data, users_dict, items_dict, init_col=[\"user\", \"business\", \"rating\"])\n",
    "yelp_testing_df = generate_with_feature(yelp_testing_data, users_dict, items_dict, init_col=[\"user\", \"business\", \"rating\"])\n",
    "\n",
    "print(\"users: \", len(yelp_users))\n",
    "print(\"items: \", len(business))\n",
    "# generarte one hot encoding\n",
    "bpr = False\n",
    "if bpr:\n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(yelp_training_data, yelp_users, business)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    train_uij = np.vstack((uij_pos, uij_neg))\n",
    "    test_uij_pos, test_uij_neg = get_uij(yelp_testing_data, yelp_users, business)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "    one_hot_x, y, add_fake_data = get_uij_one_hot_feature(data,  'user_business', train_uij)\n",
    "else:\n",
    "    one_hot_x, y, add_fake_data = get_one_hot_feature(data,  'user_business')\n",
    "\n",
    "# generarte one hot encoding\n",
    "X_train_yelp, X_test_yelp, y_train_yelp, y_test_yelp = training_testing_XY(one_hot_x, y, random_state=int(config['model']['random_state']))\n",
    "training_index_yelp, test_index_yelp, _, _ = training_testing_XY(add_fake_data, y, random_state=int(config['model']['random_state']))\n",
    "print(X_train_yelp.shape, X_test_yelp.shape)\n",
    "print(one_hot_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ba6de-2893-4a33-b9c2-e5a77953b129",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01661c74-3b39-49c2-a121-7002680d2ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_author:[['12131', '3871'], ['20995', '10690'], ['9905', '3845']]\n",
      "book_publisher:[['12131', '108'], ['20995', '1470'], ['9905', '1696']]\n",
      "book_year:[['9905', '16'], ['21153', '15'], ['12823', '15']]\n",
      "user_book:[['10855', '938', '4'], ['10027', '3', '3'], ['741', '2426', '5']]\n",
      "user_group:[['3587', '232'], ['3587', '666'], ['3587', '226']]\n",
      "user_location:[['3587', '33'], ['3210', '179'], ['7993', '394']]\n",
      "使用者評分大於三次的共有：(788898, 3)\n",
      "users:  11266\n",
      "items:  22347\n",
      "(788898, 3)\n",
      "[0/1915498] sparse_matrix shape is (10000, 49626)\n",
      "[10000/1915498] sparse_matrix shape is (20000, 49626)\n",
      "[20000/1915498] sparse_matrix shape is (30000, 49626)\n",
      "[30000/1915498] sparse_matrix shape is (40000, 49626)\n",
      "[40000/1915498] sparse_matrix shape is (50000, 49626)\n",
      "[50000/1915498] sparse_matrix shape is (60000, 49626)\n",
      "[60000/1915498] sparse_matrix shape is (70000, 49626)\n",
      "[70000/1915498] sparse_matrix shape is (80000, 49626)\n",
      "[80000/1915498] sparse_matrix shape is (90000, 49626)\n",
      "[90000/1915498] sparse_matrix shape is (100000, 49626)\n",
      "[100000/1915498] sparse_matrix shape is (110000, 49626)\n",
      "[110000/1915498] sparse_matrix shape is (120000, 49626)\n",
      "[120000/1915498] sparse_matrix shape is (130000, 49626)\n",
      "[130000/1915498] sparse_matrix shape is (140000, 49626)\n",
      "[140000/1915498] sparse_matrix shape is (150000, 49626)\n",
      "[150000/1915498] sparse_matrix shape is (160000, 49626)\n",
      "[160000/1915498] sparse_matrix shape is (170000, 49626)\n",
      "[170000/1915498] sparse_matrix shape is (180000, 49626)\n",
      "[180000/1915498] sparse_matrix shape is (190000, 49626)\n",
      "[190000/1915498] sparse_matrix shape is (200000, 49626)\n",
      "[200000/1915498] sparse_matrix shape is (210000, 49626)\n",
      "[210000/1915498] sparse_matrix shape is (220000, 49626)\n",
      "[220000/1915498] sparse_matrix shape is (230000, 49626)\n",
      "[230000/1915498] sparse_matrix shape is (240000, 49626)\n",
      "[240000/1915498] sparse_matrix shape is (250000, 49626)\n",
      "[250000/1915498] sparse_matrix shape is (260000, 49626)\n",
      "[260000/1915498] sparse_matrix shape is (270000, 49626)\n",
      "[270000/1915498] sparse_matrix shape is (280000, 49626)\n",
      "[280000/1915498] sparse_matrix shape is (290000, 49626)\n",
      "[290000/1915498] sparse_matrix shape is (300000, 49626)\n",
      "[300000/1915498] sparse_matrix shape is (310000, 49626)\n",
      "[310000/1915498] sparse_matrix shape is (320000, 49626)\n",
      "[320000/1915498] sparse_matrix shape is (330000, 49626)\n",
      "[330000/1915498] sparse_matrix shape is (340000, 49626)\n",
      "[340000/1915498] sparse_matrix shape is (350000, 49626)\n",
      "[350000/1915498] sparse_matrix shape is (360000, 49626)\n",
      "[360000/1915498] sparse_matrix shape is (370000, 49626)\n",
      "[370000/1915498] sparse_matrix shape is (380000, 49626)\n",
      "[380000/1915498] sparse_matrix shape is (390000, 49626)\n",
      "[390000/1915498] sparse_matrix shape is (400000, 49626)\n",
      "[400000/1915498] sparse_matrix shape is (410000, 49626)\n",
      "[410000/1915498] sparse_matrix shape is (420000, 49626)\n",
      "[420000/1915498] sparse_matrix shape is (430000, 49626)\n",
      "[430000/1915498] sparse_matrix shape is (440000, 49626)\n",
      "[440000/1915498] sparse_matrix shape is (450000, 49626)\n",
      "[450000/1915498] sparse_matrix shape is (460000, 49626)\n",
      "[460000/1915498] sparse_matrix shape is (470000, 49626)\n",
      "[470000/1915498] sparse_matrix shape is (480000, 49626)\n",
      "[480000/1915498] sparse_matrix shape is (490000, 49626)\n",
      "[490000/1915498] sparse_matrix shape is (500000, 49626)\n",
      "[500000/1915498] sparse_matrix shape is (510000, 49626)\n",
      "[510000/1915498] sparse_matrix shape is (520000, 49626)\n",
      "[520000/1915498] sparse_matrix shape is (530000, 49626)\n",
      "[530000/1915498] sparse_matrix shape is (540000, 49626)\n",
      "[540000/1915498] sparse_matrix shape is (550000, 49626)\n",
      "[550000/1915498] sparse_matrix shape is (560000, 49626)\n",
      "[560000/1915498] sparse_matrix shape is (570000, 49626)\n",
      "[570000/1915498] sparse_matrix shape is (580000, 49626)\n",
      "[580000/1915498] sparse_matrix shape is (590000, 49626)\n",
      "[590000/1915498] sparse_matrix shape is (600000, 49626)\n",
      "[600000/1915498] sparse_matrix shape is (610000, 49626)\n",
      "[610000/1915498] sparse_matrix shape is (620000, 49626)\n",
      "[620000/1915498] sparse_matrix shape is (630000, 49626)\n",
      "[630000/1915498] sparse_matrix shape is (640000, 49626)\n",
      "[640000/1915498] sparse_matrix shape is (650000, 49626)\n",
      "[650000/1915498] sparse_matrix shape is (660000, 49626)\n",
      "[660000/1915498] sparse_matrix shape is (670000, 49626)\n",
      "[670000/1915498] sparse_matrix shape is (680000, 49626)\n",
      "[680000/1915498] sparse_matrix shape is (690000, 49626)\n",
      "[690000/1915498] sparse_matrix shape is (700000, 49626)\n",
      "[700000/1915498] sparse_matrix shape is (710000, 49626)\n",
      "[710000/1915498] sparse_matrix shape is (720000, 49626)\n",
      "[720000/1915498] sparse_matrix shape is (730000, 49626)\n",
      "[730000/1915498] sparse_matrix shape is (740000, 49626)\n",
      "[740000/1915498] sparse_matrix shape is (750000, 49626)\n",
      "[750000/1915498] sparse_matrix shape is (760000, 49626)\n",
      "[760000/1915498] sparse_matrix shape is (770000, 49626)\n",
      "[770000/1915498] sparse_matrix shape is (780000, 49626)\n",
      "[780000/1915498] sparse_matrix shape is (790000, 49626)\n",
      "[790000/1915498] sparse_matrix shape is (800000, 49626)\n",
      "[800000/1915498] sparse_matrix shape is (810000, 49626)\n",
      "[810000/1915498] sparse_matrix shape is (820000, 49626)\n",
      "[820000/1915498] sparse_matrix shape is (830000, 49626)\n",
      "[870000/1915498] sparse_matrix shape is (880000, 49626)\n",
      "[880000/1915498] sparse_matrix shape is (890000, 49626)\n",
      "[890000/1915498] sparse_matrix shape is (900000, 49626)\n",
      "[900000/1915498] sparse_matrix shape is (910000, 49626)\n",
      "[910000/1915498] sparse_matrix shape is (920000, 49626)\n",
      "[920000/1915498] sparse_matrix shape is (930000, 49626)\n",
      "[930000/1915498] sparse_matrix shape is (940000, 49626)\n",
      "[940000/1915498] sparse_matrix shape is (950000, 49626)\n",
      "[950000/1915498] sparse_matrix shape is (960000, 49626)\n",
      "[960000/1915498] sparse_matrix shape is (970000, 49626)\n",
      "[970000/1915498] sparse_matrix shape is (980000, 49626)\n",
      "[980000/1915498] sparse_matrix shape is (990000, 49626)\n",
      "[990000/1915498] sparse_matrix shape is (1000000, 49626)\n",
      "[1000000/1915498] sparse_matrix shape is (1010000, 49626)\n",
      "[1010000/1915498] sparse_matrix shape is (1020000, 49626)\n",
      "[1020000/1915498] sparse_matrix shape is (1030000, 49626)\n",
      "[1030000/1915498] sparse_matrix shape is (1040000, 49626)\n",
      "[1040000/1915498] sparse_matrix shape is (1050000, 49626)\n",
      "[1050000/1915498] sparse_matrix shape is (1060000, 49626)\n",
      "[1060000/1915498] sparse_matrix shape is (1070000, 49626)\n",
      "[1070000/1915498] sparse_matrix shape is (1080000, 49626)\n",
      "[1080000/1915498] sparse_matrix shape is (1090000, 49626)\n",
      "[1090000/1915498] sparse_matrix shape is (1100000, 49626)\n",
      "[1100000/1915498] sparse_matrix shape is (1110000, 49626)\n",
      "[1110000/1915498] sparse_matrix shape is (1120000, 49626)\n",
      "[1120000/1915498] sparse_matrix shape is (1130000, 49626)\n",
      "[1130000/1915498] sparse_matrix shape is (1140000, 49626)\n",
      "[1140000/1915498] sparse_matrix shape is (1150000, 49626)\n",
      "[1150000/1915498] sparse_matrix shape is (1160000, 49626)\n",
      "[1160000/1915498] sparse_matrix shape is (1170000, 49626)\n",
      "[1170000/1915498] sparse_matrix shape is (1180000, 49626)\n",
      "[1180000/1915498] sparse_matrix shape is (1190000, 49626)\n",
      "[1190000/1915498] sparse_matrix shape is (1200000, 49626)\n",
      "[1200000/1915498] sparse_matrix shape is (1210000, 49626)\n",
      "[1210000/1915498] sparse_matrix shape is (1220000, 49626)\n",
      "[1220000/1915498] sparse_matrix shape is (1230000, 49626)\n",
      "[1230000/1915498] sparse_matrix shape is (1240000, 49626)\n",
      "[1240000/1915498] sparse_matrix shape is (1250000, 49626)\n",
      "[1250000/1915498] sparse_matrix shape is (1260000, 49626)\n",
      "[1260000/1915498] sparse_matrix shape is (1270000, 49626)\n",
      "[1270000/1915498] sparse_matrix shape is (1280000, 49626)\n",
      "[1280000/1915498] sparse_matrix shape is (1290000, 49626)\n",
      "[1290000/1915498] sparse_matrix shape is (1300000, 49626)\n",
      "[1300000/1915498] sparse_matrix shape is (1310000, 49626)\n",
      "[1310000/1915498] sparse_matrix shape is (1320000, 49626)\n",
      "[1320000/1915498] sparse_matrix shape is (1330000, 49626)\n",
      "[1330000/1915498] sparse_matrix shape is (1340000, 49626)\n",
      "[1340000/1915498] sparse_matrix shape is (1350000, 49626)\n",
      "[1350000/1915498] sparse_matrix shape is (1360000, 49626)\n",
      "[1360000/1915498] sparse_matrix shape is (1370000, 49626)\n",
      "[1370000/1915498] sparse_matrix shape is (1380000, 49626)\n",
      "[1380000/1915498] sparse_matrix shape is (1390000, 49626)\n",
      "[1390000/1915498] sparse_matrix shape is (1400000, 49626)\n",
      "[1400000/1915498] sparse_matrix shape is (1410000, 49626)\n",
      "[1410000/1915498] sparse_matrix shape is (1420000, 49626)\n",
      "[1420000/1915498] sparse_matrix shape is (1430000, 49626)\n",
      "[1430000/1915498] sparse_matrix shape is (1440000, 49626)\n",
      "[1440000/1915498] sparse_matrix shape is (1450000, 49626)\n",
      "[1450000/1915498] sparse_matrix shape is (1460000, 49626)\n",
      "[1460000/1915498] sparse_matrix shape is (1470000, 49626)\n",
      "[1470000/1915498] sparse_matrix shape is (1480000, 49626)\n",
      "[1480000/1915498] sparse_matrix shape is (1490000, 49626)\n",
      "[1490000/1915498] sparse_matrix shape is (1500000, 49626)\n",
      "[1500000/1915498] sparse_matrix shape is (1510000, 49626)\n",
      "[1510000/1915498] sparse_matrix shape is (1520000, 49626)\n",
      "[1520000/1915498] sparse_matrix shape is (1530000, 49626)\n",
      "[1530000/1915498] sparse_matrix shape is (1540000, 49626)\n",
      "[1540000/1915498] sparse_matrix shape is (1550000, 49626)\n",
      "[1550000/1915498] sparse_matrix shape is (1560000, 49626)\n",
      "[1560000/1915498] sparse_matrix shape is (1570000, 49626)\n",
      "[1570000/1915498] sparse_matrix shape is (1580000, 49626)\n",
      "[1580000/1915498] sparse_matrix shape is (1590000, 49626)\n",
      "[1590000/1915498] sparse_matrix shape is (1600000, 49626)\n",
      "[1600000/1915498] sparse_matrix shape is (1610000, 49626)\n",
      "[1610000/1915498] sparse_matrix shape is (1620000, 49626)\n",
      "[1620000/1915498] sparse_matrix shape is (1630000, 49626)\n",
      "[1630000/1915498] sparse_matrix shape is (1640000, 49626)\n",
      "[1640000/1915498] sparse_matrix shape is (1650000, 49626)\n",
      "[1650000/1915498] sparse_matrix shape is (1660000, 49626)\n",
      "[1660000/1915498] sparse_matrix shape is (1670000, 49626)\n",
      "[1670000/1915498] sparse_matrix shape is (1680000, 49626)\n",
      "[1680000/1915498] sparse_matrix shape is (1690000, 49626)\n",
      "[1690000/1915498] sparse_matrix shape is (1700000, 49626)\n",
      "[1700000/1915498] sparse_matrix shape is (1710000, 49626)\n",
      "[1710000/1915498] sparse_matrix shape is (1720000, 49626)\n",
      "[1720000/1915498] sparse_matrix shape is (1730000, 49626)\n",
      "[1730000/1915498] sparse_matrix shape is (1740000, 49626)\n",
      "[1740000/1915498] sparse_matrix shape is (1750000, 49626)\n",
      "[1750000/1915498] sparse_matrix shape is (1760000, 49626)\n",
      "[1760000/1915498] sparse_matrix shape is (1770000, 49626)\n",
      "[1770000/1915498] sparse_matrix shape is (1780000, 49626)\n",
      "[1780000/1915498] sparse_matrix shape is (1790000, 49626)\n",
      "[1790000/1915498] sparse_matrix shape is (1800000, 49626)\n",
      "[1800000/1915498] sparse_matrix shape is (1810000, 49626)\n",
      "[1810000/1915498] sparse_matrix shape is (1820000, 49626)\n",
      "[1820000/1915498] sparse_matrix shape is (1830000, 49626)\n",
      "[1830000/1915498] sparse_matrix shape is (1840000, 49626)\n",
      "[1840000/1915498] sparse_matrix shape is (1850000, 49626)\n",
      "[1850000/1915498] sparse_matrix shape is (1860000, 49626)\n",
      "[1860000/1915498] sparse_matrix shape is (1870000, 49626)\n",
      "[1870000/1915498] sparse_matrix shape is (1880000, 49626)\n",
      "[1880000/1915498] sparse_matrix shape is (1890000, 49626)\n",
      "[1890000/1915498] sparse_matrix shape is (1900000, 49626)\n",
      "[1900000/1915498] sparse_matrix shape is (1910000, 49626)\n",
      "[1910000/1915498] sparse_matrix shape is (1915498, 49626)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = get_douban()\n",
    "# str to int\n",
    "user_book = np.array([list(map(int, data)) for data in data['user_book']])\n",
    "# 濾除使用者評分小於三筆的資料\n",
    "filter_data = user_filter(user_book, 0)\n",
    "# user label encoder\n",
    "le = LabelEncoder()\n",
    "filter_data[:, 0] = le.fit_transform(filter_data[:, 0])\n",
    "filter_data[:, 0] += 1\n",
    "# item label encoder\n",
    "ile = LabelEncoder()\n",
    "filter_data[:, 1] = ile.fit_transform(filter_data[:, 1])\n",
    "filter_data[:, 1] += 1\n",
    "print(f\"使用者評分大於三次的共有：{filter_data.shape}\")\n",
    "# 是否加上假資料\n",
    "fake=True\n",
    "if fake:\n",
    "    # 取得加上使用者未評分的sample假資料\n",
    "    filter_data = get_norating_data(filter_data)\n",
    "\n",
    "# 取得business個數及users個數\n",
    "douban_users, books = np.unique(filter_data[:,0]), np.unique(filter_data[:,1])\n",
    "# 取得訓練資料及測試資料\n",
    "douban_training_data,  douban_testing_data = training_testing(filter_data)\n",
    "users_dict, items_dict, features = get_feature_map(data, 'user_book')\n",
    "douban_training_df = generate_with_feature(douban_training_data, users_dict, items_dict, init_col=[\"user\", \"book\", \"rating\"])\n",
    "douban_testing_df = generate_with_feature(douban_testing_data, users_dict, items_dict, init_col=[\"user\", \"book\", \"rating\"])\n",
    "\n",
    "print(\"users: \", len(douban_users))\n",
    "print(\"items: \", len(books))\n",
    "# generarte one hot encoding\n",
    "bpr = False\n",
    "if bpr:\n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(training_data, douban_users, books)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    train_uij = np.vstack((uij_pos, uij_neg))\n",
    "    test_uij_pos, test_uij_neg = get_uij(testing_data, douban_users, books)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "    one_hot_x, y, add_fake_data = get_uij_one_hot_feature(data,  'user_book', train_uij)\n",
    "else:\n",
    "    one_hot_x, y, add_fake_data = get_one_hot_feature(data,  'user_book')\n",
    "\n",
    "# generarte one hot encoding\n",
    "X_train_douban, X_test_douban, y_train_douban, y_test_douban = training_testing_XY(one_hot_x, y, random_state=int(config['model']['random_state']))\n",
    "training_index_douban, test_index_douban, _, _ = training_testing_XY(add_fake_data, y, random_state=int(config['model']['random_state']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100878b3-d40a-4d90-a916-6cdde0b47339",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. User-based Collaborative Filtering (U-CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550a514-2c1a-4a63-933f-ec3210319308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import copy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7207d08-17cf-46cc-836c-2a2928438f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def user_sim_score(users, items, train_data, test_data, k=int(config['CF']['user_K'])):\n",
    "    # make matrix\n",
    "    user_matrix = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "    # 計算bias\n",
    "    bias_matrix = util.get_bias(user_matrix, users, items)\n",
    "    # 計算相似度\n",
    "#     cos, pcc = util.get_sim_array(user_matrix)\n",
    "#     cosine_dis = cos -  np.identity(len(users))\n",
    "#     pcc_dis = pcc -  np.identity(len(users))\n",
    "    \n",
    "#     sim = {\"cos\":cosine_dis, \"pcc\":pcc_dis}\n",
    "    sim = [\"cos\", \"pcc\"]\n",
    "    evaluation = dict()\n",
    "    for s in sim:\n",
    "        delta_list = list()\n",
    "        predict_array = np.zeros((test_matrix.shape))\n",
    "        # sim_dis = sim[s]\n",
    "        sim_array = util.get_sim_array(user_matrix, sim=s)\n",
    "        sim_dis = sim_array -  np.identity(len(users))\n",
    "        for i in tqdm(range(len(users)), desc=f\"UCF predicting {s} score with {k}\"):\n",
    "            # Suv: 取出前K個最相似的使用者相似度 ex:K=3, output=[0.378, 0.353, 0.336]\n",
    "            Suv = heapq.nlargest(k ,sim_dis[i])\n",
    "            # 若i不存在，則跳過\n",
    "            if np.isnan(sim_dis[i]).all():\n",
    "                continue\n",
    "            # top_sim_index: 取出與使用者i最為相似的前K個使用者 ex:K=3, output=[915, 406, 214]\n",
    "            sim_dis_idx = sim_dis[i].tolist()\n",
    "            top_sim_index = list(map(sim_dis_idx.index, heapq.nlargest(k,sim_dis[i])))\n",
    "            # recall\n",
    "            prediction = list()\n",
    "            # 計算相似使用者與使用者i的評分誤差\n",
    "            for item_idx in range(len(items)):\n",
    "                # 取得使用者i的評分(ground truth)\n",
    "                rth = test_matrix[i, item_idx]\n",
    "                # 如果使用者i有進行評分，則才納入計算RMSE\n",
    "                if rth != 0:\n",
    "                    # 之後需剔除對電影m未評分的相似使用者，因此先進行複製，才不會影響下一部電影的計算\n",
    "                    copy_Suv = copy.deepcopy(Suv)\n",
    "                    # R: 若相似使用者對電影 m 有評分則進行調整\n",
    "                    R = list()\n",
    "                    # 判斷相似使用者是否對電影ｍ有評分，若有評分則將原始評分減去該使用者對電影m的bias\n",
    "                    for c, j in enumerate(top_sim_index):\n",
    "                        if  test_matrix[j, item_idx] == 0:\n",
    "                            R.append(0)\n",
    "                            copy_Suv[c] = 0\n",
    "                        else:\n",
    "                            R.append(test_matrix[j, item_idx] - bias_matrix[j, item_idx])\n",
    "                    # 如果所有相似使用者都沒評分則跳過此次計算\n",
    "                    if sum(R) != 0:\n",
    "                        # 預測使用者i對於第m部電影的評分 + 使用者i對電影m的偏差\n",
    "                        Rui = predict(copy_Suv, R) + bias_matrix[i, item_idx]\n",
    "                        # 計算square error\n",
    "                        delta_list.append(util.se(rth, Rui))\n",
    "                        # 儲存預測結果, 並取四捨五入\n",
    "                        predict_array[i, item_idx] = Rui\n",
    "        # 各評估指標\n",
    "        evaluation[f'{s}_rmse']= util.rmse(delta_list)\n",
    "        evaluation[f'{s}_recall@10'] = recall_k(test_matrix, predict_array) \n",
    "        evaluation[f'{s}_NDCG@10']=ndcg_score(test_matrix, predict_array, k=10)\n",
    "        \n",
    "    return evaluation\n",
    "\n",
    "\n",
    "print(\"==========\\nMovielens:\\n==========\")\n",
    "wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"UCF\")\n",
    "wandb_log = WandbLog()\n",
    "movie_reuslt = user_sim_score(len_users, movies, training_data, testing_data)\n",
    "wandb_log.log_evaluation(movie_reuslt)\n",
    "print(movie_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"UCF\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = user_sim_score(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "wandb.init(project=config['general']['douban'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"UCF\")\n",
    "wandb_log = WandbLog()\n",
    "douban_reuslt = user_sim_score(douban_users, books, douban_training_data, douban_testing_data)\n",
    "wandb_log.log_evaluation(douban_reuslt)\n",
    "print(douban_reuslt)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76ff5f-9a67-4ed0-9a0f-f4f94add8de9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Item-based Collaborative Filtering (I-CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b2f05-9860-4be9-b6be-88fb7e345438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from util.mywandb import WandbLog\n",
    "\n",
    "def item_sim_score(users, items, train_data, test_data, k=int(config['CF']['user_K'])):\n",
    "    # make matrix\n",
    "    user_matrix = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "    item_matrix = user_matrix.T \n",
    "    item_test = test_matrix.T\n",
    "    #item_test = sparse.csr_matrix(item_test)\n",
    "    del test_matrix\n",
    "    \n",
    "    # 計算bias\n",
    "    bias_matrix = util.get_bias(user_matrix, users, items)\n",
    "    item_bias = bias_matrix.T\n",
    "    del bias_matrix\n",
    "    del user_matrix\n",
    "    \n",
    "    # 計算相似度\n",
    "    #cos, pcc = util.get_sim_array(item_matrix)\n",
    "    #cosine_dis = cos -  np.identity(len(items))\n",
    "    #cosine_dis = sparse.csr_matrix(cosine_dis)\n",
    "    #pcc_dis = pcc -  np.identity(len(items))\n",
    "    #pcc_dis = sparse.csr_matrix(pcc_dis)\n",
    "    #sim = {\"cos\":cosine_dis, \"pcc\":pcc_dis}\n",
    "    sim = [\"cos\", \"pcc\"]\n",
    "    evaluation = dict()\n",
    "    for s in sim:\n",
    "        delta_list = list()\n",
    "        predict_array = np.zeros((item_test.shape))\n",
    "        # predict array to spase\n",
    "        predict_array = sparse.csr_matrix(predict_array)\n",
    "        sim_array = util.get_sim_array(item_matrix, sim=s)\n",
    "        sim_dis = sim_array -  np.identity(len(items))\n",
    "        # sim_dis = sim[s]\n",
    "        for i in tqdm(range(len(items)), desc=f\"ICF predicting {s} score with {k}\"):\n",
    "            # Siv: 取出前K個最相似的使用者相似度 ex:K=3, output=[0.378, 0.353, 0.336]\n",
    "            Siv = heapq.nlargest(k ,sim_dis[i])\n",
    "            # 若i不存在，則跳過\n",
    "            if np.isnan(sim_dis[i]).all():\n",
    "                continue\n",
    "            sim_dis[i][np.isnan(sim_dis[i])] = 0\n",
    "            # top_sim_index: 取出與使用者i最為相似的前K個使用者 ex:K=3, output=[915, 406, 214]\n",
    "            sim_dis_idx = sim_dis[i].tolist()\n",
    "            top_sim_index = list(map(sim_dis_idx.index, heapq.nlargest(k,sim_dis[i])))\n",
    "            # recall\n",
    "            prediction = list()\n",
    "            # 計算相似電影與電影i的評分誤差\n",
    "            for user_idx in range(len(users)):\n",
    "                # 取得項目i的評分(ground truth)\n",
    "                rth = item_test[i, user_idx]\n",
    "                # 如果使用者i有進行評分，則才納入計算RMSE\n",
    "                if rth != 0:\n",
    "                    # 之後需剔除對電影m未評分的相似使用者，因此先進行複製，才不會影響下一部電影的計算\n",
    "                    copy_Siv = copy.deepcopy(Siv)\n",
    "                    # R: 若相似使用者對電影 m 有評分則進行調整\n",
    "                    R = list()\n",
    "                    # 判斷相似使用者是否對電影ｍ有評分，若有評分則將原始評分減去該使用者對電影m的bias\n",
    "                    for c, j in enumerate(top_sim_index):\n",
    "                        if  item_test[j, user_idx] == 0:\n",
    "                            R.append(0)\n",
    "                            copy_Siv[c] = 0\n",
    "                        else:\n",
    "                            R.append(item_test[j, user_idx] - item_bias[j, user_idx])\n",
    "                    # 如果所有相似使用者都沒評分則跳過此次計算\n",
    "                    if sum(R) != 0:\n",
    "                        # 預測使用者i對於第m部電影的評分 + 使用者i對電影m的偏差\n",
    "                        Rui = predict(copy_Siv, R) + item_bias[i, user_idx]\n",
    "                        # 計算square error\n",
    "                        delta_list.append(util.se(rth, Rui))\n",
    "                        # 儲存預測結果, 並取四捨五入\n",
    "                        if np.isnan(Rui):\n",
    "                            Rui=0\n",
    "                        predict_array[i, user_idx] = Rui\n",
    "        \n",
    "        \n",
    "        # 各評估指標\n",
    "        delta_list = pd.Series(delta_list, dtype=object).fillna(0).tolist()\n",
    "        evaluation[f'{s}_rmse']= util.rmse(delta_list)\n",
    "        evaluation[f'{s}_recall@10'] = recall_k(item_test, predict_array) \n",
    "        evaluation[f'{s}_NDCG@10']=ndcg_score(item_test, predict_array.toarray(), k=10)\n",
    "        \n",
    "    return evaluation\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"ICF\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = item_sim_score(len_users, movies, training_data, testing_data)\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# print(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"ICF\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = item_sim_score(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"ICF\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = item_sim_score(douban_users, books, douban_training_data, douban_testing_data)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555705a2-5424-4878-8f2d-d0c87a5de4d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e38937-3e80-412a-9a71-4e68c459cf54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from util.mywandb import WandbLog\n",
    "\n",
    "# 進行測試資料驗證評估\n",
    "def test(test_data, p, q, gu=False, bu=False, bi=False):\n",
    "    rmse_test = list()\n",
    "\n",
    "    for test in test_data:\n",
    "        user = test[0] - 1\n",
    "        movie = test[1] - 1\n",
    "        # 判斷是否有bias\n",
    "        if gu and bu.any() and bi.any():\n",
    "            rmse_test.append(util.se(test[2], (np.dot(p[user], q[movie]) + gu + bu[user] + bi[movie])))\n",
    "        else:\n",
    "            rmse_test.append(util.se(test[2], (np.dot(p[user], q[movie]))))\n",
    "    return util.rmse(rmse_test)\n",
    "\n",
    "def execute_matrix_factorization(users, items, train_data, test_data):\n",
    "    # 存放測試資料集的rmse結果\n",
    "    MF_bias_testing = list()\n",
    "    # init evaluation\n",
    "    evaluation = dict()\n",
    "    user_item = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "\n",
    "    # init setting global mean\n",
    "    gu= util.get_u(user_item)\n",
    "    # init setting user mean as bias\n",
    "    bu = np.array([util.get_ubias(user_item, i) - gu for i in range(len(users))])\n",
    "    # init setting items mean as bias\n",
    "    bi = np.array([util.get_ibias(user_item, m) - gu for m in range(len(items))])\n",
    "\n",
    "    # init lentent vector\n",
    "    K = int(config[\"MF\"][\"latent_vector_number\"])\n",
    "    # init user lentent matrix\n",
    "    P = np.random.uniform(low=0, high=3, size=(users.max(), K))\n",
    "    # init items lentent matrix\n",
    "    Q = np.random.uniform(low=0, high=3, size=(items.max(), K))\n",
    "\n",
    "    # parameter\n",
    "    epochs = int(config[\"MF\"][\"epochs\"])\n",
    "    alpha = float(config[\"MF\"][\"alpha\"])\n",
    "    l = float(config[\"MF\"][\"learning_rate\"])\n",
    "\n",
    "    # 更新次數, init=100\n",
    "    for epoch in range(epochs):\n",
    "        # 存放 spuare error 結果\n",
    "        se_list = list()\n",
    "        # 針對user有評分過的rating位置進行更新(User Latent Matrix)\n",
    "        for j in range(len(users)):\n",
    "            # 找出被使用者j評分過的電影\n",
    "            # movie_index = [i for i, e in enumerate(user_item[j]) if e != 0]\n",
    "            movie_index = np.nonzero(user_item[j])[0]\n",
    "            for m in movie_index:\n",
    "                # 對u 做偏微分進行ＳＧＤ更新\n",
    "                tmp_gu = gu - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) + l*(gu))\n",
    "                # 對bu 做偏微分進行ＳＧＤ更新\n",
    "                tmp_bu = bu[j] - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) + l*(bu[j]))\n",
    "                # 對bi 做偏微分進行ＳＧＤ更新\n",
    "                tmp_bi = bi[m] - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) + l*(bi[m]))\n",
    "                # 若user item 有值則對Q的相對欄位進行SGD更新, 將更新後user latent matrix先暫存\n",
    "                tmp = Q[m] - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) * P[j] + l*(Q[m]))\n",
    "                # 更新 movie latent matrix\n",
    "                P[j] -= alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) * Q[m] + l*(P[j]))\n",
    "                # 更新 user latent matrix\n",
    "                Q[m] = tmp\n",
    "                # 更新bias\n",
    "                gu = tmp_gu\n",
    "                bu[j] = tmp_bu\n",
    "                bi[m] = tmp_bi\n",
    "                # 計算ＳＥ\n",
    "                se_list.append(util.se(user_item[j, m], (np.dot(P[j], Q[m]) + gu + bu[j] + bi[m])))\n",
    "                \n",
    "        # 進行驗證資料測試\n",
    "        MF_bias_testing.append(test(test_data, P, Q, gu, bu, bi))\n",
    "        if epoch % 9 == 0:\n",
    "            print(f\"[{epoch}/{epochs}] gu={gu}, bu={np.mean(bu)}, bi={np.mean(bi)}, testing error={MF_bias_testing[-1]}\")\n",
    "\n",
    "    # 各評估指標\n",
    "    evaluation['rmse']= MF_bias_testing[-1]\n",
    "    evaluation['recall@10'] = recall_k(test_matrix, np.dot(P, Q.T))\n",
    "    evaluation['NDCG@10'] = ndcg_score(test_matrix, np.dot(P, Q.T))\n",
    "    \n",
    "    return evaluation\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"MF\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = execute_matrix_factorization(len_users, movies, training_data, testing_data)\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# print(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"MF\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = execute_matrix_factorization(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "wandb.init(project=config['general']['douban'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"MF\")\n",
    "wandb_log = WandbLog()\n",
    "douban_reuslt = execute_matrix_factorization(douban_users, books, douban_training_data, douban_testing_data)\n",
    "wandb_log.log_evaluation(douban_reuslt)\n",
    "print(douban_reuslt)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345f5f0-cb98-436a-bc18-3d33e399f6cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. BPR-MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed929932-c906-4d20-b84c-3c8329c6d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from util.mywandb import WandbLog\n",
    "\n",
    "# 進行測試資料驗證評估\n",
    "def test(test_uij, users, items, p, q, gu=False, bu=False, bi=False):\n",
    "    rmse_test = list()\n",
    "    \n",
    "    \n",
    "    for u, i, j, rank in test_uij:\n",
    "        u_idx = u - 1\n",
    "        i_idx = i - 1\n",
    "        j_idx = j - 1\n",
    "        rui = np.dot(p[u_idx], q[i_idx])\n",
    "        ruj = np.dot(p[u_idx], q[j_idx])\n",
    "        x_uij =  rui - ruj\n",
    "        # sigmoid\n",
    "        exp_x = np.exp(-x_uij)\n",
    "        y_hat = 1/(1 + np.exp(exp_x))\n",
    "        \n",
    "        rmse_test.append(util.se(y_hat, rank))\n",
    "        \n",
    "    return util.rmse(rmse_test)\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "def execute_bpr_matrix_factorization(users, items, train_data, test_data):\n",
    "    # 存放測試資料集的rmse結果\n",
    "    MF_bias_testing = list()\n",
    "    # init evaluation\n",
    "    evaluation = dict()\n",
    "    user_item = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "\n",
    "    # init setting global mean\n",
    "    gu= util.get_u(user_item)\n",
    "    # init setting user mean as bias\n",
    "    bu = np.array([util.get_ubias(user_item, i) - gu for i in range(len(users))])\n",
    "    # init setting items mean as bias\n",
    "    bi = np.array([util.get_ibias(user_item, m) - gu for m in range(len(items))])\n",
    "\n",
    "    # init lentent vector\n",
    "    K = int(config[\"MF\"][\"latent_vector_number\"])\n",
    "    # init user lentent matrix\n",
    "    # P = np.random.uniform(low=0, high=3, size=(users.max(), K))\n",
    "    P = np.random.randn(users.max(), K)/10\n",
    "    # init items lentent matrix\n",
    "    # Q = np.random.uniform(low=0, high=3, size=(items.max(), K))\n",
    "    Q = np.random.randn(items.max(), K)/10\n",
    "    \n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(train_data, users, items)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    # uij = np.vstack(uij_pos, uij_neg)\n",
    "    test_uij_pos, test_uij_neg = get_uij(test_data, users, items)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "\n",
    "    # parameter\n",
    "    epochs = int(config[\"MF\"][\"epochs\"])\n",
    "    alpha = float(config[\"MF\"][\"alpha\"])\n",
    "    l = float(config[\"MF\"][\"learning_rate\"])\n",
    "\n",
    "    # 更新次數, init=100\n",
    "    for epoch in range(epochs):\n",
    "        # 針對user有評分過的rating位置進行更新(User Latent Matrix)\n",
    "        for u, i, j, rank in uij_pos:\n",
    "            # 計算x_uij\n",
    "            # rui = np.dot(P[u], Q[i]) + gu + bu[u] + bi[i]\n",
    "            # ruj = np.dot(P[u], Q[j]) + gu + bu[u] + bi[j]\n",
    "            i_idx = i-1\n",
    "            j_idx = j-1\n",
    "            u_idx = u-1\n",
    "            rui = np.dot(P[u_idx], Q[i_idx])\n",
    "            ruj = np.dot(P[u_idx], Q[j_idx])\n",
    "            x_uij =  rui - ruj\n",
    "            \n",
    "            # sigmoid\n",
    "            exp_x = np.exp(-x_uij)\n",
    "            partial_BPR = 1/(1 + np.exp(exp_x))\n",
    "            \n",
    "            # 更新 user latent matrix\n",
    "            New_P= alpha * (partial_BPR*(Q[i_idx]-Q[j_idx]) + l*(P[u_idx]))\n",
    "            # 若user item 有值則對Q的相對欄位進行SGD更新, 將更新後user latent matrix先暫存\n",
    "            Q[i_idx] -=  alpha * (partial_BPR*P[u_idx] + l*(Q[i_idx]))\n",
    "            Q[j_idx] -=  alpha * (partial_BPR*-P[u_idx] + l*(Q[j_idx]))\n",
    "            # 更新 user latent matrix\n",
    "            P[u_idx] = New_P\n",
    "            # # 更新bias\n",
    "            # # 對u 做偏微分進行ＳＧＤ更新\n",
    "            # gu = gu - alpha * ((rui - user_item[j,m]) + l*(gu))\n",
    "            # # 對bu 做偏微分進行ＳＧＤ更新\n",
    "            # bu[j] = bu[j] - alpha * ((rui - user_item[j,m]) + l*(bu[j]))\n",
    "            # # 對bi 做偏微分進行ＳＧＤ更新\n",
    "            # bi[m] = bi[m] - alpha * ((rui - user_item[j,m]) + l*(bi[m]))\n",
    "            \n",
    "\n",
    "                \n",
    "        # 進行驗證資料測試\n",
    "        MF_bias_testing.append(test(test_uij, users, items, P, Q))\n",
    "        if epoch % 9 == 0:\n",
    "            print(f\"[{epoch}/{epochs}] testing error={MF_bias_testing[-1]}\")\n",
    "    \n",
    "    rui = np.dot(P[u_idx], Q[i_idx])\n",
    "    ruj = np.dot(P[u_idx], Q[j_idx])\n",
    "    x_uij =  rui - ruj\n",
    "    print(\"{} user like item{} more than item{}, score is {}: \".format(u, i, j, x_uij))\n",
    "    # 各評估指標\n",
    "    evaluation['rmse']= MF_bias_testing[-1]\n",
    "    evaluation['recall@10'] = recall_k(test_matrix, np.dot(P, Q.T))\n",
    "    evaluation['NDCG@10'] = ndcg_score(test_matrix, np.dot(P, Q.T))\n",
    "    \n",
    "    return evaluation, P, Q\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-MF\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt, P, Q = execute_bpr_matrix_factorization(len_users, movies, training_data, testing_data)\n",
    "# print(movie_reuslt)\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"BPR-MF\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = execute_bpr_matrix_factorization(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-MF\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_bpr_matrix_factorization(douban_users, books, douban_training_data, douban_testing_data)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282af117-a92e-423b-9046-37d7649708f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5. FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac852f2d-998e-4559-a13e-6918187bde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywFM\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_factorization_machine(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} FM Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "\n",
    "        # reshape y\n",
    "        y_train = y_train.reshape(1, -1)[0]\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        fm = pywFM.FM(task='regression')\n",
    "\n",
    "        model = fm.run(X_train, y_train, X_val, y_val)\n",
    "        predict_values = model.predictions\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        kfold.append(util.rmse(predict_values - y_val))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = execute_factorization_machine(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# print(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# wandb.init(project=config['general']['yelp'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# yelp_reuslt = execute_factorization_machine(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "# wandb_log.log_evaluation(yelp_reuslt)\n",
    "# print(yelp_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "wandb.init(project=config['general']['douban'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"FM\")\n",
    "wandb_log = WandbLog()\n",
    "douban_reuslt = execute_factorization_machine(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "wandb_log.log_evaluation(douban_reuslt)\n",
    "print(douban_reuslt)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa178ba6-8d9b-49d5-8ffc-c6df7c4190b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6. BPR-FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92308f-b439-47b8-8d2f-47936b751813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywFM\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_bpr_factorization_machine(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} FM Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        \n",
    "        # reshape y\n",
    "        y_train = y_train.reshape(1, -1)[0]\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        fm = pywFM.FM(task='classification')\n",
    "\n",
    "        model = fm.run(X_train, y_train, X_val, y_val)\n",
    "        predict_values = model.predictions\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        kfold.append(util.rmse(list(map(abs, predict_values - y_val))))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = execute_bpr_factorization_machine(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# print(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"BPR-FM\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = execute_bpr_factorization_machine(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_bpr_factorization_machine(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460fc07-b61b-4a62-b5bc-df381606ea0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 7.GBDT+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159f1913-085a-46f4-8cae-607b071f536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Yelp:\n",
      "==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1c6s7y7d) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">clone-astromech-16</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_yelp/runs/1c6s7y7d\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_yelp/runs/1c6s7y7d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220504_135654-1c6s7y7d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1c6s7y7d). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 14:10:19.612330: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-04 14:10:19.612369: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/baron/HW/Recommender_System/notebook/wandb/run-20220504_141012-xca51zux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/recommendation-system_yelp/runs/xca51zux\" target=\"_blank\">rogue-carrier-17</a></strong> to <a href=\"https://wandb.ai/baron/recommendation-system_yelp\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 0 GBDT+LR Cross-Validation\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 108. GiB for an array with shape (660553, 22026) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myelp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     60\u001b[0m                         entity\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     61\u001b[0m                         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGBDT_LR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m wandb_log \u001b[38;5;241m=\u001b[39m WandbLog()\n\u001b[0;32m---> 63\u001b[0m yelp_reuslt \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_gbdt_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_index_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myelp_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbusiness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m wandb_log\u001b[38;5;241m.\u001b[39mlog_evaluation(yelp_reuslt)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(yelp_reuslt)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mexecute_gbdt_lr\u001b[0;34m(X, y, X_test, y_test, training_index, test_index, users, items)\u001b[0m\n\u001b[1;32m     29\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m     30\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgb_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, gbf), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr)])\n\u001b[0;32m---> 32\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, y_train)\n\u001b[1;32m     34\u001b[0m predict_values \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_val\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[1;32m     35\u001b[0m predict \u001b[38;5;241m=\u001b[39m generate_eval_array(predict_values, val_index, users, items)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/compressed.py:1039\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1039\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py:1202\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 108. GiB for an array with shape (660553, 22026) and data type float64"
     ]
    }
   ],
   "source": [
    "from sktools import GradientBoostingFeatureGenerator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_gbdt_lr(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} GBDT+LR Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        \n",
    "        # reshape y\n",
    "        y_train = y_train.ravel()\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        gbf = GradientBoostingFeatureGenerator(regression=True)\n",
    "        lr = LogisticRegression()\n",
    "        pipe = Pipeline([(\"gb_features\", gbf), (\"logistic\", lr)])\n",
    "        \n",
    "        pipe.fit(X_train.toarray(), y_train)\n",
    "\n",
    "        predict_values = pipe.predict(X_val.toarray())\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        kfold.append(util.rmse(list(map(abs, predict_values - y_val))))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"GBDT_LR\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = execute_gbdt_lr(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "# print(movie_reuslt)\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"GBDT_LR\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = execute_gbdt_lr(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"GBDT_LR\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_gbdt_lr(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee77f90-24a7-4de4-bdb5-e863d29b7a2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8. XGB-LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d45a75-fe62-49a0-9e90-0b917edb4158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Yelp:\n",
      "==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xca51zux) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rogue-carrier-17</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_yelp/runs/xca51zux\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_yelp/runs/xca51zux</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220504_141012-xca51zux/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xca51zux). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 14:10:34.296354: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-04 14:10:34.296394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/baron/HW/Recommender_System/notebook/wandb/run-20220504_141027-35ojzg2h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/recommendation-system_yelp/runs/35ojzg2h\" target=\"_blank\">stellar-master-18</a></strong> to <a href=\"https://wandb.ai/baron/recommendation-system_yelp\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 0 XGB+LR Cross-Validation\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 108. GiB for an array with shape (660553, 22026) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myelp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     61\u001b[0m                         entity\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     62\u001b[0m                         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGB_LR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m wandb_log \u001b[38;5;241m=\u001b[39m WandbLog()\n\u001b[0;32m---> 64\u001b[0m yelp_reuslt \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_xgb_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_index_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index_yelp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myelp_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbusiness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m wandb_log\u001b[38;5;241m.\u001b[39mlog_evaluation(yelp_reuslt)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(yelp_reuslt)\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mexecute_xgb_lr\u001b[0;34m(X, y, X_test, y_test, training_index, test_index, users, items)\u001b[0m\n\u001b[1;32m     30\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m     31\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, gbf), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr)])\n\u001b[0;32m---> 33\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, y_train)\n\u001b[1;32m     35\u001b[0m predict_values \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_val\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[1;32m     36\u001b[0m predict \u001b[38;5;241m=\u001b[39m generate_eval_array(predict_values, val_index, users, items)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/compressed.py:1039\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1039\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py:1202\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 108. GiB for an array with shape (660553, 22026) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_xgb_lr(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} XGB+LR Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        \n",
    "        # reshape y\n",
    "        y_train = y_train.ravel()\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        gbf = SelectFromModel(estimator=XGBRegressor(), max_features=100, threshold=-np.inf)\n",
    "        lr = LogisticRegression()\n",
    "        pipe = Pipeline([(\"xgb_features\", gbf), (\"logistic\", lr)])\n",
    "        \n",
    "        pipe.fit(X_train.toarray(), y_train)\n",
    "\n",
    "        predict_values = pipe.predict(X_val.toarray())\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        kfold.append(util.rmse(list(map(abs, predict_values - y_val))))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"XGB_LR\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = execute_xgb_lr(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "# print(movie_reuslt)\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"XGB_LR\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = execute_xgb_lr(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"XGB_LR\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_xgb_lr(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fd429-f996-4335-a26f-338efe74ee54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9. NN-based RecSys Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978674b1-f0e1-44c7-b8ac-7e12b7989bb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cd156a-7d29-43ae-94fb-423513aacc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 23:50:47.920296: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-11 23:50:47.920638: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from models.nn_based_models import DeepCTRModel\n",
    "\n",
    "\n",
    "def deepfm(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"DeepFM\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result = deer.DeepFM(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"DeepFM={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def nfm(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"NFM\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result = deer.NFM(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"NFM={result}\")\n",
    "    run.finish()\n",
    "    \n",
    "def dcn(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"DCN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result = deer.DCN(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"DCN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def wd(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"W&D\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result = deer.WD(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"W&D={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def ccpm(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"CCPM\",\n",
    "                        reinit=True)\n",
    "    # no surppot dense\n",
    "    deer = DeepCTRModel(sparse, y=y)\n",
    "    result = deer.CCPM(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"CCPM={result}\")\n",
    "    run.finish()\n",
    "    \n",
    "def fnn(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"FNN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result, _ = deer.FNN(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"FNN={result}\")\n",
    "\n",
    "    run.finish()\n",
    "\n",
    "def ipnn(dataframe, testing_data, test_index, users, items, dataset='movielens', inner=True, outter=False,\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"IPNN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result, _ = deer.PNN(dataframe, testing_data, test_index, users, items, inner=inner, outter=outter)\n",
    "    clear_output()\n",
    "    print(f\"IPNN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def opnn(dataframe, testing_data, test_index, users, items, dataset='movielens', inner=False, outter=True,\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"OPNN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result, _ = deer.PNN(dataframe, testing_data, test_index, users, items, inner=inner, outter=outter)\n",
    "    clear_output()\n",
    "    print(f\"OPNN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def pin(dataframe, testing_data, test_index, users, items, dataset='movielens', inner=True, outter=True,\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"PIN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result = deer.PNN(dataframe, testing_data, test_index, users, items, inner=inner, outter=outter)\n",
    "    clear_output()\n",
    "    print(f\"PIN={result}\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4efb099-3ab2-443d-a617-f8f967e03c67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7981ea-1c09-4332-9a81-bd52e6f3fbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Douban Book:\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: baron (use `wandb login --relogin` to force relogin)\n",
      "2022-05-12 01:23:18.953363: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-12 01:23:18.953409: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/baron/HW/Recommender_System/notebook/wandb/run-20220512_012317-3hvouadt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/recommendation-system_douban/runs/3hvouadt\" target=\"_blank\">distinctive-monkey-33</a></strong> to <a href=\"https://wandb.ai/baron/recommendation-system_douban\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/5 Cross Validation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 01:23:26.505836: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-12 01:23:26.506964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-12 01:23:26.789893: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-12 01:23:26.789956: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gpu-server): /proc/driver/nvidia/version does not exist\n",
      "2022-05-12 01:23:26.791534: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-12 01:23:26.792355: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-12 01:23:27.306375: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-12 01:23:27.307210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2693670000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4310/4310 - 16s - loss: 2.5585 - mse: 2.5547 - val_loss: 2.4110 - val_mse: 2.4035\n",
      "Epoch 2/100\n"
     ]
    }
   ],
   "source": [
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# # 1. FM-supported Neural Networks\n",
    "# fnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 2. Product-based Neural Networks\n",
    "# ipnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# opnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# pin(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 3. Convolutional Click Prediction Model \n",
    "# ccpm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 4. neumf\n",
    "# # 5. Wide&Deep\n",
    "# wd(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 6. Deep Drossing\n",
    "# dcn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 7. Neural Factorization Machine\n",
    "# nfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 8. Deep Factorization Machine\n",
    "# deepfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# # 1. FM-supported Neural Networks\n",
    "# fnn(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# # 2. Product-based Neural Networks\n",
    "# ipnn(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# opnn(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# pin(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "\n",
    "# #3. Convolutional Click Prediction Model \n",
    "# ccpm(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category', 'user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# #4. neumf\n",
    "# #5. Wide&Deep\n",
    "# wd(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# # 6. Deep Drossing\n",
    "# dcn(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# # 7. Neural Factorization Machine\n",
    "# nfm(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# # 8. Deep Factorization Machine\n",
    "# deepfm(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "# 1. FM-supported Neural Networks\n",
    "fnn(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])\n",
    "# 2. Product-based Neural Networks\n",
    "ipnn(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])\n",
    "opnn(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])\n",
    "pin(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])\n",
    "\n",
    "#3. Convolutional Click Prediction Model \n",
    "ccpm(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    y = ['rating'])\n",
    "# 4. neumf\n",
    "# 5. Wide&Deep\n",
    "wd(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])\n",
    "# 6. Deep Drossing\n",
    "dcn(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])\n",
    "# 7. Neural Factorization Machine\n",
    "nfm(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])\n",
    "# 8. Deep Factorization Machine\n",
    "deepfm(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "    sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "    dense=['book_year'],\n",
    "    y = ['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f83b5-a90d-4570-b030-70937d006dfe",
   "metadata": {},
   "source": [
    "## 10. Recent NN-based RecSys Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5eaab9-115a-4f2b-bd71-7bb692e6c27d",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cdc365-b79b-4928-9119-e1eb0723d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nn_based_models import DeepCTRModel\n",
    "\n",
    "def din(train_df, test_df, test_index, users, items, watch_history = ['movie', 'movie_genre'], target=\"rating\", dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"DIN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result = deer.DIN(train_df, test_df, test_index, users, items, watch_history, target)\n",
    "    clear_output()\n",
    "    print(f\"DIN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def xdeepfm(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"xDeepFM\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse, dense, y)\n",
    "    result = deer.xDeepFM(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"xDeepFM={result}\")\n",
    "    run.finish()\n",
    "    \n",
    "def afm(dataframe, testing_data, test_index, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'], \n",
    "            y=['rating']):\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"AFM\",\n",
    "                        reinit=True)\n",
    "    # no dense\n",
    "    deer = DeepCTRModel(sparse, y=y)\n",
    "    result = deer.AFM(dataframe, testing_data, test_index, users, items)\n",
    "    clear_output()\n",
    "    print(f\"AFM={result}\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765641d-6037-4366-9e63-a8fb1cbb78c4",
   "metadata": {},
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa6504-66b8-49ab-829b-f4cb09ddd022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 13:22:40.872684: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-14 13:22:40.872726: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/baron/HW/Recommender_System/notebook/wandb/run-20220514_132239-3ixkbcpx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/recommendation-system_yelp/runs/3ixkbcpx\" target=\"_blank\">fluent-voice-59</a></strong> to <a href=\"https://wandb.ai/baron/recommendation-system_yelp\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trasfer history items: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 183487/183487 [00:10<00:00, 17168.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# # 1. Attentional Factorization Machines\n",
    "# afm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 3. xDeepFM\n",
    "# xdeepfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # # 4. Deep Interest Network\n",
    "# # din(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# # 1. Attentional Factorization Machines\n",
    "# afm(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category', 'user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# # 3. xDeepFM\n",
    "# xdeepfm(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "# # 4. Deep Interest Network\n",
    "din(yelp_training_df, yelp_testing_df, test_index_yelp, yelp_users, business, watch_history = ['business', 'business_category'], dataset='yelp', \n",
    "    sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "    dense=['user_compliment'],\n",
    "    y = ['rating'])\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "# #1. Attentional Factorization Machines\n",
    "# afm(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "#     sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "#     dense=['book_year'],\n",
    "#     y = ['rating'])\n",
    "# # 3. xDeepFM\n",
    "# xdeepfm(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, dataset='douban', \n",
    "#     sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "#     dense=['book_year'],\n",
    "#     y = ['rating'])\n",
    "# 4. Deep Interest Network\n",
    "# din(douban_training_df, douban_testing_df, test_index_douban, douban_users, books, watch_history = ['book', 'book_publisher'], dataset='douban', \n",
    "#     sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "#     dense=['book_year'],\n",
    "#     y = ['rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e206e4c-16f6-4591-a7ab-14bec64fe102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 13:24:28.140632: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-14 13:24:28.140672: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: baron (use `wandb login --relogin` to force relogin)\n",
      "2022-05-14 13:24:33.476260: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-14 13:24:33.476300: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/baron/HW/Recommender_System/notebook/wandb/run-20220514_132431-28shsq2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/28shsq2n\" target=\"_blank\">glad-snowball-215</a></strong> to <a href=\"https://wandb.ai/baron/recommendation-system_movielens\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/5 Cross Validation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 13:24:34.624970: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-14 13:24:34.640503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-14 13:24:34.870306: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-14 13:24:34.870365: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gpu-server): /proc/driver/nvidia/version does not exist\n",
      "2022-05-14 13:24:34.871785: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-14 13:24:34.872922: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 13:24:35.582224: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-05-14 13:24:35.592868: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2693670000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 4.6909 - mse: 4.6900 - val_loss: 3.2446 - val_mse: 3.2426\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.7786 - mse: 2.7749 - val_loss: 2.3678 - val_mse: 2.3625\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.2185 - mse: 2.2126 - val_loss: 2.2518 - val_mse: 2.2457\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.1288 - mse: 2.1225 - val_loss: 2.2092 - val_mse: 2.2027\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 2.0829 - mse: 2.0763 - val_loss: 2.1871 - val_mse: 2.1804\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 2.0550 - mse: 2.0482 - val_loss: 2.1755 - val_mse: 2.1687\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 2.0358 - mse: 2.0289 - val_loss: 2.1663 - val_mse: 2.1594\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 2.0200 - mse: 2.0130 - val_loss: 2.1580 - val_mse: 2.1510\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 2.0067 - mse: 1.9996 - val_loss: 2.1502 - val_mse: 2.1430\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.9935 - mse: 1.9863 - val_loss: 2.1455 - val_mse: 2.1382\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.9817 - mse: 1.9743 - val_loss: 2.1386 - val_mse: 2.1313\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.9699 - mse: 1.9625 - val_loss: 2.1308 - val_mse: 2.1233\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.9594 - mse: 1.9518 - val_loss: 2.1275 - val_mse: 2.1198\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.9495 - mse: 1.9417 - val_loss: 2.1245 - val_mse: 2.1166\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.9403 - mse: 1.9323 - val_loss: 2.1251 - val_mse: 2.1170\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 1.9326 - mse: 1.9244 - val_loss: 2.1171 - val_mse: 2.1088\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 1.9247 - mse: 1.9164 - val_loss: 2.1175 - val_mse: 2.1091\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.9176 - mse: 1.9090 - val_loss: 2.1163 - val_mse: 2.1077\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.9115 - mse: 1.9028 - val_loss: 2.1146 - val_mse: 2.1058\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.9059 - mse: 1.8970 - val_loss: 2.1111 - val_mse: 2.1021\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.8994 - mse: 1.8904 - val_loss: 2.1098 - val_mse: 2.1007\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.8943 - mse: 1.8851 - val_loss: 2.1101 - val_mse: 2.1007\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.8888 - mse: 1.8794 - val_loss: 2.1052 - val_mse: 2.0957\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.8833 - mse: 1.8737 - val_loss: 2.1096 - val_mse: 2.1000\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.8780 - mse: 1.8682 - val_loss: 2.1037 - val_mse: 2.0939\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.8735 - mse: 1.8636 - val_loss: 2.1049 - val_mse: 2.0949\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.8687 - mse: 1.8586 - val_loss: 2.1048 - val_mse: 2.0947\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.8644 - mse: 1.8542 - val_loss: 2.1072 - val_mse: 2.0969\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.8592 - mse: 1.8489 - val_loss: 2.1073 - val_mse: 2.0969\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.8544 - mse: 1.8439 - val_loss: 2.1056 - val_mse: 2.0950\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.8505 - mse: 1.8399 - val_loss: 2.1093 - val_mse: 2.0986\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.8456 - mse: 1.8349 - val_loss: 2.1073 - val_mse: 2.0964\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.8423 - mse: 1.8314 - val_loss: 2.1074 - val_mse: 2.0964\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.8379 - mse: 1.8268 - val_loss: 2.1142 - val_mse: 2.1030\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.8340 - mse: 1.8228 - val_loss: 2.1067 - val_mse: 2.0954\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.8298 - mse: 1.8185 - val_loss: 2.1103 - val_mse: 2.0989\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.8260 - mse: 1.8146 - val_loss: 2.1092 - val_mse: 2.0977\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.8222 - mse: 1.8106 - val_loss: 2.1150 - val_mse: 2.1033\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.8184 - mse: 1.8067 - val_loss: 2.1142 - val_mse: 2.1024\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.8151 - mse: 1.8032 - val_loss: 2.1200 - val_mse: 2.1081\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.8115 - mse: 1.7996 - val_loss: 2.1182 - val_mse: 2.1061\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.8076 - mse: 1.7955 - val_loss: 2.1200 - val_mse: 2.1079\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.8042 - mse: 1.7920 - val_loss: 2.1182 - val_mse: 2.1059\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.8006 - mse: 1.7883 - val_loss: 2.1204 - val_mse: 2.1080\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.7970 - mse: 1.7845 - val_loss: 2.1233 - val_mse: 2.1108\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.7925 - mse: 1.7799 - val_loss: 2.1282 - val_mse: 2.1156\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.7897 - mse: 1.7770 - val_loss: 2.1269 - val_mse: 2.1141\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.7856 - mse: 1.7728 - val_loss: 2.1280 - val_mse: 2.1151\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.7831 - mse: 1.7702 - val_loss: 2.1333 - val_mse: 2.1203\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.7787 - mse: 1.7656 - val_loss: 2.1314 - val_mse: 2.1183\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.7746 - mse: 1.7614 - val_loss: 2.1326 - val_mse: 2.1194\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.7717 - mse: 1.7584 - val_loss: 2.1387 - val_mse: 2.1253\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.7679 - mse: 1.7545 - val_loss: 2.1354 - val_mse: 2.1220\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.7642 - mse: 1.7507 - val_loss: 2.1413 - val_mse: 2.1277\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.7608 - mse: 1.7472 - val_loss: 2.1407 - val_mse: 2.1270\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.7570 - mse: 1.7433 - val_loss: 2.1459 - val_mse: 2.1321\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.7542 - mse: 1.7403 - val_loss: 2.1476 - val_mse: 2.1337\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.7506 - mse: 1.7366 - val_loss: 2.1506 - val_mse: 2.1366\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.7471 - mse: 1.7330 - val_loss: 2.1553 - val_mse: 2.1412\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.7436 - mse: 1.7294 - val_loss: 2.1541 - val_mse: 2.1399\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.7406 - mse: 1.7263 - val_loss: 2.1613 - val_mse: 2.1469\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.7368 - mse: 1.7224 - val_loss: 2.1560 - val_mse: 2.1416\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.7332 - mse: 1.7187 - val_loss: 2.1594 - val_mse: 2.1449\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.7302 - mse: 1.7156 - val_loss: 2.1608 - val_mse: 2.1461\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.7273 - mse: 1.7126 - val_loss: 2.1660 - val_mse: 2.1512\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.7253 - mse: 1.7105 - val_loss: 2.1686 - val_mse: 2.1538\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.7222 - mse: 1.7073 - val_loss: 2.1737 - val_mse: 2.1587\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.7187 - mse: 1.7037 - val_loss: 2.1776 - val_mse: 2.1625\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.7169 - mse: 1.7019 - val_loss: 2.1771 - val_mse: 2.1619\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.7140 - mse: 1.6988 - val_loss: 2.1805 - val_mse: 2.1652\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.7111 - mse: 1.6958 - val_loss: 2.1880 - val_mse: 2.1727\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.7085 - mse: 1.6932 - val_loss: 2.1858 - val_mse: 2.1704\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.7054 - mse: 1.6899 - val_loss: 2.1898 - val_mse: 2.1742\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.7043 - mse: 1.6888 - val_loss: 2.1928 - val_mse: 2.1772\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.7021 - mse: 1.6864 - val_loss: 2.1896 - val_mse: 2.1739\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.6993 - mse: 1.6835 - val_loss: 2.1935 - val_mse: 2.1777\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.6974 - mse: 1.6816 - val_loss: 2.1969 - val_mse: 2.1810\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.6951 - mse: 1.6792 - val_loss: 2.1965 - val_mse: 2.1806\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.6916 - mse: 1.6756 - val_loss: 2.1995 - val_mse: 2.1835\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.6909 - mse: 1.6748 - val_loss: 2.2018 - val_mse: 2.1857\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.6884 - mse: 1.6722 - val_loss: 2.2049 - val_mse: 2.1887\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.6855 - mse: 1.6693 - val_loss: 2.2024 - val_mse: 2.1861\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.6840 - mse: 1.6677 - val_loss: 2.2072 - val_mse: 2.1908\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.6826 - mse: 1.6662 - val_loss: 2.2064 - val_mse: 2.1900\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.6807 - mse: 1.6642 - val_loss: 2.2126 - val_mse: 2.1960\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.6794 - mse: 1.6628 - val_loss: 2.2108 - val_mse: 2.1942\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.6758 - mse: 1.6592 - val_loss: 2.2090 - val_mse: 2.1923\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.6759 - mse: 1.6592 - val_loss: 2.2109 - val_mse: 2.1942\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.6735 - mse: 1.6567 - val_loss: 2.2142 - val_mse: 2.1974\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.6715 - mse: 1.6546 - val_loss: 2.2210 - val_mse: 2.2041\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.6699 - mse: 1.6529 - val_loss: 2.2167 - val_mse: 2.1997\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.6687 - mse: 1.6517 - val_loss: 2.2219 - val_mse: 2.2049\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.6675 - mse: 1.6504 - val_loss: 2.2215 - val_mse: 2.2043\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.6657 - mse: 1.6485 - val_loss: 2.2242 - val_mse: 2.2070\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.6643 - mse: 1.6471 - val_loss: 2.2257 - val_mse: 2.2084\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.6625 - mse: 1.6452 - val_loss: 2.2269 - val_mse: 2.2096\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.6608 - mse: 1.6434 - val_loss: 2.2293 - val_mse: 2.2119\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.6599 - mse: 1.6424 - val_loss: 2.2283 - val_mse: 2.2108\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.6596 - mse: 1.6421 - val_loss: 2.2287 - val_mse: 2.2111\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.6570 - mse: 1.6394 - val_loss: 2.2332 - val_mse: 2.2156\n",
      "Epoch 1/100\n",
      "438/438 - 3s - loss: 2.7903 - mse: 2.7901 - val_loss: 2.2525 - val_mse: 2.2522\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.1673 - mse: 2.1669 - val_loss: 2.2175 - val_mse: 2.2170\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.1069 - mse: 2.1064 - val_loss: 2.1819 - val_mse: 2.1814\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.0226 - mse: 2.0220 - val_loss: 2.1461 - val_mse: 2.1454\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 1.9378 - mse: 1.9370 - val_loss: 2.1110 - val_mse: 2.1102\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 1.8713 - mse: 1.8704 - val_loss: 2.0662 - val_mse: 2.0652\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 1.8220 - mse: 1.8211 - val_loss: 2.0657 - val_mse: 2.0647\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 1.7803 - mse: 1.7793 - val_loss: 2.0494 - val_mse: 2.0482\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 1.7517 - mse: 1.7505 - val_loss: 2.0675 - val_mse: 2.0663\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.7282 - mse: 1.7269 - val_loss: 2.0788 - val_mse: 2.0774\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.7065 - mse: 1.7052 - val_loss: 2.0429 - val_mse: 2.0414\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.6882 - mse: 1.6868 - val_loss: 2.0497 - val_mse: 2.0482\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.6729 - mse: 1.6714 - val_loss: 2.0443 - val_mse: 2.0427\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.6606 - mse: 1.6590 - val_loss: 2.0828 - val_mse: 2.0811\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.6509 - mse: 1.6491 - val_loss: 2.0963 - val_mse: 2.0945\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 1.6370 - mse: 1.6352 - val_loss: 2.0789 - val_mse: 2.0770\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 1.6309 - mse: 1.6290 - val_loss: 2.0734 - val_mse: 2.0714\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.6226 - mse: 1.6206 - val_loss: 2.0981 - val_mse: 2.0960\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.6143 - mse: 1.6122 - val_loss: 2.0791 - val_mse: 2.0769\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.5994 - mse: 1.5972 - val_loss: 2.0977 - val_mse: 2.0954\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.5959 - mse: 1.5936 - val_loss: 2.1030 - val_mse: 2.1006\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.5895 - mse: 1.5871 - val_loss: 2.1053 - val_mse: 2.1028\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.5823 - mse: 1.5798 - val_loss: 2.1303 - val_mse: 2.1277\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.5748 - mse: 1.5722 - val_loss: 2.1118 - val_mse: 2.1091\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.5673 - mse: 1.5646 - val_loss: 2.1056 - val_mse: 2.1028\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.5606 - mse: 1.5578 - val_loss: 2.1220 - val_mse: 2.1192\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.5547 - mse: 1.5518 - val_loss: 2.1250 - val_mse: 2.1221\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.5514 - mse: 1.5485 - val_loss: 2.1386 - val_mse: 2.1356\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.5436 - mse: 1.5406 - val_loss: 2.1300 - val_mse: 2.1269\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.5429 - mse: 1.5398 - val_loss: 2.1277 - val_mse: 2.1245\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.5347 - mse: 1.5315 - val_loss: 2.1454 - val_mse: 2.1422\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.5286 - mse: 1.5254 - val_loss: 2.1774 - val_mse: 2.1741\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.5241 - mse: 1.5208 - val_loss: 2.1862 - val_mse: 2.1828\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.5189 - mse: 1.5155 - val_loss: 2.1463 - val_mse: 2.1428\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.5122 - mse: 1.5087 - val_loss: 2.1727 - val_mse: 2.1692\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.5131 - mse: 1.5095 - val_loss: 2.1783 - val_mse: 2.1747\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.5073 - mse: 1.5037 - val_loss: 2.2305 - val_mse: 2.2268\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.5057 - mse: 1.5020 - val_loss: 2.1994 - val_mse: 2.1957\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.4995 - mse: 1.4957 - val_loss: 2.1722 - val_mse: 2.1684\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.4959 - mse: 1.4921 - val_loss: 2.2338 - val_mse: 2.2300\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.4911 - mse: 1.4873 - val_loss: 2.2430 - val_mse: 2.2390\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.4920 - mse: 1.4880 - val_loss: 2.2055 - val_mse: 2.2016\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.4856 - mse: 1.4815 - val_loss: 2.2105 - val_mse: 2.2065\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.4842 - mse: 1.4801 - val_loss: 2.2598 - val_mse: 2.2556\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.4754 - mse: 1.4712 - val_loss: 2.2604 - val_mse: 2.2562\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.4765 - mse: 1.4723 - val_loss: 2.2499 - val_mse: 2.2456\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.4757 - mse: 1.4714 - val_loss: 2.2294 - val_mse: 2.2251\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.4691 - mse: 1.4647 - val_loss: 2.2706 - val_mse: 2.2662\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.4673 - mse: 1.4629 - val_loss: 2.2500 - val_mse: 2.2456\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.4644 - mse: 1.4599 - val_loss: 2.2531 - val_mse: 2.2486\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.4620 - mse: 1.4575 - val_loss: 2.2304 - val_mse: 2.2258\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.4564 - mse: 1.4518 - val_loss: 2.2732 - val_mse: 2.2685\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.4573 - mse: 1.4527 - val_loss: 2.2371 - val_mse: 2.2324\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.4528 - mse: 1.4481 - val_loss: 2.2581 - val_mse: 2.2534\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.4470 - mse: 1.4422 - val_loss: 2.3097 - val_mse: 2.3049\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.4497 - mse: 1.4449 - val_loss: 2.2674 - val_mse: 2.2626\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.4433 - mse: 1.4385 - val_loss: 2.2830 - val_mse: 2.2781\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.4418 - mse: 1.4369 - val_loss: 2.2872 - val_mse: 2.2822\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.4401 - mse: 1.4351 - val_loss: 2.2871 - val_mse: 2.2821\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.4356 - mse: 1.4306 - val_loss: 2.3110 - val_mse: 2.3059\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.4364 - mse: 1.4313 - val_loss: 2.2975 - val_mse: 2.2924\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.4345 - mse: 1.4293 - val_loss: 2.2867 - val_mse: 2.2815\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.4324 - mse: 1.4272 - val_loss: 2.3336 - val_mse: 2.3284\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.4295 - mse: 1.4242 - val_loss: 2.2970 - val_mse: 2.2917\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.4270 - mse: 1.4217 - val_loss: 2.3335 - val_mse: 2.3281\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.4262 - mse: 1.4209 - val_loss: 2.2863 - val_mse: 2.2809\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.4226 - mse: 1.4172 - val_loss: 2.3125 - val_mse: 2.3070\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.4209 - mse: 1.4154 - val_loss: 2.3023 - val_mse: 2.2968\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.4197 - mse: 1.4141 - val_loss: 2.3130 - val_mse: 2.3075\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.4197 - mse: 1.4142 - val_loss: 2.2967 - val_mse: 2.2911\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.4154 - mse: 1.4098 - val_loss: 2.3299 - val_mse: 2.3242\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.4155 - mse: 1.4098 - val_loss: 2.3033 - val_mse: 2.2976\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.4100 - mse: 1.4043 - val_loss: 2.3045 - val_mse: 2.2987\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.4088 - mse: 1.4030 - val_loss: 2.3162 - val_mse: 2.3104\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.4093 - mse: 1.4035 - val_loss: 2.3330 - val_mse: 2.3271\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.4017 - mse: 1.3958 - val_loss: 2.3124 - val_mse: 2.3065\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.4065 - mse: 1.4006 - val_loss: 2.3161 - val_mse: 2.3101\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.4042 - mse: 1.3982 - val_loss: 2.3322 - val_mse: 2.3262\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.4000 - mse: 1.3940 - val_loss: 2.3174 - val_mse: 2.3114\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.3951 - mse: 1.3890 - val_loss: 2.3158 - val_mse: 2.3097\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.3967 - mse: 1.3906 - val_loss: 2.3180 - val_mse: 2.3118\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.3969 - mse: 1.3907 - val_loss: 2.3574 - val_mse: 2.3512\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.3948 - mse: 1.3885 - val_loss: 2.3759 - val_mse: 2.3696\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.3928 - mse: 1.3865 - val_loss: 2.2872 - val_mse: 2.2808\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.3905 - mse: 1.3842 - val_loss: 2.3647 - val_mse: 2.3584\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.3870 - mse: 1.3806 - val_loss: 2.3280 - val_mse: 2.3216\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.3867 - mse: 1.3803 - val_loss: 2.3780 - val_mse: 2.3715\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.3863 - mse: 1.3798 - val_loss: 2.3374 - val_mse: 2.3309\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.3820 - mse: 1.3755 - val_loss: 2.3510 - val_mse: 2.3444\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.3805 - mse: 1.3739 - val_loss: 2.4241 - val_mse: 2.4175\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.3808 - mse: 1.3742 - val_loss: 2.3140 - val_mse: 2.3074\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.3787 - mse: 1.3720 - val_loss: 2.3440 - val_mse: 2.3373\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.3733 - mse: 1.3666 - val_loss: 2.3539 - val_mse: 2.3471\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.3751 - mse: 1.3683 - val_loss: 2.3392 - val_mse: 2.3324\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.3735 - mse: 1.3667 - val_loss: 2.3719 - val_mse: 2.3651\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.3721 - mse: 1.3653 - val_loss: 2.3743 - val_mse: 2.3674\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.3705 - mse: 1.3636 - val_loss: 2.3665 - val_mse: 2.3595\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.3726 - mse: 1.3656 - val_loss: 2.3374 - val_mse: 2.3305\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.3642 - mse: 1.3572 - val_loss: 2.3408 - val_mse: 2.3338\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.3655 - mse: 1.3585 - val_loss: 2.3657 - val_mse: 2.3586\n",
      "[1/5 Cross Validation]\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_1/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 4.7616 - mse: 4.7606 - val_loss: 3.1387 - val_mse: 3.1360\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.5618 - mse: 2.5576 - val_loss: 2.3224 - val_mse: 2.3170\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.2007 - mse: 2.1950 - val_loss: 2.2481 - val_mse: 2.2422\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.1210 - mse: 2.1150 - val_loss: 2.2057 - val_mse: 2.1996\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 2.0728 - mse: 2.0665 - val_loss: 2.1868 - val_mse: 2.1804\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 2.0431 - mse: 2.0366 - val_loss: 2.1681 - val_mse: 2.1614\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 2.0212 - mse: 2.0144 - val_loss: 2.1582 - val_mse: 2.1513\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 2.0018 - mse: 1.9948 - val_loss: 2.1502 - val_mse: 2.1432\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 1.9866 - mse: 1.9795 - val_loss: 2.1452 - val_mse: 2.1379\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.9725 - mse: 1.9652 - val_loss: 2.1383 - val_mse: 2.1308\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.9602 - mse: 1.9526 - val_loss: 2.1344 - val_mse: 2.1268\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.9495 - mse: 1.9417 - val_loss: 2.1310 - val_mse: 2.1232\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.9391 - mse: 1.9311 - val_loss: 2.1262 - val_mse: 2.1182\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.9291 - mse: 1.9210 - val_loss: 2.1234 - val_mse: 2.1152\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.9194 - mse: 1.9111 - val_loss: 2.1195 - val_mse: 2.1111\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 1.9110 - mse: 1.9025 - val_loss: 2.1188 - val_mse: 2.1102\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 1.9022 - mse: 1.8935 - val_loss: 2.1174 - val_mse: 2.1087\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.8942 - mse: 1.8853 - val_loss: 2.1190 - val_mse: 2.1101\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.8866 - mse: 1.8775 - val_loss: 2.1154 - val_mse: 2.1063\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.8796 - mse: 1.8704 - val_loss: 2.1165 - val_mse: 2.1073\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.8720 - mse: 1.8626 - val_loss: 2.1141 - val_mse: 2.1046\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.8656 - mse: 1.8561 - val_loss: 2.1124 - val_mse: 2.1028\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.8594 - mse: 1.8498 - val_loss: 2.1142 - val_mse: 2.1045\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.8534 - mse: 1.8436 - val_loss: 2.1149 - val_mse: 2.1050\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.8484 - mse: 1.8385 - val_loss: 2.1175 - val_mse: 2.1075\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.8439 - mse: 1.8338 - val_loss: 2.1162 - val_mse: 2.1061\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.8383 - mse: 1.8281 - val_loss: 2.1128 - val_mse: 2.1025\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.8342 - mse: 1.8239 - val_loss: 2.1148 - val_mse: 2.1044\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.8287 - mse: 1.8182 - val_loss: 2.1165 - val_mse: 2.1059\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.8248 - mse: 1.8142 - val_loss: 2.1166 - val_mse: 2.1060\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.8208 - mse: 1.8101 - val_loss: 2.1197 - val_mse: 2.1090\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.8165 - mse: 1.8056 - val_loss: 2.1169 - val_mse: 2.1060\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.8133 - mse: 1.8024 - val_loss: 2.1152 - val_mse: 2.1041\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.8101 - mse: 1.7990 - val_loss: 2.1136 - val_mse: 2.1025\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.8067 - mse: 1.7955 - val_loss: 2.1151 - val_mse: 2.1038\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.8032 - mse: 1.7918 - val_loss: 2.1192 - val_mse: 2.1078\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.8001 - mse: 1.7887 - val_loss: 2.1212 - val_mse: 2.1097\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.7972 - mse: 1.7856 - val_loss: 2.1173 - val_mse: 2.1057\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.7942 - mse: 1.7825 - val_loss: 2.1220 - val_mse: 2.1103\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.7902 - mse: 1.7784 - val_loss: 2.1180 - val_mse: 2.1062\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.7880 - mse: 1.7761 - val_loss: 2.1198 - val_mse: 2.1079\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.7854 - mse: 1.7734 - val_loss: 2.1203 - val_mse: 2.1083\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.7821 - mse: 1.7700 - val_loss: 2.1186 - val_mse: 2.1064\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.7794 - mse: 1.7672 - val_loss: 2.1219 - val_mse: 2.1097\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.7774 - mse: 1.7651 - val_loss: 2.1280 - val_mse: 2.1157\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.7752 - mse: 1.7628 - val_loss: 2.1196 - val_mse: 2.1071\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.7721 - mse: 1.7597 - val_loss: 2.1238 - val_mse: 2.1112\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.7692 - mse: 1.7566 - val_loss: 2.1221 - val_mse: 2.1094\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.7672 - mse: 1.7546 - val_loss: 2.1230 - val_mse: 2.1103\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.7649 - mse: 1.7522 - val_loss: 2.1204 - val_mse: 2.1076\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.7629 - mse: 1.7501 - val_loss: 2.1254 - val_mse: 2.1125\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.7597 - mse: 1.7468 - val_loss: 2.1278 - val_mse: 2.1149\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.7579 - mse: 1.7448 - val_loss: 2.1261 - val_mse: 2.1131\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.7557 - mse: 1.7425 - val_loss: 2.1281 - val_mse: 2.1149\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.7536 - mse: 1.7404 - val_loss: 2.1285 - val_mse: 2.1153\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.7510 - mse: 1.7377 - val_loss: 2.1295 - val_mse: 2.1161\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.7487 - mse: 1.7353 - val_loss: 2.1338 - val_mse: 2.1203\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.7459 - mse: 1.7324 - val_loss: 2.1449 - val_mse: 2.1314\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.7427 - mse: 1.7292 - val_loss: 2.1407 - val_mse: 2.1271\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.7407 - mse: 1.7270 - val_loss: 2.1376 - val_mse: 2.1239\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.7378 - mse: 1.7240 - val_loss: 2.1396 - val_mse: 2.1258\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.7339 - mse: 1.7201 - val_loss: 2.1436 - val_mse: 2.1298\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.7318 - mse: 1.7179 - val_loss: 2.1464 - val_mse: 2.1325\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.7295 - mse: 1.7156 - val_loss: 2.1441 - val_mse: 2.1301\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.7259 - mse: 1.7119 - val_loss: 2.1528 - val_mse: 2.1388\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.7237 - mse: 1.7096 - val_loss: 2.1524 - val_mse: 2.1383\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.7199 - mse: 1.7058 - val_loss: 2.1566 - val_mse: 2.1424\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.7171 - mse: 1.7028 - val_loss: 2.1582 - val_mse: 2.1439\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.7149 - mse: 1.7006 - val_loss: 2.1576 - val_mse: 2.1432\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.7119 - mse: 1.6975 - val_loss: 2.1629 - val_mse: 2.1485\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.7088 - mse: 1.6943 - val_loss: 2.1599 - val_mse: 2.1454\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.7062 - mse: 1.6917 - val_loss: 2.1605 - val_mse: 2.1459\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.7037 - mse: 1.6891 - val_loss: 2.1680 - val_mse: 2.1534\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.7017 - mse: 1.6870 - val_loss: 2.1730 - val_mse: 2.1583\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.6983 - mse: 1.6835 - val_loss: 2.1740 - val_mse: 2.1592\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.6974 - mse: 1.6825 - val_loss: 2.1766 - val_mse: 2.1617\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.6946 - mse: 1.6797 - val_loss: 2.1746 - val_mse: 2.1596\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.6916 - mse: 1.6766 - val_loss: 2.1817 - val_mse: 2.1667\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.6902 - mse: 1.6751 - val_loss: 2.1844 - val_mse: 2.1693\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.6885 - mse: 1.6733 - val_loss: 2.1853 - val_mse: 2.1701\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.6848 - mse: 1.6696 - val_loss: 2.1910 - val_mse: 2.1757\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.6839 - mse: 1.6687 - val_loss: 2.1945 - val_mse: 2.1792\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.6817 - mse: 1.6663 - val_loss: 2.1863 - val_mse: 2.1709\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.6787 - mse: 1.6633 - val_loss: 2.1949 - val_mse: 2.1794\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.6780 - mse: 1.6625 - val_loss: 2.1961 - val_mse: 2.1806\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.6756 - mse: 1.6601 - val_loss: 2.2014 - val_mse: 2.1859\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.6731 - mse: 1.6575 - val_loss: 2.2002 - val_mse: 2.1845\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.6720 - mse: 1.6563 - val_loss: 2.2041 - val_mse: 2.1884\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.6709 - mse: 1.6552 - val_loss: 2.2084 - val_mse: 2.1926\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.6688 - mse: 1.6530 - val_loss: 2.2062 - val_mse: 2.1903\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.6663 - mse: 1.6505 - val_loss: 2.2124 - val_mse: 2.1966\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.6645 - mse: 1.6486 - val_loss: 2.2109 - val_mse: 2.1950\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.6635 - mse: 1.6475 - val_loss: 2.2142 - val_mse: 2.1982\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.6628 - mse: 1.6467 - val_loss: 2.2162 - val_mse: 2.2002\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.6610 - mse: 1.6448 - val_loss: 2.2191 - val_mse: 2.2029\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.6592 - mse: 1.6430 - val_loss: 2.2201 - val_mse: 2.2039\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.6575 - mse: 1.6412 - val_loss: 2.2220 - val_mse: 2.2057\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.6553 - mse: 1.6390 - val_loss: 2.2212 - val_mse: 2.2049\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.6558 - mse: 1.6395 - val_loss: 2.2244 - val_mse: 2.2080\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.6529 - mse: 1.6365 - val_loss: 2.2249 - val_mse: 2.2085\n",
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 2.8396 - mse: 2.8394 - val_loss: 2.2648 - val_mse: 2.2645\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.1722 - mse: 2.1718 - val_loss: 2.2399 - val_mse: 2.2395\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.1085 - mse: 2.1080 - val_loss: 2.1985 - val_mse: 2.1980\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.0333 - mse: 2.0327 - val_loss: 2.1579 - val_mse: 2.1572\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 1.9580 - mse: 1.9573 - val_loss: 2.1361 - val_mse: 2.1353\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 1.8897 - mse: 1.8888 - val_loss: 2.1221 - val_mse: 2.1212\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 1.8347 - mse: 1.8337 - val_loss: 2.1007 - val_mse: 2.0997\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 1.7894 - mse: 1.7882 - val_loss: 2.0699 - val_mse: 2.0687\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 1.7571 - mse: 1.7559 - val_loss: 2.1249 - val_mse: 2.1236\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.7313 - mse: 1.7300 - val_loss: 2.1015 - val_mse: 2.1002\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.7101 - mse: 1.7087 - val_loss: 2.0767 - val_mse: 2.0752\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.6919 - mse: 1.6904 - val_loss: 2.0845 - val_mse: 2.0829\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.6715 - mse: 1.6699 - val_loss: 2.0922 - val_mse: 2.0905\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.6573 - mse: 1.6556 - val_loss: 2.0922 - val_mse: 2.0905\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.6444 - mse: 1.6426 - val_loss: 2.1020 - val_mse: 2.1001\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 1.6323 - mse: 1.6303 - val_loss: 2.1079 - val_mse: 2.1059\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 1.6196 - mse: 1.6176 - val_loss: 2.1150 - val_mse: 2.1129\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.6103 - mse: 1.6082 - val_loss: 2.1314 - val_mse: 2.1292\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.6018 - mse: 1.5995 - val_loss: 2.1230 - val_mse: 2.1207\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.5932 - mse: 1.5909 - val_loss: 2.1183 - val_mse: 2.1159\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.5830 - mse: 1.5806 - val_loss: 2.1091 - val_mse: 2.1066\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.5720 - mse: 1.5695 - val_loss: 2.1372 - val_mse: 2.1346\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.5679 - mse: 1.5653 - val_loss: 2.1682 - val_mse: 2.1655\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.5577 - mse: 1.5550 - val_loss: 2.1688 - val_mse: 2.1660\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.5512 - mse: 1.5483 - val_loss: 2.1704 - val_mse: 2.1676\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.5409 - mse: 1.5380 - val_loss: 2.1697 - val_mse: 2.1667\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.5340 - mse: 1.5310 - val_loss: 2.1881 - val_mse: 2.1851\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.5343 - mse: 1.5312 - val_loss: 2.1810 - val_mse: 2.1778\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.5248 - mse: 1.5217 - val_loss: 2.2126 - val_mse: 2.2094\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.5204 - mse: 1.5172 - val_loss: 2.2130 - val_mse: 2.2097\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.5119 - mse: 1.5085 - val_loss: 2.2176 - val_mse: 2.2142\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.5086 - mse: 1.5052 - val_loss: 2.2448 - val_mse: 2.2413\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.5005 - mse: 1.4970 - val_loss: 2.2042 - val_mse: 2.2007\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.4983 - mse: 1.4947 - val_loss: 2.2281 - val_mse: 2.2245\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.4933 - mse: 1.4896 - val_loss: 2.2113 - val_mse: 2.2076\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.4879 - mse: 1.4842 - val_loss: 2.2500 - val_mse: 2.2462\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.4823 - mse: 1.4785 - val_loss: 2.2457 - val_mse: 2.2419\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.4781 - mse: 1.4742 - val_loss: 2.2715 - val_mse: 2.2676\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.4742 - mse: 1.4703 - val_loss: 2.2972 - val_mse: 2.2932\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.4727 - mse: 1.4686 - val_loss: 2.2628 - val_mse: 2.2588\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.4637 - mse: 1.4596 - val_loss: 2.2259 - val_mse: 2.2217\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.4592 - mse: 1.4550 - val_loss: 2.3008 - val_mse: 2.2966\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.4599 - mse: 1.4557 - val_loss: 2.2522 - val_mse: 2.2479\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.4534 - mse: 1.4490 - val_loss: 2.2558 - val_mse: 2.2515\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.4512 - mse: 1.4468 - val_loss: 2.2331 - val_mse: 2.2287\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.4482 - mse: 1.4438 - val_loss: 2.2694 - val_mse: 2.2649\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.4399 - mse: 1.4354 - val_loss: 2.2217 - val_mse: 2.2171\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.4382 - mse: 1.4336 - val_loss: 2.2967 - val_mse: 2.2922\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.4359 - mse: 1.4313 - val_loss: 2.3139 - val_mse: 2.3093\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.4338 - mse: 1.4292 - val_loss: 2.2471 - val_mse: 2.2424\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.4282 - mse: 1.4234 - val_loss: 2.2866 - val_mse: 2.2819\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.4238 - mse: 1.4190 - val_loss: 2.3084 - val_mse: 2.3036\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.4226 - mse: 1.4177 - val_loss: 2.3007 - val_mse: 2.2958\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.4155 - mse: 1.4106 - val_loss: 2.3202 - val_mse: 2.3153\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.4173 - mse: 1.4123 - val_loss: 2.3005 - val_mse: 2.2955\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.4136 - mse: 1.4086 - val_loss: 2.3009 - val_mse: 2.2958\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.4104 - mse: 1.4053 - val_loss: 2.3159 - val_mse: 2.3108\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.4069 - mse: 1.4018 - val_loss: 2.3015 - val_mse: 2.2964\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.4058 - mse: 1.4006 - val_loss: 2.3237 - val_mse: 2.3185\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.4024 - mse: 1.3972 - val_loss: 2.3205 - val_mse: 2.3152\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.4005 - mse: 1.3952 - val_loss: 2.2976 - val_mse: 2.2922\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.3975 - mse: 1.3921 - val_loss: 2.2884 - val_mse: 2.2830\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.3967 - mse: 1.3913 - val_loss: 2.3066 - val_mse: 2.3011\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.3917 - mse: 1.3863 - val_loss: 2.3373 - val_mse: 2.3318\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.3914 - mse: 1.3858 - val_loss: 2.3291 - val_mse: 2.3235\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.3890 - mse: 1.3835 - val_loss: 2.3192 - val_mse: 2.3136\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.3868 - mse: 1.3812 - val_loss: 2.3071 - val_mse: 2.3015\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.3878 - mse: 1.3821 - val_loss: 2.3031 - val_mse: 2.2974\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.3814 - mse: 1.3757 - val_loss: 2.3423 - val_mse: 2.3365\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.3828 - mse: 1.3770 - val_loss: 2.3265 - val_mse: 2.3207\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.3803 - mse: 1.3744 - val_loss: 2.3377 - val_mse: 2.3318\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.3752 - mse: 1.3693 - val_loss: 2.3423 - val_mse: 2.3364\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.3785 - mse: 1.3725 - val_loss: 2.2960 - val_mse: 2.2900\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.3787 - mse: 1.3727 - val_loss: 2.3657 - val_mse: 2.3597\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.3705 - mse: 1.3644 - val_loss: 2.3513 - val_mse: 2.3452\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.3705 - mse: 1.3644 - val_loss: 2.3683 - val_mse: 2.3622\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.3702 - mse: 1.3640 - val_loss: 2.3288 - val_mse: 2.3226\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.3655 - mse: 1.3593 - val_loss: 2.3438 - val_mse: 2.3375\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.3651 - mse: 1.3588 - val_loss: 2.3705 - val_mse: 2.3642\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.3639 - mse: 1.3576 - val_loss: 2.3634 - val_mse: 2.3571\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.3623 - mse: 1.3560 - val_loss: 2.3449 - val_mse: 2.3385\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.3602 - mse: 1.3538 - val_loss: 2.3635 - val_mse: 2.3571\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.3577 - mse: 1.3513 - val_loss: 2.3769 - val_mse: 2.3704\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.3578 - mse: 1.3513 - val_loss: 2.4102 - val_mse: 2.4036\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.3552 - mse: 1.3487 - val_loss: 2.3904 - val_mse: 2.3838\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.3551 - mse: 1.3485 - val_loss: 2.3483 - val_mse: 2.3416\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.3525 - mse: 1.3459 - val_loss: 2.4437 - val_mse: 2.4370\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.3485 - mse: 1.3417 - val_loss: 2.3771 - val_mse: 2.3703\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.3486 - mse: 1.3418 - val_loss: 2.3597 - val_mse: 2.3529\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.3441 - mse: 1.3373 - val_loss: 2.4164 - val_mse: 2.4095\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.3476 - mse: 1.3408 - val_loss: 2.3692 - val_mse: 2.3623\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.3449 - mse: 1.3380 - val_loss: 2.4118 - val_mse: 2.4048\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.3406 - mse: 1.3337 - val_loss: 2.4220 - val_mse: 2.4150\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.3418 - mse: 1.3348 - val_loss: 2.4076 - val_mse: 2.4006\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.3373 - mse: 1.3303 - val_loss: 2.4366 - val_mse: 2.4296\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.3390 - mse: 1.3319 - val_loss: 2.3693 - val_mse: 2.3622\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.3341 - mse: 1.3269 - val_loss: 2.3833 - val_mse: 2.3761\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.3371 - mse: 1.3299 - val_loss: 2.4484 - val_mse: 2.4411\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.3329 - mse: 1.3256 - val_loss: 2.3738 - val_mse: 2.3665\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.3319 - mse: 1.3245 - val_loss: 2.3747 - val_mse: 2.3674\n",
      "[2/5 Cross Validation]\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_2/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 4.7726 - mse: 4.7715 - val_loss: 3.1296 - val_mse: 3.1270\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.5524 - mse: 2.5481 - val_loss: 2.3801 - val_mse: 2.3749\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.2766 - mse: 2.2711 - val_loss: 2.3307 - val_mse: 2.3250\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.2266 - mse: 2.2207 - val_loss: 2.3014 - val_mse: 2.2953\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 2.1935 - mse: 2.1872 - val_loss: 2.2807 - val_mse: 2.2742\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 2.1653 - mse: 2.1586 - val_loss: 2.2604 - val_mse: 2.2536\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 2.1401 - mse: 2.1331 - val_loss: 2.2399 - val_mse: 2.2329\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 2.1163 - mse: 2.1091 - val_loss: 2.2252 - val_mse: 2.2179\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 2.0960 - mse: 2.0885 - val_loss: 2.2111 - val_mse: 2.2036\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 2.0796 - mse: 2.0719 - val_loss: 2.2003 - val_mse: 2.1925\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 2.0651 - mse: 2.0572 - val_loss: 2.1963 - val_mse: 2.1883\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 2.0534 - mse: 2.0453 - val_loss: 2.1861 - val_mse: 2.1780\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 2.0421 - mse: 2.0338 - val_loss: 2.1812 - val_mse: 2.1729\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 2.0315 - mse: 2.0231 - val_loss: 2.1724 - val_mse: 2.1639\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 2.0218 - mse: 2.0132 - val_loss: 2.1683 - val_mse: 2.1597\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 2.0128 - mse: 2.0041 - val_loss: 2.1642 - val_mse: 2.1554\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 2.0031 - mse: 1.9942 - val_loss: 2.1568 - val_mse: 2.1478\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.9934 - mse: 1.9843 - val_loss: 2.1532 - val_mse: 2.1441\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.9856 - mse: 1.9764 - val_loss: 2.1486 - val_mse: 2.1393\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.9773 - mse: 1.9679 - val_loss: 2.1434 - val_mse: 2.1339\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.9687 - mse: 1.9591 - val_loss: 2.1416 - val_mse: 2.1319\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.9605 - mse: 1.9508 - val_loss: 2.1362 - val_mse: 2.1264\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.9522 - mse: 1.9423 - val_loss: 2.1334 - val_mse: 2.1235\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.9441 - mse: 1.9341 - val_loss: 2.1335 - val_mse: 2.1234\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.9370 - mse: 1.9268 - val_loss: 2.1277 - val_mse: 2.1175\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.9288 - mse: 1.9184 - val_loss: 2.1277 - val_mse: 2.1172\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.9215 - mse: 1.9109 - val_loss: 2.1286 - val_mse: 2.1180\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.9131 - mse: 1.9024 - val_loss: 2.1253 - val_mse: 2.1145\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.9054 - mse: 1.8945 - val_loss: 2.1227 - val_mse: 2.1117\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.8978 - mse: 1.8867 - val_loss: 2.1209 - val_mse: 2.1098\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.8897 - mse: 1.8785 - val_loss: 2.1223 - val_mse: 2.1110\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.8830 - mse: 1.8716 - val_loss: 2.1173 - val_mse: 2.1058\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.8747 - mse: 1.8631 - val_loss: 2.1186 - val_mse: 2.1069\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.8670 - mse: 1.8552 - val_loss: 2.1168 - val_mse: 2.1050\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.8595 - mse: 1.8476 - val_loss: 2.1186 - val_mse: 2.1066\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.8529 - mse: 1.8408 - val_loss: 2.1180 - val_mse: 2.1058\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.8452 - mse: 1.8329 - val_loss: 2.1181 - val_mse: 2.1057\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.8376 - mse: 1.8252 - val_loss: 2.1211 - val_mse: 2.1086\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.8307 - mse: 1.8181 - val_loss: 2.1229 - val_mse: 2.1103\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.8237 - mse: 1.8109 - val_loss: 2.1192 - val_mse: 2.1063\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.8171 - mse: 1.8041 - val_loss: 2.1211 - val_mse: 2.1081\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.8105 - mse: 1.7974 - val_loss: 2.1201 - val_mse: 2.1069\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.8044 - mse: 1.7912 - val_loss: 2.1228 - val_mse: 2.1095\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.7982 - mse: 1.7848 - val_loss: 2.1225 - val_mse: 2.1091\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.7929 - mse: 1.7794 - val_loss: 2.1284 - val_mse: 2.1148\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.7876 - mse: 1.7739 - val_loss: 2.1293 - val_mse: 2.1156\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.7818 - mse: 1.7680 - val_loss: 2.1325 - val_mse: 2.1186\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.7769 - mse: 1.7629 - val_loss: 2.1319 - val_mse: 2.1179\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.7719 - mse: 1.7579 - val_loss: 2.1338 - val_mse: 2.1197\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.7667 - mse: 1.7525 - val_loss: 2.1357 - val_mse: 2.1215\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.7620 - mse: 1.7477 - val_loss: 2.1415 - val_mse: 2.1271\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.7580 - mse: 1.7435 - val_loss: 2.1403 - val_mse: 2.1258\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.7535 - mse: 1.7390 - val_loss: 2.1378 - val_mse: 2.1232\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.7502 - mse: 1.7355 - val_loss: 2.1443 - val_mse: 2.1296\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.7451 - mse: 1.7304 - val_loss: 2.1473 - val_mse: 2.1325\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.7417 - mse: 1.7268 - val_loss: 2.1469 - val_mse: 2.1319\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.7375 - mse: 1.7224 - val_loss: 2.1532 - val_mse: 2.1381\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.7331 - mse: 1.7180 - val_loss: 2.1521 - val_mse: 2.1369\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.7294 - mse: 1.7142 - val_loss: 2.1572 - val_mse: 2.1420\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.7266 - mse: 1.7112 - val_loss: 2.1565 - val_mse: 2.1411\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.7229 - mse: 1.7074 - val_loss: 2.1632 - val_mse: 2.1477\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.7186 - mse: 1.7030 - val_loss: 2.1691 - val_mse: 2.1534\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.7154 - mse: 1.6997 - val_loss: 2.1669 - val_mse: 2.1511\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.7116 - mse: 1.6958 - val_loss: 2.1690 - val_mse: 2.1532\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.7084 - mse: 1.6925 - val_loss: 2.1720 - val_mse: 2.1561\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.7057 - mse: 1.6897 - val_loss: 2.1758 - val_mse: 2.1597\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.7022 - mse: 1.6861 - val_loss: 2.1708 - val_mse: 2.1547\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.6993 - mse: 1.6831 - val_loss: 2.1789 - val_mse: 2.1627\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.6961 - mse: 1.6798 - val_loss: 2.1838 - val_mse: 2.1674\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.6933 - mse: 1.6769 - val_loss: 2.1881 - val_mse: 2.1716\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.6901 - mse: 1.6736 - val_loss: 2.1898 - val_mse: 2.1733\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.6875 - mse: 1.6709 - val_loss: 2.1883 - val_mse: 2.1716\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.6844 - mse: 1.6677 - val_loss: 2.1944 - val_mse: 2.1776\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.6823 - mse: 1.6655 - val_loss: 2.1937 - val_mse: 2.1769\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.6790 - mse: 1.6621 - val_loss: 2.1962 - val_mse: 2.1792\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.6767 - mse: 1.6596 - val_loss: 2.1952 - val_mse: 2.1781\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.6745 - mse: 1.6574 - val_loss: 2.2058 - val_mse: 2.1886\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.6716 - mse: 1.6544 - val_loss: 2.2041 - val_mse: 2.1868\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.6697 - mse: 1.6524 - val_loss: 2.2059 - val_mse: 2.1886\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.6669 - mse: 1.6495 - val_loss: 2.2097 - val_mse: 2.1923\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.6636 - mse: 1.6461 - val_loss: 2.2089 - val_mse: 2.1913\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.6623 - mse: 1.6447 - val_loss: 2.2121 - val_mse: 2.1945\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.6597 - mse: 1.6420 - val_loss: 2.2157 - val_mse: 2.1980\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.6573 - mse: 1.6395 - val_loss: 2.2189 - val_mse: 2.2011\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.6553 - mse: 1.6374 - val_loss: 2.2200 - val_mse: 2.2020\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.6542 - mse: 1.6363 - val_loss: 2.2202 - val_mse: 2.2022\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.6506 - mse: 1.6326 - val_loss: 2.2185 - val_mse: 2.2004\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.6489 - mse: 1.6308 - val_loss: 2.2235 - val_mse: 2.2053\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.6469 - mse: 1.6287 - val_loss: 2.2254 - val_mse: 2.2071\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.6442 - mse: 1.6259 - val_loss: 2.2329 - val_mse: 2.2146\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.6429 - mse: 1.6245 - val_loss: 2.2353 - val_mse: 2.2169\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.6397 - mse: 1.6211 - val_loss: 2.2389 - val_mse: 2.2203\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.6387 - mse: 1.6201 - val_loss: 2.2390 - val_mse: 2.2204\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.6365 - mse: 1.6178 - val_loss: 2.2385 - val_mse: 2.2197\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.6352 - mse: 1.6164 - val_loss: 2.2421 - val_mse: 2.2233\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.6331 - mse: 1.6142 - val_loss: 2.2410 - val_mse: 2.2220\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.6313 - mse: 1.6124 - val_loss: 2.2408 - val_mse: 2.2218\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.6300 - mse: 1.6110 - val_loss: 2.2484 - val_mse: 2.2294\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.6276 - mse: 1.6085 - val_loss: 2.2513 - val_mse: 2.2321\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.6266 - mse: 1.6074 - val_loss: 2.2562 - val_mse: 2.2370\n",
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 2.8037 - mse: 2.8035 - val_loss: 2.2950 - val_mse: 2.2947\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.1857 - mse: 2.1853 - val_loss: 2.2711 - val_mse: 2.2707\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.1251 - mse: 2.1246 - val_loss: 2.2065 - val_mse: 2.2060\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.0629 - mse: 2.0623 - val_loss: 2.1607 - val_mse: 2.1601\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 2.0033 - mse: 2.0026 - val_loss: 2.1429 - val_mse: 2.1422\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 1.9423 - mse: 1.9415 - val_loss: 2.1651 - val_mse: 2.1643\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 1.8961 - mse: 1.8951 - val_loss: 2.1088 - val_mse: 2.1078\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 1.8523 - mse: 1.8513 - val_loss: 2.0871 - val_mse: 2.0860\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 1.8177 - mse: 1.8165 - val_loss: 2.0599 - val_mse: 2.0587\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.7891 - mse: 1.7878 - val_loss: 2.1374 - val_mse: 2.1361\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.7643 - mse: 1.7630 - val_loss: 2.0630 - val_mse: 2.0616\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.7437 - mse: 1.7423 - val_loss: 2.0806 - val_mse: 2.0791\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.7222 - mse: 1.7206 - val_loss: 2.0810 - val_mse: 2.0794\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.7048 - mse: 1.7031 - val_loss: 2.0703 - val_mse: 2.0686\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.6949 - mse: 1.6932 - val_loss: 2.0774 - val_mse: 2.0756\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 1.6791 - mse: 1.6772 - val_loss: 2.0931 - val_mse: 2.0912\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 1.6663 - mse: 1.6644 - val_loss: 2.1084 - val_mse: 2.1064\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.6530 - mse: 1.6509 - val_loss: 2.0748 - val_mse: 2.0727\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.6405 - mse: 1.6384 - val_loss: 2.1464 - val_mse: 2.1442\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.6324 - mse: 1.6302 - val_loss: 2.1277 - val_mse: 2.1254\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.6258 - mse: 1.6235 - val_loss: 2.1319 - val_mse: 2.1295\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.6141 - mse: 1.6117 - val_loss: 2.1326 - val_mse: 2.1301\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.6066 - mse: 1.6041 - val_loss: 2.1539 - val_mse: 2.1513\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.6002 - mse: 1.5976 - val_loss: 2.1643 - val_mse: 2.1616\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.5949 - mse: 1.5922 - val_loss: 2.1746 - val_mse: 2.1718\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.5853 - mse: 1.5825 - val_loss: 2.1259 - val_mse: 2.1230\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.5783 - mse: 1.5754 - val_loss: 2.1815 - val_mse: 2.1785\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.5718 - mse: 1.5688 - val_loss: 2.1615 - val_mse: 2.1584\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.5649 - mse: 1.5618 - val_loss: 2.1607 - val_mse: 2.1576\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.5605 - mse: 1.5574 - val_loss: 2.1627 - val_mse: 2.1595\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.5565 - mse: 1.5533 - val_loss: 2.2267 - val_mse: 2.2234\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.5479 - mse: 1.5446 - val_loss: 2.2292 - val_mse: 2.2259\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.5415 - mse: 1.5381 - val_loss: 2.1830 - val_mse: 2.1795\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.5399 - mse: 1.5364 - val_loss: 2.2394 - val_mse: 2.2359\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.5330 - mse: 1.5295 - val_loss: 2.2279 - val_mse: 2.2243\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.5316 - mse: 1.5280 - val_loss: 2.2185 - val_mse: 2.2148\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.5265 - mse: 1.5228 - val_loss: 2.2287 - val_mse: 2.2249\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.5224 - mse: 1.5186 - val_loss: 2.2834 - val_mse: 2.2796\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.5155 - mse: 1.5117 - val_loss: 2.2422 - val_mse: 2.2383\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.5155 - mse: 1.5116 - val_loss: 2.2097 - val_mse: 2.2058\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.5074 - mse: 1.5034 - val_loss: 2.2852 - val_mse: 2.2812\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.4997 - mse: 1.4957 - val_loss: 2.2664 - val_mse: 2.2624\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.4974 - mse: 1.4933 - val_loss: 2.2412 - val_mse: 2.2371\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.4983 - mse: 1.4941 - val_loss: 2.2651 - val_mse: 2.2609\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.4922 - mse: 1.4880 - val_loss: 2.2751 - val_mse: 2.2709\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.4885 - mse: 1.4843 - val_loss: 2.2937 - val_mse: 2.2894\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.4842 - mse: 1.4798 - val_loss: 2.3144 - val_mse: 2.3101\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.4818 - mse: 1.4774 - val_loss: 2.3451 - val_mse: 2.3407\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.4768 - mse: 1.4724 - val_loss: 2.3049 - val_mse: 2.3004\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.4735 - mse: 1.4690 - val_loss: 2.2850 - val_mse: 2.2804\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.4678 - mse: 1.4632 - val_loss: 2.2684 - val_mse: 2.2638\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.4639 - mse: 1.4592 - val_loss: 2.2671 - val_mse: 2.2624\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.4621 - mse: 1.4574 - val_loss: 2.3005 - val_mse: 2.2958\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.4588 - mse: 1.4540 - val_loss: 2.3068 - val_mse: 2.3020\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.4566 - mse: 1.4518 - val_loss: 2.2929 - val_mse: 2.2880\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.4580 - mse: 1.4532 - val_loss: 2.2930 - val_mse: 2.2881\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.4540 - mse: 1.4491 - val_loss: 2.3238 - val_mse: 2.3188\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.4493 - mse: 1.4443 - val_loss: 2.2671 - val_mse: 2.2621\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.4469 - mse: 1.4418 - val_loss: 2.3277 - val_mse: 2.3226\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.4420 - mse: 1.4369 - val_loss: 2.2828 - val_mse: 2.2777\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.4436 - mse: 1.4385 - val_loss: 2.3046 - val_mse: 2.2995\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.4364 - mse: 1.4312 - val_loss: 2.3570 - val_mse: 2.3518\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.4289 - mse: 1.4237 - val_loss: 2.3201 - val_mse: 2.3148\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.4286 - mse: 1.4233 - val_loss: 2.3298 - val_mse: 2.3245\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.4290 - mse: 1.4236 - val_loss: 2.3414 - val_mse: 2.3360\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.4257 - mse: 1.4202 - val_loss: 2.3723 - val_mse: 2.3668\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.4192 - mse: 1.4138 - val_loss: 2.3844 - val_mse: 2.3789\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.4195 - mse: 1.4140 - val_loss: 2.3435 - val_mse: 2.3379\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.4171 - mse: 1.4115 - val_loss: 2.3810 - val_mse: 2.3754\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.4156 - mse: 1.4100 - val_loss: 2.3675 - val_mse: 2.3618\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.4100 - mse: 1.4043 - val_loss: 2.3523 - val_mse: 2.3466\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.4084 - mse: 1.4027 - val_loss: 2.3679 - val_mse: 2.3622\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.4038 - mse: 1.3980 - val_loss: 2.3390 - val_mse: 2.3332\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.4031 - mse: 1.3973 - val_loss: 2.3901 - val_mse: 2.3842\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.4008 - mse: 1.3949 - val_loss: 2.3457 - val_mse: 2.3398\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.3977 - mse: 1.3918 - val_loss: 2.3597 - val_mse: 2.3537\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.3968 - mse: 1.3908 - val_loss: 2.3626 - val_mse: 2.3566\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.3958 - mse: 1.3898 - val_loss: 2.3684 - val_mse: 2.3623\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.3890 - mse: 1.3829 - val_loss: 2.4319 - val_mse: 2.4258\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.3862 - mse: 1.3801 - val_loss: 2.3799 - val_mse: 2.3738\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.3831 - mse: 1.3769 - val_loss: 2.4128 - val_mse: 2.4066\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.3847 - mse: 1.3785 - val_loss: 2.4164 - val_mse: 2.4102\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.3820 - mse: 1.3758 - val_loss: 2.3985 - val_mse: 2.3922\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.3786 - mse: 1.3723 - val_loss: 2.4271 - val_mse: 2.4208\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.3785 - mse: 1.3721 - val_loss: 2.4259 - val_mse: 2.4195\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.3757 - mse: 1.3693 - val_loss: 2.3980 - val_mse: 2.3916\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.3728 - mse: 1.3664 - val_loss: 2.3696 - val_mse: 2.3631\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.3726 - mse: 1.3661 - val_loss: 2.4031 - val_mse: 2.3966\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.3679 - mse: 1.3614 - val_loss: 2.4440 - val_mse: 2.4374\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.3654 - mse: 1.3588 - val_loss: 2.4363 - val_mse: 2.4296\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.3677 - mse: 1.3610 - val_loss: 2.4236 - val_mse: 2.4169\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.3646 - mse: 1.3579 - val_loss: 2.4162 - val_mse: 2.4095\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.3641 - mse: 1.3574 - val_loss: 2.4029 - val_mse: 2.3961\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.3601 - mse: 1.3533 - val_loss: 2.4275 - val_mse: 2.4206\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.3595 - mse: 1.3527 - val_loss: 2.3759 - val_mse: 2.3691\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.3576 - mse: 1.3507 - val_loss: 2.4469 - val_mse: 2.4400\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.3567 - mse: 1.3497 - val_loss: 2.4519 - val_mse: 2.4450\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.3542 - mse: 1.3472 - val_loss: 2.4223 - val_mse: 2.4153\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.3544 - mse: 1.3473 - val_loss: 2.4490 - val_mse: 2.4419\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.3532 - mse: 1.3461 - val_loss: 2.4336 - val_mse: 2.4265\n",
      "[3/5 Cross Validation]\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_3/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 4.7099 - mse: 4.7089 - val_loss: 3.1125 - val_mse: 3.1102\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.5733 - mse: 2.5694 - val_loss: 2.3863 - val_mse: 2.3814\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.2810 - mse: 2.2759 - val_loss: 2.3342 - val_mse: 2.3288\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.2301 - mse: 2.2245 - val_loss: 2.3036 - val_mse: 2.2978\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 2.1977 - mse: 2.1918 - val_loss: 2.2865 - val_mse: 2.2804\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 2.1712 - mse: 2.1649 - val_loss: 2.2671 - val_mse: 2.2606\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 2.1502 - mse: 2.1435 - val_loss: 2.2540 - val_mse: 2.2472\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 2.1309 - mse: 2.1240 - val_loss: 2.2434 - val_mse: 2.2363\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 2.1150 - mse: 2.1077 - val_loss: 2.2344 - val_mse: 2.2270\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 2.1012 - mse: 2.0936 - val_loss: 2.2248 - val_mse: 2.2172\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 2.0888 - mse: 2.0810 - val_loss: 2.2194 - val_mse: 2.2115\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 2.0786 - mse: 2.0707 - val_loss: 2.2091 - val_mse: 2.2011\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 2.0685 - mse: 2.0604 - val_loss: 2.2035 - val_mse: 2.1952\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 2.0589 - mse: 2.0506 - val_loss: 2.1969 - val_mse: 2.1884\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 2.0506 - mse: 2.0420 - val_loss: 2.1938 - val_mse: 2.1852\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 2.0418 - mse: 2.0330 - val_loss: 2.1912 - val_mse: 2.1824\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 2.0341 - mse: 2.0252 - val_loss: 2.1826 - val_mse: 2.1736\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 2.0261 - mse: 2.0170 - val_loss: 2.1804 - val_mse: 2.1712\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 2.0181 - mse: 2.0089 - val_loss: 2.1762 - val_mse: 2.1669\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 2.0107 - mse: 2.0013 - val_loss: 2.1734 - val_mse: 2.1639\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 2.0029 - mse: 1.9933 - val_loss: 2.1676 - val_mse: 2.1580\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.9956 - mse: 1.9858 - val_loss: 2.1663 - val_mse: 2.1565\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.9885 - mse: 1.9786 - val_loss: 2.1605 - val_mse: 2.1505\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.9811 - mse: 1.9710 - val_loss: 2.1595 - val_mse: 2.1494\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.9744 - mse: 1.9642 - val_loss: 2.1532 - val_mse: 2.1429\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.9669 - mse: 1.9565 - val_loss: 2.1546 - val_mse: 2.1441\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.9601 - mse: 1.9495 - val_loss: 2.1500 - val_mse: 2.1393\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.9530 - mse: 1.9422 - val_loss: 2.1464 - val_mse: 2.1356\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.9460 - mse: 1.9351 - val_loss: 2.1470 - val_mse: 2.1360\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.9392 - mse: 1.9281 - val_loss: 2.1416 - val_mse: 2.1304\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.9319 - mse: 1.9206 - val_loss: 2.1390 - val_mse: 2.1277\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.9249 - mse: 1.9134 - val_loss: 2.1355 - val_mse: 2.1240\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.9177 - mse: 1.9061 - val_loss: 2.1357 - val_mse: 2.1240\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.9103 - mse: 1.8985 - val_loss: 2.1312 - val_mse: 2.1193\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.9032 - mse: 1.8912 - val_loss: 2.1314 - val_mse: 2.1193\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.8957 - mse: 1.8836 - val_loss: 2.1304 - val_mse: 2.1181\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.8886 - mse: 1.8762 - val_loss: 2.1303 - val_mse: 2.1179\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.8808 - mse: 1.8683 - val_loss: 2.1297 - val_mse: 2.1171\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.8738 - mse: 1.8611 - val_loss: 2.1272 - val_mse: 2.1145\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.8671 - mse: 1.8543 - val_loss: 2.1268 - val_mse: 2.1138\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.8594 - mse: 1.8464 - val_loss: 2.1278 - val_mse: 2.1147\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.8522 - mse: 1.8390 - val_loss: 2.1281 - val_mse: 2.1148\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.8452 - mse: 1.8318 - val_loss: 2.1249 - val_mse: 2.1114\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.8384 - mse: 1.8248 - val_loss: 2.1241 - val_mse: 2.1105\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.8318 - mse: 1.8180 - val_loss: 2.1279 - val_mse: 2.1141\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.8256 - mse: 1.8117 - val_loss: 2.1274 - val_mse: 2.1134\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.8193 - mse: 1.8052 - val_loss: 2.1284 - val_mse: 2.1142\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.8132 - mse: 1.7989 - val_loss: 2.1314 - val_mse: 2.1170\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.8075 - mse: 1.7930 - val_loss: 2.1294 - val_mse: 2.1148\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.8013 - mse: 1.7867 - val_loss: 2.1355 - val_mse: 2.1208\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.7961 - mse: 1.7814 - val_loss: 2.1345 - val_mse: 2.1197\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.7910 - mse: 1.7761 - val_loss: 2.1333 - val_mse: 2.1183\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.7857 - mse: 1.7706 - val_loss: 2.1357 - val_mse: 2.1206\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.7803 - mse: 1.7651 - val_loss: 2.1370 - val_mse: 2.1217\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.7754 - mse: 1.7601 - val_loss: 2.1368 - val_mse: 2.1214\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.7702 - mse: 1.7546 - val_loss: 2.1406 - val_mse: 2.1250\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.7659 - mse: 1.7502 - val_loss: 2.1398 - val_mse: 2.1241\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.7614 - mse: 1.7456 - val_loss: 2.1412 - val_mse: 2.1253\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.7566 - mse: 1.7407 - val_loss: 2.1432 - val_mse: 2.1272\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.7522 - mse: 1.7361 - val_loss: 2.1450 - val_mse: 2.1289\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.7475 - mse: 1.7313 - val_loss: 2.1492 - val_mse: 2.1329\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.7432 - mse: 1.7269 - val_loss: 2.1527 - val_mse: 2.1363\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.7394 - mse: 1.7230 - val_loss: 2.1513 - val_mse: 2.1348\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.7353 - mse: 1.7187 - val_loss: 2.1552 - val_mse: 2.1385\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.7310 - mse: 1.7143 - val_loss: 2.1587 - val_mse: 2.1420\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.7278 - mse: 1.7110 - val_loss: 2.1585 - val_mse: 2.1417\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.7237 - mse: 1.7068 - val_loss: 2.1586 - val_mse: 2.1416\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.7196 - mse: 1.7026 - val_loss: 2.1620 - val_mse: 2.1449\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.7162 - mse: 1.6990 - val_loss: 2.1649 - val_mse: 2.1476\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.7129 - mse: 1.6956 - val_loss: 2.1679 - val_mse: 2.1506\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.7096 - mse: 1.6922 - val_loss: 2.1696 - val_mse: 2.1521\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.7055 - mse: 1.6880 - val_loss: 2.1688 - val_mse: 2.1512\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.7027 - mse: 1.6851 - val_loss: 2.1770 - val_mse: 2.1593\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.7004 - mse: 1.6827 - val_loss: 2.1787 - val_mse: 2.1609\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.6968 - mse: 1.6789 - val_loss: 2.1810 - val_mse: 2.1631\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.6934 - mse: 1.6754 - val_loss: 2.1875 - val_mse: 2.1694\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.6908 - mse: 1.6727 - val_loss: 2.1871 - val_mse: 2.1689\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.6875 - mse: 1.6693 - val_loss: 2.1894 - val_mse: 2.1711\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.6856 - mse: 1.6673 - val_loss: 2.1892 - val_mse: 2.1708\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.6825 - mse: 1.6640 - val_loss: 2.1949 - val_mse: 2.1764\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.6801 - mse: 1.6615 - val_loss: 2.1957 - val_mse: 2.1771\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.6768 - mse: 1.6581 - val_loss: 2.1980 - val_mse: 2.1793\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.6741 - mse: 1.6553 - val_loss: 2.2092 - val_mse: 2.1904\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.6723 - mse: 1.6534 - val_loss: 2.2021 - val_mse: 2.1832\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.6695 - mse: 1.6506 - val_loss: 2.2107 - val_mse: 2.1917\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.6671 - mse: 1.6480 - val_loss: 2.2104 - val_mse: 2.1912\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.6643 - mse: 1.6451 - val_loss: 2.2141 - val_mse: 2.1948\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.6620 - mse: 1.6427 - val_loss: 2.2123 - val_mse: 2.1930\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.6593 - mse: 1.6399 - val_loss: 2.2225 - val_mse: 2.2030\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.6577 - mse: 1.6382 - val_loss: 2.2236 - val_mse: 2.2041\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.6555 - mse: 1.6359 - val_loss: 2.2280 - val_mse: 2.2084\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.6530 - mse: 1.6333 - val_loss: 2.2309 - val_mse: 2.2111\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.6515 - mse: 1.6317 - val_loss: 2.2324 - val_mse: 2.2125\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.6494 - mse: 1.6295 - val_loss: 2.2339 - val_mse: 2.2140\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.6469 - mse: 1.6269 - val_loss: 2.2383 - val_mse: 2.2182\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.6445 - mse: 1.6244 - val_loss: 2.2439 - val_mse: 2.2237\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.6432 - mse: 1.6230 - val_loss: 2.2439 - val_mse: 2.2237\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.6408 - mse: 1.6205 - val_loss: 2.2457 - val_mse: 2.2254\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.6392 - mse: 1.6188 - val_loss: 2.2456 - val_mse: 2.2251\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.6368 - mse: 1.6164 - val_loss: 2.2445 - val_mse: 2.2240\n",
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 2.7715 - mse: 2.7713 - val_loss: 2.2732 - val_mse: 2.2729\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.1966 - mse: 2.1962 - val_loss: 2.2501 - val_mse: 2.2496\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.1456 - mse: 2.1451 - val_loss: 2.2203 - val_mse: 2.2198\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.1106 - mse: 2.1100 - val_loss: 2.2089 - val_mse: 2.2083\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 2.0734 - mse: 2.0728 - val_loss: 2.1801 - val_mse: 2.1793\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 2.0313 - mse: 2.0305 - val_loss: 2.1506 - val_mse: 2.1498\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 1.9799 - mse: 1.9790 - val_loss: 2.1122 - val_mse: 2.1113\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 1.9322 - mse: 1.9312 - val_loss: 2.0968 - val_mse: 2.0957\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 1.8901 - mse: 1.8890 - val_loss: 2.0794 - val_mse: 2.0783\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.8605 - mse: 1.8593 - val_loss: 2.0834 - val_mse: 2.0821\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.8347 - mse: 1.8334 - val_loss: 2.0653 - val_mse: 2.0640\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.8084 - mse: 1.8070 - val_loss: 2.0678 - val_mse: 2.0664\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.7953 - mse: 1.7938 - val_loss: 2.0642 - val_mse: 2.0627\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.7748 - mse: 1.7733 - val_loss: 2.0717 - val_mse: 2.0701\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.7564 - mse: 1.7548 - val_loss: 2.0784 - val_mse: 2.0767\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 1.7391 - mse: 1.7373 - val_loss: 2.0791 - val_mse: 2.0773\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 1.7236 - mse: 1.7217 - val_loss: 2.0741 - val_mse: 2.0721\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.7099 - mse: 1.7079 - val_loss: 2.0697 - val_mse: 2.0676\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.6922 - mse: 1.6901 - val_loss: 2.0882 - val_mse: 2.0860\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.6804 - mse: 1.6782 - val_loss: 2.1129 - val_mse: 2.1106\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.6674 - mse: 1.6651 - val_loss: 2.0943 - val_mse: 2.0919\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.6506 - mse: 1.6482 - val_loss: 2.1091 - val_mse: 2.1066\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.6400 - mse: 1.6375 - val_loss: 2.1006 - val_mse: 2.0980\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.6289 - mse: 1.6263 - val_loss: 2.1276 - val_mse: 2.1249\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.6176 - mse: 1.6149 - val_loss: 2.1375 - val_mse: 2.1348\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.6094 - mse: 1.6066 - val_loss: 2.1320 - val_mse: 2.1291\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.6006 - mse: 1.5977 - val_loss: 2.1679 - val_mse: 2.1650\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.5868 - mse: 1.5838 - val_loss: 2.1471 - val_mse: 2.1440\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.5793 - mse: 1.5762 - val_loss: 2.1454 - val_mse: 2.1423\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.5679 - mse: 1.5648 - val_loss: 2.2438 - val_mse: 2.2406\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.5639 - mse: 1.5606 - val_loss: 2.2016 - val_mse: 2.1983\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.5576 - mse: 1.5542 - val_loss: 2.2143 - val_mse: 2.2109\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.5499 - mse: 1.5465 - val_loss: 2.1997 - val_mse: 2.1963\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.5449 - mse: 1.5414 - val_loss: 2.2036 - val_mse: 2.2000\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.5431 - mse: 1.5395 - val_loss: 2.2210 - val_mse: 2.2174\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.5334 - mse: 1.5298 - val_loss: 2.1953 - val_mse: 2.1916\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.5260 - mse: 1.5223 - val_loss: 2.2217 - val_mse: 2.2179\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.5198 - mse: 1.5160 - val_loss: 2.2094 - val_mse: 2.2055\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.5164 - mse: 1.5125 - val_loss: 2.2533 - val_mse: 2.2494\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.5135 - mse: 1.5096 - val_loss: 2.2400 - val_mse: 2.2360\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.5121 - mse: 1.5081 - val_loss: 2.2690 - val_mse: 2.2650\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.5036 - mse: 1.4995 - val_loss: 2.2815 - val_mse: 2.2773\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.5009 - mse: 1.4968 - val_loss: 2.2379 - val_mse: 2.2337\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.4931 - mse: 1.4889 - val_loss: 2.2627 - val_mse: 2.2584\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.4948 - mse: 1.4905 - val_loss: 2.2542 - val_mse: 2.2499\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.4906 - mse: 1.4862 - val_loss: 2.2889 - val_mse: 2.2845\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.4825 - mse: 1.4780 - val_loss: 2.2727 - val_mse: 2.2682\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.4813 - mse: 1.4767 - val_loss: 2.2634 - val_mse: 2.2588\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.4761 - mse: 1.4715 - val_loss: 2.2742 - val_mse: 2.2696\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.4726 - mse: 1.4680 - val_loss: 2.2684 - val_mse: 2.2637\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.4755 - mse: 1.4708 - val_loss: 2.3085 - val_mse: 2.3038\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.4687 - mse: 1.4639 - val_loss: 2.2910 - val_mse: 2.2862\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.4671 - mse: 1.4623 - val_loss: 2.3362 - val_mse: 2.3314\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.4624 - mse: 1.4575 - val_loss: 2.2998 - val_mse: 2.2949\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.4599 - mse: 1.4550 - val_loss: 2.3505 - val_mse: 2.3455\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.4561 - mse: 1.4511 - val_loss: 2.3269 - val_mse: 2.3219\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.4510 - mse: 1.4460 - val_loss: 2.3197 - val_mse: 2.3146\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.4493 - mse: 1.4442 - val_loss: 2.3356 - val_mse: 2.3304\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.4467 - mse: 1.4415 - val_loss: 2.3337 - val_mse: 2.3285\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.4457 - mse: 1.4405 - val_loss: 2.3320 - val_mse: 2.3267\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.4440 - mse: 1.4387 - val_loss: 2.3240 - val_mse: 2.3187\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.4395 - mse: 1.4342 - val_loss: 2.3340 - val_mse: 2.3287\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.4380 - mse: 1.4326 - val_loss: 2.2988 - val_mse: 2.2934\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.4292 - mse: 1.4237 - val_loss: 2.3415 - val_mse: 2.3360\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.4324 - mse: 1.4269 - val_loss: 2.3131 - val_mse: 2.3076\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.4296 - mse: 1.4240 - val_loss: 2.3155 - val_mse: 2.3100\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.4281 - mse: 1.4225 - val_loss: 2.3192 - val_mse: 2.3135\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.4271 - mse: 1.4215 - val_loss: 2.3197 - val_mse: 2.3140\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.4217 - mse: 1.4160 - val_loss: 2.3384 - val_mse: 2.3327\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.4191 - mse: 1.4134 - val_loss: 2.3783 - val_mse: 2.3725\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.4186 - mse: 1.4128 - val_loss: 2.3863 - val_mse: 2.3804\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.4142 - mse: 1.4084 - val_loss: 2.3826 - val_mse: 2.3768\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.4138 - mse: 1.4079 - val_loss: 2.4048 - val_mse: 2.3989\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.4128 - mse: 1.4068 - val_loss: 2.3141 - val_mse: 2.3081\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.4099 - mse: 1.4039 - val_loss: 2.3355 - val_mse: 2.3295\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.4043 - mse: 1.3982 - val_loss: 2.3844 - val_mse: 2.3783\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.4050 - mse: 1.3989 - val_loss: 2.3505 - val_mse: 2.3443\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.4021 - mse: 1.3960 - val_loss: 2.3508 - val_mse: 2.3447\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.4008 - mse: 1.3946 - val_loss: 2.3516 - val_mse: 2.3454\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.3983 - mse: 1.3921 - val_loss: 2.3598 - val_mse: 2.3535\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.4008 - mse: 1.3945 - val_loss: 2.3814 - val_mse: 2.3751\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.3907 - mse: 1.3843 - val_loss: 2.3968 - val_mse: 2.3904\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.3938 - mse: 1.3874 - val_loss: 2.4040 - val_mse: 2.3975\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.3909 - mse: 1.3844 - val_loss: 2.3672 - val_mse: 2.3607\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.3873 - mse: 1.3808 - val_loss: 2.4310 - val_mse: 2.4245\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.3873 - mse: 1.3808 - val_loss: 2.4199 - val_mse: 2.4133\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.3835 - mse: 1.3769 - val_loss: 2.4125 - val_mse: 2.4059\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.3833 - mse: 1.3767 - val_loss: 2.4155 - val_mse: 2.4089\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.3814 - mse: 1.3747 - val_loss: 2.4106 - val_mse: 2.4039\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.3787 - mse: 1.3720 - val_loss: 2.4378 - val_mse: 2.4311\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.3742 - mse: 1.3674 - val_loss: 2.4422 - val_mse: 2.4354\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.3767 - mse: 1.3699 - val_loss: 2.3925 - val_mse: 2.3857\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.3725 - mse: 1.3657 - val_loss: 2.4077 - val_mse: 2.4008\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.3723 - mse: 1.3654 - val_loss: 2.4595 - val_mse: 2.4526\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.3660 - mse: 1.3591 - val_loss: 2.3983 - val_mse: 2.3913\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.3686 - mse: 1.3617 - val_loss: 2.4045 - val_mse: 2.3975\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.3659 - mse: 1.3588 - val_loss: 2.4404 - val_mse: 2.4334\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.3681 - mse: 1.3610 - val_loss: 2.3998 - val_mse: 2.3927\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.3636 - mse: 1.3565 - val_loss: 2.4044 - val_mse: 2.3973\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.3607 - mse: 1.3535 - val_loss: 2.4167 - val_mse: 2.4095\n",
      "[4/5 Cross Validation]\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_4/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "438/438 - 2s - loss: 4.7616 - mse: 4.7607 - val_loss: 3.1994 - val_mse: 3.1969\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.7945 - mse: 2.7905 - val_loss: 2.4248 - val_mse: 2.4193\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.2194 - mse: 2.2132 - val_loss: 2.2349 - val_mse: 2.2284\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.1105 - mse: 2.1038 - val_loss: 2.2001 - val_mse: 2.1934\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 2.0682 - mse: 2.0613 - val_loss: 2.1814 - val_mse: 2.1745\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 2.0397 - mse: 2.0327 - val_loss: 2.1701 - val_mse: 2.1630\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 2.0182 - mse: 2.0110 - val_loss: 2.1599 - val_mse: 2.1527\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 2.0001 - mse: 1.9928 - val_loss: 2.1529 - val_mse: 2.1455\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 1.9853 - mse: 1.9778 - val_loss: 2.1507 - val_mse: 2.1432\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.9725 - mse: 1.9649 - val_loss: 2.1431 - val_mse: 2.1354\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.9610 - mse: 1.9532 - val_loss: 2.1379 - val_mse: 2.1300\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.9506 - mse: 1.9427 - val_loss: 2.1378 - val_mse: 2.1299\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.9425 - mse: 1.9345 - val_loss: 2.1351 - val_mse: 2.1270\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.9340 - mse: 1.9258 - val_loss: 2.1317 - val_mse: 2.1235\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.9269 - mse: 1.9186 - val_loss: 2.1308 - val_mse: 2.1225\n",
      "Epoch 16/100\n",
      "438/438 - 1s - loss: 1.9197 - mse: 1.9113 - val_loss: 2.1290 - val_mse: 2.1206\n",
      "Epoch 17/100\n",
      "438/438 - 1s - loss: 1.9133 - mse: 1.9047 - val_loss: 2.1251 - val_mse: 2.1165\n",
      "Epoch 18/100\n",
      "438/438 - 1s - loss: 1.9076 - mse: 1.8990 - val_loss: 2.1223 - val_mse: 2.1136\n",
      "Epoch 19/100\n",
      "438/438 - 1s - loss: 1.9019 - mse: 1.8932 - val_loss: 2.1266 - val_mse: 2.1178\n",
      "Epoch 20/100\n",
      "438/438 - 1s - loss: 1.8972 - mse: 1.8883 - val_loss: 2.1195 - val_mse: 2.1105\n",
      "Epoch 21/100\n",
      "438/438 - 1s - loss: 1.8917 - mse: 1.8827 - val_loss: 2.1217 - val_mse: 2.1127\n",
      "Epoch 22/100\n",
      "438/438 - 1s - loss: 1.8879 - mse: 1.8787 - val_loss: 2.1196 - val_mse: 2.1103\n",
      "Epoch 23/100\n",
      "438/438 - 1s - loss: 1.8826 - mse: 1.8733 - val_loss: 2.1178 - val_mse: 2.1084\n",
      "Epoch 24/100\n",
      "438/438 - 1s - loss: 1.8783 - mse: 1.8689 - val_loss: 2.1187 - val_mse: 2.1092\n",
      "Epoch 25/100\n",
      "438/438 - 1s - loss: 1.8741 - mse: 1.8646 - val_loss: 2.1181 - val_mse: 2.1085\n",
      "Epoch 26/100\n",
      "438/438 - 1s - loss: 1.8701 - mse: 1.8604 - val_loss: 2.1180 - val_mse: 2.1082\n",
      "Epoch 27/100\n",
      "438/438 - 1s - loss: 1.8660 - mse: 1.8561 - val_loss: 2.1158 - val_mse: 2.1059\n",
      "Epoch 28/100\n",
      "438/438 - 1s - loss: 1.8618 - mse: 1.8519 - val_loss: 2.1143 - val_mse: 2.1042\n",
      "Epoch 29/100\n",
      "438/438 - 1s - loss: 1.8577 - mse: 1.8476 - val_loss: 2.1141 - val_mse: 2.1040\n",
      "Epoch 30/100\n",
      "438/438 - 1s - loss: 1.8536 - mse: 1.8434 - val_loss: 2.1159 - val_mse: 2.1056\n",
      "Epoch 31/100\n",
      "438/438 - 1s - loss: 1.8498 - mse: 1.8394 - val_loss: 2.1131 - val_mse: 2.1027\n",
      "Epoch 32/100\n",
      "438/438 - 1s - loss: 1.8453 - mse: 1.8348 - val_loss: 2.1167 - val_mse: 2.1061\n",
      "Epoch 33/100\n",
      "438/438 - 1s - loss: 1.8414 - mse: 1.8307 - val_loss: 2.1180 - val_mse: 2.1074\n",
      "Epoch 34/100\n",
      "438/438 - 1s - loss: 1.8373 - mse: 1.8266 - val_loss: 2.1206 - val_mse: 2.1098\n",
      "Epoch 35/100\n",
      "438/438 - 1s - loss: 1.8328 - mse: 1.8219 - val_loss: 2.1186 - val_mse: 2.1076\n",
      "Epoch 36/100\n",
      "438/438 - 1s - loss: 1.8289 - mse: 1.8178 - val_loss: 2.1206 - val_mse: 2.1095\n",
      "Epoch 37/100\n",
      "438/438 - 1s - loss: 1.8239 - mse: 1.8127 - val_loss: 2.1249 - val_mse: 2.1136\n",
      "Epoch 38/100\n",
      "438/438 - 1s - loss: 1.8198 - mse: 1.8085 - val_loss: 2.1230 - val_mse: 2.1116\n",
      "Epoch 39/100\n",
      "438/438 - 1s - loss: 1.8151 - mse: 1.8036 - val_loss: 2.1287 - val_mse: 2.1172\n",
      "Epoch 40/100\n",
      "438/438 - 1s - loss: 1.8112 - mse: 1.7996 - val_loss: 2.1289 - val_mse: 2.1172\n",
      "Epoch 41/100\n",
      "438/438 - 1s - loss: 1.8067 - mse: 1.7950 - val_loss: 2.1319 - val_mse: 2.1202\n",
      "Epoch 42/100\n",
      "438/438 - 1s - loss: 1.8020 - mse: 1.7901 - val_loss: 2.1325 - val_mse: 2.1206\n",
      "Epoch 43/100\n",
      "438/438 - 1s - loss: 1.7976 - mse: 1.7856 - val_loss: 2.1355 - val_mse: 2.1234\n",
      "Epoch 44/100\n",
      "438/438 - 1s - loss: 1.7932 - mse: 1.7811 - val_loss: 2.1375 - val_mse: 2.1253\n",
      "Epoch 45/100\n",
      "438/438 - 1s - loss: 1.7886 - mse: 1.7764 - val_loss: 2.1430 - val_mse: 2.1307\n",
      "Epoch 46/100\n",
      "438/438 - 1s - loss: 1.7843 - mse: 1.7719 - val_loss: 2.1438 - val_mse: 2.1314\n",
      "Epoch 47/100\n",
      "438/438 - 1s - loss: 1.7806 - mse: 1.7681 - val_loss: 2.1490 - val_mse: 2.1365\n",
      "Epoch 48/100\n",
      "438/438 - 1s - loss: 1.7760 - mse: 1.7634 - val_loss: 2.1508 - val_mse: 2.1381\n",
      "Epoch 49/100\n",
      "438/438 - 1s - loss: 1.7721 - mse: 1.7594 - val_loss: 2.1533 - val_mse: 2.1405\n",
      "Epoch 50/100\n",
      "438/438 - 1s - loss: 1.7683 - mse: 1.7555 - val_loss: 2.1567 - val_mse: 2.1438\n",
      "Epoch 51/100\n",
      "438/438 - 1s - loss: 1.7639 - mse: 1.7509 - val_loss: 2.1608 - val_mse: 2.1478\n",
      "Epoch 52/100\n",
      "438/438 - 1s - loss: 1.7609 - mse: 1.7478 - val_loss: 2.1585 - val_mse: 2.1454\n",
      "Epoch 53/100\n",
      "438/438 - 1s - loss: 1.7564 - mse: 1.7432 - val_loss: 2.1641 - val_mse: 2.1509\n",
      "Epoch 54/100\n",
      "438/438 - 1s - loss: 1.7527 - mse: 1.7394 - val_loss: 2.1616 - val_mse: 2.1483\n",
      "Epoch 55/100\n",
      "438/438 - 1s - loss: 1.7490 - mse: 1.7356 - val_loss: 2.1674 - val_mse: 2.1540\n",
      "Epoch 56/100\n",
      "438/438 - 1s - loss: 1.7459 - mse: 1.7324 - val_loss: 2.1715 - val_mse: 2.1580\n",
      "Epoch 57/100\n",
      "438/438 - 1s - loss: 1.7419 - mse: 1.7283 - val_loss: 2.1743 - val_mse: 2.1606\n",
      "Epoch 58/100\n",
      "438/438 - 1s - loss: 1.7391 - mse: 1.7254 - val_loss: 2.1751 - val_mse: 2.1613\n",
      "Epoch 59/100\n",
      "438/438 - 1s - loss: 1.7352 - mse: 1.7214 - val_loss: 2.1778 - val_mse: 2.1639\n",
      "Epoch 60/100\n",
      "438/438 - 1s - loss: 1.7322 - mse: 1.7182 - val_loss: 2.1780 - val_mse: 2.1640\n",
      "Epoch 61/100\n",
      "438/438 - 1s - loss: 1.7296 - mse: 1.7155 - val_loss: 2.1831 - val_mse: 2.1690\n",
      "Epoch 62/100\n",
      "438/438 - 1s - loss: 1.7264 - mse: 1.7123 - val_loss: 2.1847 - val_mse: 2.1705\n",
      "Epoch 63/100\n",
      "438/438 - 1s - loss: 1.7234 - mse: 1.7092 - val_loss: 2.1838 - val_mse: 2.1696\n",
      "Epoch 64/100\n",
      "438/438 - 1s - loss: 1.7208 - mse: 1.7065 - val_loss: 2.1931 - val_mse: 2.1787\n",
      "Epoch 65/100\n",
      "438/438 - 1s - loss: 1.7180 - mse: 1.7035 - val_loss: 2.1919 - val_mse: 2.1774\n",
      "Epoch 66/100\n",
      "438/438 - 1s - loss: 1.7152 - mse: 1.7007 - val_loss: 2.1957 - val_mse: 2.1811\n",
      "Epoch 67/100\n",
      "438/438 - 1s - loss: 1.7126 - mse: 1.6979 - val_loss: 2.2004 - val_mse: 2.1857\n",
      "Epoch 68/100\n",
      "438/438 - 1s - loss: 1.7101 - mse: 1.6953 - val_loss: 2.2000 - val_mse: 2.1852\n",
      "Epoch 69/100\n",
      "438/438 - 1s - loss: 1.7079 - mse: 1.6931 - val_loss: 2.2031 - val_mse: 2.1882\n",
      "Epoch 70/100\n",
      "438/438 - 1s - loss: 1.7049 - mse: 1.6900 - val_loss: 2.2048 - val_mse: 2.1898\n",
      "Epoch 71/100\n",
      "438/438 - 1s - loss: 1.7025 - mse: 1.6876 - val_loss: 2.2108 - val_mse: 2.1957\n",
      "Epoch 72/100\n",
      "438/438 - 1s - loss: 1.7011 - mse: 1.6860 - val_loss: 2.2091 - val_mse: 2.1939\n",
      "Epoch 73/100\n",
      "438/438 - 1s - loss: 1.6982 - mse: 1.6831 - val_loss: 2.2176 - val_mse: 2.2023\n",
      "Epoch 74/100\n",
      "438/438 - 1s - loss: 1.6958 - mse: 1.6806 - val_loss: 2.2168 - val_mse: 2.2015\n",
      "Epoch 75/100\n",
      "438/438 - 1s - loss: 1.6937 - mse: 1.6784 - val_loss: 2.2221 - val_mse: 2.2067\n",
      "Epoch 76/100\n",
      "438/438 - 1s - loss: 1.6919 - mse: 1.6765 - val_loss: 2.2262 - val_mse: 2.2108\n",
      "Epoch 77/100\n",
      "438/438 - 1s - loss: 1.6893 - mse: 1.6738 - val_loss: 2.2235 - val_mse: 2.2079\n",
      "Epoch 78/100\n",
      "438/438 - 1s - loss: 1.6867 - mse: 1.6711 - val_loss: 2.2263 - val_mse: 2.2107\n",
      "Epoch 79/100\n",
      "438/438 - 1s - loss: 1.6861 - mse: 1.6704 - val_loss: 2.2261 - val_mse: 2.2104\n",
      "Epoch 80/100\n",
      "438/438 - 1s - loss: 1.6832 - mse: 1.6674 - val_loss: 2.2318 - val_mse: 2.2160\n",
      "Epoch 81/100\n",
      "438/438 - 1s - loss: 1.6817 - mse: 1.6658 - val_loss: 2.2318 - val_mse: 2.2159\n",
      "Epoch 82/100\n",
      "438/438 - 1s - loss: 1.6796 - mse: 1.6637 - val_loss: 2.2339 - val_mse: 2.2180\n",
      "Epoch 83/100\n",
      "438/438 - 1s - loss: 1.6776 - mse: 1.6616 - val_loss: 2.2318 - val_mse: 2.2158\n",
      "Epoch 84/100\n",
      "438/438 - 1s - loss: 1.6754 - mse: 1.6593 - val_loss: 2.2401 - val_mse: 2.2240\n",
      "Epoch 85/100\n",
      "438/438 - 1s - loss: 1.6743 - mse: 1.6581 - val_loss: 2.2411 - val_mse: 2.2249\n",
      "Epoch 86/100\n",
      "438/438 - 1s - loss: 1.6724 - mse: 1.6562 - val_loss: 2.2409 - val_mse: 2.2247\n",
      "Epoch 87/100\n",
      "438/438 - 1s - loss: 1.6707 - mse: 1.6543 - val_loss: 2.2474 - val_mse: 2.2310\n",
      "Epoch 88/100\n",
      "438/438 - 1s - loss: 1.6690 - mse: 1.6526 - val_loss: 2.2455 - val_mse: 2.2291\n",
      "Epoch 89/100\n",
      "438/438 - 1s - loss: 1.6674 - mse: 1.6510 - val_loss: 2.2520 - val_mse: 2.2355\n",
      "Epoch 90/100\n",
      "438/438 - 1s - loss: 1.6661 - mse: 1.6495 - val_loss: 2.2513 - val_mse: 2.2347\n",
      "Epoch 91/100\n",
      "438/438 - 1s - loss: 1.6643 - mse: 1.6477 - val_loss: 2.2524 - val_mse: 2.2358\n",
      "Epoch 92/100\n",
      "438/438 - 1s - loss: 1.6626 - mse: 1.6459 - val_loss: 2.2525 - val_mse: 2.2358\n",
      "Epoch 93/100\n",
      "438/438 - 1s - loss: 1.6613 - mse: 1.6445 - val_loss: 2.2548 - val_mse: 2.2380\n",
      "Epoch 94/100\n",
      "438/438 - 1s - loss: 1.6598 - mse: 1.6430 - val_loss: 2.2582 - val_mse: 2.2413\n",
      "Epoch 95/100\n",
      "438/438 - 1s - loss: 1.6581 - mse: 1.6412 - val_loss: 2.2597 - val_mse: 2.2428\n",
      "Epoch 96/100\n",
      "438/438 - 1s - loss: 1.6568 - mse: 1.6398 - val_loss: 2.2586 - val_mse: 2.2417\n",
      "Epoch 97/100\n",
      "438/438 - 1s - loss: 1.6555 - mse: 1.6385 - val_loss: 2.2670 - val_mse: 2.2499\n",
      "Epoch 98/100\n",
      "438/438 - 1s - loss: 1.6546 - mse: 1.6376 - val_loss: 2.2659 - val_mse: 2.2488\n",
      "Epoch 99/100\n",
      "438/438 - 1s - loss: 1.6530 - mse: 1.6358 - val_loss: 2.2702 - val_mse: 2.2530\n",
      "Epoch 100/100\n",
      "438/438 - 1s - loss: 1.6519 - mse: 1.6347 - val_loss: 2.2696 - val_mse: 2.2524\n",
      "Epoch 1/100\n",
      "438/438 - 3s - loss: 2.7856 - mse: 2.7854 - val_loss: 2.2852 - val_mse: 2.2849\n",
      "Epoch 2/100\n",
      "438/438 - 1s - loss: 2.1767 - mse: 2.1763 - val_loss: 2.2243 - val_mse: 2.2238\n",
      "Epoch 3/100\n",
      "438/438 - 1s - loss: 2.1054 - mse: 2.1049 - val_loss: 2.2157 - val_mse: 2.2151\n",
      "Epoch 4/100\n",
      "438/438 - 1s - loss: 2.0433 - mse: 2.0426 - val_loss: 2.2110 - val_mse: 2.2104\n",
      "Epoch 5/100\n",
      "438/438 - 1s - loss: 1.9884 - mse: 1.9877 - val_loss: 2.1319 - val_mse: 2.1311\n",
      "Epoch 6/100\n",
      "438/438 - 1s - loss: 1.9412 - mse: 1.9403 - val_loss: 2.1256 - val_mse: 2.1247\n",
      "Epoch 7/100\n",
      "438/438 - 1s - loss: 1.8992 - mse: 1.8982 - val_loss: 2.1036 - val_mse: 2.1025\n",
      "Epoch 8/100\n",
      "438/438 - 1s - loss: 1.8639 - mse: 1.8628 - val_loss: 2.0810 - val_mse: 2.0798\n",
      "Epoch 9/100\n",
      "438/438 - 1s - loss: 1.8323 - mse: 1.8311 - val_loss: 2.1186 - val_mse: 2.1173\n",
      "Epoch 10/100\n",
      "438/438 - 1s - loss: 1.7978 - mse: 1.7965 - val_loss: 2.0564 - val_mse: 2.0551\n",
      "Epoch 11/100\n",
      "438/438 - 1s - loss: 1.7685 - mse: 1.7671 - val_loss: 2.0518 - val_mse: 2.0503\n",
      "Epoch 12/100\n",
      "438/438 - 1s - loss: 1.7455 - mse: 1.7440 - val_loss: 2.0514 - val_mse: 2.0499\n",
      "Epoch 13/100\n",
      "438/438 - 1s - loss: 1.7219 - mse: 1.7203 - val_loss: 2.0687 - val_mse: 2.0670\n",
      "Epoch 14/100\n",
      "438/438 - 1s - loss: 1.7022 - mse: 1.7005 - val_loss: 2.0733 - val_mse: 2.0716\n",
      "Epoch 15/100\n",
      "438/438 - 1s - loss: 1.6849 - mse: 1.6832 - val_loss: 2.1048 - val_mse: 2.1030\n",
      "Epoch 16/100\n"
     ]
    }
   ],
   "source": [
    "from models.nn_based_models import DeepCTRModel\n",
    "\n",
    "def EnsembleModel(dataframe, testing_data, test_index, y_test, users, items, dataset='movielens',\n",
    "            sparse=['user', 'movie', 'movie_genre', 'user_occupation'], \n",
    "            dense=['user_age'],\n",
    "            y=['rating']):\n",
    "    # init wandb run\n",
    "    run = wandb.init(project=config['general'][dataset],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"Ensemble\")\n",
    "    \n",
    "    deer = DeepCTRModel(sparse, dense, y=y)\n",
    "    result = deer.Ensemble(dataframe, testing_data, test_index, users, items)\n",
    "    \n",
    "    clear_output()\n",
    "    print(f\"Ensemble={result}\")\n",
    "\n",
    "    run.finish()\n",
    "    \n",
    "    \n",
    "    \n",
    "EnsembleModel(movielens_training_df, movielens_testing_df, test_index, y_test, len_users, movies)\n",
    "    \n",
    "# EnsembleModel(yelp_training_df, yelp_testing_df, test_index_yelp, y_test_yelp, yelp_users, business, dataset='yelp', \n",
    "#     sparse=['user', 'business', 'business_city', 'business_category'],\n",
    "#     dense=['user_compliment'],\n",
    "#     y = ['rating'])\n",
    "    \n",
    "# EnsemblemModel(douban_training_df, douban_testing_df, test_index_douban, y_test_douban,  douban_users, books, dataset='douban', \n",
    "#     sparse=['user', 'book', 'user_location', 'book_author', 'book_publisher', 'user_group'],\n",
    "#     y = ['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f8fcd-dacb-463d-8cac-b03c282b09b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
