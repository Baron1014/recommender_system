{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d29f8d-13fb-4094-ac45-cf49ef5e22b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from imp import reload\n",
    "from dataaccessframeworks.read_data import get_movielens, user_filter, training_testing, get_yelp, get_douban, training_testing_XY\n",
    "from dataaccessframeworks.data_preprocessing import get_one_hot_feature, generate_eval_array\n",
    "from models.collaborative_filtering import get_user_item_matrix, predict\n",
    "from models.evaluation import recall_k\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import ndcg_score\n",
    "import configparser\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from util.mywandb import WandbLog\n",
    "import util.utility as util\n",
    "import itertools\n",
    "from random import sample\n",
    "from IPython.display import clear_output\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.join(os.path.dirname(os.getcwd()), 'config.ini'))\n",
    "LIBFM_PATH = '/home/baron/libfm/bin/'\n",
    "os.environ['LIBFM_PATH'] = LIBFM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1bd60d8-f070-4b2b-b73a-34d25167da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data input:\n",
    "[[user, item, rank], .....]\n",
    "'''\n",
    "def get_uij(data, users, items, sample_rate=1000):\n",
    "    for ii, user in enumerate(users):\n",
    "        items_data = data[data[:, 0]==user]\n",
    "        item_compare = list()\n",
    "        item_neg = list()\n",
    "        neg_count = 0\n",
    "        items_iter =[i for i in itertools.combinations(items, 2)]\n",
    "        items_iter = sample(items_iter, sample_rate)\n",
    "        for i, j in items_iter:\n",
    "            # if i exist items, but j not exsit items, i>j\n",
    "            if i in items_data[:, 1] and j not in items_data[:, 1]:\n",
    "                item_compare.append([user, i, j, 1])\n",
    "            # if j exist items, but i not exsit items, j>i\n",
    "            elif i not in items_data[:, 1] and j in items_data[:, 1]:\n",
    "                item_compare.append([user, j, i, 1])\n",
    "            # if i exist items, and also j exsit items, compare i and j\n",
    "            elif i in items_data[:, 1] and j in items_data[:, 1]:\n",
    "                ri = items_data[(items_data[:, 0]==user) & (items_data[:, 1]==i)][0, 2]\n",
    "                rj = items_data[(items_data[:, 0]==user) & (items_data[:, 1]==j)][0, 2]\n",
    "                if ri > rj:\n",
    "                    item_compare.append([user, i, j, 1])\n",
    "                elif ri < rj:\n",
    "                    item_compare.append([user, j, i, 1])\n",
    "                else:\n",
    "                    if neg_count < len(item_compare)//2:\n",
    "                        item_neg.append([user, j, i, 0])\n",
    "                        item_neg.append([user, i, j, 0])\n",
    "                        neg_count+=1\n",
    "            else:\n",
    "                if neg_count < len(item_compare)//2:\n",
    "                    item_neg.append([user, j, i, 0])\n",
    "                    item_neg.append([user, i, j, 0])\n",
    "                    neg_count+=1\n",
    "        if ii==0:\n",
    "            uij = np.array(item_compare)\n",
    "            uij_neg = np.array(item_neg)\n",
    "        else:\n",
    "            if len(item_compare)!= 0:\n",
    "                uij = np.vstack((uij, np.array(item_compare)))\n",
    "            if len(item_neg)!= 0:\n",
    "                uij_neg = np.vstack((uij_neg, np.array(item_neg)))\n",
    "        \n",
    "        if ii%300==0:\n",
    "            print(\"[{}/{}] uij_pos: {}, uij_neg: {}\".format(ii, len(users), uij.shape, uij_neg.shape))\n",
    "    \n",
    "    return uij, uij_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4011be-f3e9-46b9-a80e-ae726fc3e542",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc7fb39-e567-42b6-b8a5-b5fdb61739b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataaccessframeworks.data_preprocessing import get_feature_map, generate_with_feature, get_norating_data\n",
    "\n",
    "def get_uij_one_hot_feature(data, user_item_col, uij_data, y_col=3, time_col=3, batch_size=10000):\n",
    "    # 取得user及items feature map \n",
    "    users_dict, items_dict, features = get_feature_map(data, user_item_col)\n",
    "\n",
    "    # 將user item 數值轉為integer\n",
    "    # user_items = np.array([list(map(int, data))for data in data[user_item_col]])\n",
    "    # 使用者評分次數小於三筆則剔除\n",
    "    filter_data = user_filter(uij_data, 0)\n",
    "    print(filter_data.shape)\n",
    "    print(filter_data[:5])\n",
    "    # user label encoder\n",
    "    le = LabelEncoder()\n",
    "    filter_data[:, 0] = le.fit_transform(filter_data[:, 0])\n",
    "    # item label encoder\n",
    "    ile = LabelEncoder()\n",
    "    filter_data[:, 1] = ile.fit_transform(filter_data[:, 1])\n",
    "    filter_data[:, 2] = ile.fit_transform(filter_data[:, 2])\n",
    "    \n",
    "    # 做特徵的onehot encoding \n",
    "    one_hot_encoder_data, y, concat_data = get_uij_onehot_encoding(filter_data, users_dict, items_dict, features, le, ile, batch_size, y_col)\n",
    "\n",
    "    return one_hot_encoder_data, y, concat_data\n",
    "\n",
    "# 取得user及items的one hot encoding map\n",
    "def get_uij_onehot_encoding(data, users_dict, items_dict, features, le, ile, batch_size, y_col):\n",
    "    #users_onehot = get_users_onehot(data)\n",
    "    sparse_, dense = get_uij_feature_onehot(data, users_dict, items_dict, features, le, ile, batch_size)\n",
    "    \n",
    "    # 取得y\n",
    "    y = data[:,y_col].reshape(-1,1)\n",
    "    \n",
    "    # return np.concatenate((sparse_, dense), axis=1), y, concat_data\n",
    "    return sparse.hstack((sparse_, dense), format='csr'), y, data\n",
    "\n",
    "# 取得feature one hot\n",
    "def get_uij_feature_onehot(data, users_feature, items_feature, features_map, le, ile, batch_size):\n",
    "    # 取得user & item個數\n",
    "    user_number = np.max(data[:,0]) + 1\n",
    "    item_number = np.max(data[:,1]) + 1\n",
    "    i_feature = items_feature[1].keys()\n",
    "    # one hot encoding\n",
    "    for b in range(0, data.shape[0], batch_size):\n",
    "        user_one_hot = np.eye(user_number)[data[b:b+batch_size,0]]\n",
    "        itemi_one_hot = np.eye(item_number)[data[b:b+batch_size,1]]\n",
    "        itemj_one_hot = np.eye(item_number)[data[b:b+batch_size,2]]\n",
    "        sparse_ = np.concatenate((user_one_hot, itemi_one_hot, itemj_one_hot), axis=1)\n",
    "        dense = np.empty((user_one_hot.shape[0], 1), int)\n",
    "\n",
    "        # create items feature \n",
    "        i_feature = items_feature[1].keys()\n",
    "        for fe in i_feature:\n",
    "            # sparse\n",
    "            if fe.split(\"_\")[1] != 'year':\n",
    "                f_map = features_map[fe]\n",
    "                feature_lengh = f_map[list(f_map.keys())[0]].shape[1]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), feature_lengh*2))\n",
    "                for i, item_ij in enumerate(data[b:b+batch_size, 1:3]):\n",
    "                    item_i, item_j = item_ij\n",
    "                    item_i = ile.inverse_transform(np.array([item_i])).item()\n",
    "                    item_j = ile.inverse_transform(np.array([item_j])).item()\n",
    "                    if item_i not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, :feature_lengh] = features_map[fe][item_i].toarray()\n",
    "                    if item_j not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, feature_lengh:] = features_map[fe][item_j].toarray()\n",
    "                # sparse_ = np.concatenate((sparse_, tmp), axis=1)\n",
    "                sparse_ = np.hstack((sparse_, tmp))\n",
    "            # dense\n",
    "            else:\n",
    "                # i = 0\n",
    "                f_map = features_map[fe]\n",
    "                feature_lengh = f_map[list(f_map.keys())[0]].shape[1]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), feature_lengh*2))\n",
    "                for i, item_ij in enumerate(data[b:b+batch_size, 1:3]):\n",
    "                    item_i, item_j = item_ij\n",
    "                    item_i = ile.inverse_transform(np.array([item_i])).item()\n",
    "                    item_j = ile.inverse_transform(np.array([item_j])).item()\n",
    "                    if item_i not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, :feature_lengh] = features_map[fe][item_i].toarray()\n",
    "                    if item_j not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # item_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        # item_feature_onehot = features_map[fe][item].toarray()\n",
    "                        tmp[i, feature_lengh:] = features_map[fe][item_j].toarray()\n",
    "                # dense = np.concatenate((dense, tmp), axis=1)\n",
    "                dense = np.hstack((dense, tmp))\n",
    "\n",
    "        # create user feature\n",
    "        u_feature = users_feature[1].keys()\n",
    "        for fe in u_feature:\n",
    "            # sparse\n",
    "            if fe.split(\"_\")[1] != 'age':\n",
    "                f_map = features_map[fe]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                for i, user in enumerate(data[b:b+batch_size, 0]):\n",
    "                    # i = 0\n",
    "                    user = le.inverse_transform(np.array([user])).item()\n",
    "                    if user not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # user_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        tmp[i] = features_map[fe][user].toarray()\n",
    "                # sparse_ = np.concatenate((sparse_, tmp), axis=1)\n",
    "                sparse_ = np.hstack((sparse_, tmp))\n",
    "                \n",
    "            # dense\n",
    "            else:\n",
    "                f_map = features_map[fe]\n",
    "                tmp = np.zeros((len(data[b:b+batch_size, 1]), f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                for i, user in enumerate(data[b:b+batch_size, 0]):\n",
    "                    # i = 0\n",
    "                    user = le.inverse_transform(np.array([user])).item()\n",
    "                    if user not in features_map[fe].keys():\n",
    "                        # 取第一個鍵值得長度\n",
    "                        # f_map = features_map[fe]\n",
    "                        # user_feature_onehot = np.zeros((f_map[list(f_map.keys())[0]].shape[1]))\n",
    "                        pass\n",
    "                    else:\n",
    "                        tmp[i] = features_map[fe][user].toarray()\n",
    "                # dense = np.concatenate((dense, tmp), axis=1)\n",
    "                dense = np.hstack((dense, tmp))\n",
    "        if b==0:\n",
    "            sparse_matrix = csr_matrix(sparse_)\n",
    "            dense_matrix = dense\n",
    "        else:\n",
    "            sparse_matrix = sparse.vstack((sparse_matrix, csr_matrix(sparse_)))\n",
    "            dense_matrix = np.vstack((dense_matrix, dense))\n",
    "        print(\"[{}/{}] sparse_matrix shape is {}\".format(b, data.shape[0], sparse_matrix.shape))\n",
    "    \n",
    "    return sparse_matrix, dense_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682edb3-cccb-4711-b0da-fa7754ae3070",
   "metadata": {},
   "source": [
    "### MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de72e1bc-5f21-45ac-aeb9-272d3b19aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_movie:[['196' '242' '3']\n",
      " ['186' '302' '3']\n",
      " ['22' '377' '1']]\n",
      "movie_genre:[['1' '3']\n",
      " ['1' '4']\n",
      " ['1' '5']]\n",
      "user_age:[['1' '3']\n",
      " ['2' '6']\n",
      " ['3' '3']]\n",
      "user_occupation:[['1' '1']\n",
      " ['2' '2']\n",
      " ['3' '3']]\n",
      "使用者評分大於三次的共有：(100000, 3)\n",
      "users:  943\n",
      "items:  1682\n",
      "(100000, 3)\n",
      "[0/194300] sparse_matrix shape is (100000, 2666)\n",
      "[100000/194300] sparse_matrix shape is (194300, 2666)\n",
      "(155440, 2676) (38860, 2676)\n",
      "(194300, 2676)\n"
     ]
    }
   ],
   "source": [
    "data = get_movielens()\n",
    "# str to int\n",
    "user_movie = np.array([list(map(int, data)) for data in data['user_movie']])\n",
    "# 濾除使用者評分小於三筆的資料\n",
    "filter_data = user_filter(user_movie, 0)\n",
    "print(f\"使用者評分大於三次的共有：{filter_data.shape}\")\n",
    "# 是否加上假資料\n",
    "fake=True\n",
    "if fake:\n",
    "    # 取得加上使用者未評分的sample假資料\n",
    "    filter_data = get_norating_data(filter_data)\n",
    "    \n",
    "# 取得電影個數及電影個數\n",
    "len_users, movies = np.unique(filter_data[:,0]), np.unique(filter_data[:,1])\n",
    "# 取得訓練資料及測試資料\n",
    "training_data,  testing_data = training_testing(filter_data)\n",
    "\n",
    "users_dict, items_dict, features = get_feature_map(data, 'user_movie')\n",
    "movielens_training_df = generate_with_feature(training_data, users_dict, items_dict, init_col=[\"user\", \"movie\", \"rating\"])\n",
    "movielens_testing_df = generate_with_feature(testing_data, users_dict, items_dict, init_col=[\"user\", \"movie\", \"rating\"])\n",
    "\n",
    "\n",
    "\n",
    "# normalize rating value\n",
    "# training_data[:, 2:3] = normalize(training_data[:, 2:3], axis=0)\n",
    "# testing_data[:, 2:3] = normalize(testing_data[:, 2:3], axis=0)\n",
    "# train_min = training_data[:, 2:3].min()\n",
    "# train_max = training_data[:, 2:3].max()\n",
    "# training_rating = (training_data[:, 2] - train_min)/(train_max-train_min)\n",
    "# test_min = testing_data[:, 2:3].min()\n",
    "# test_max = testing_data[:, 2:3].max()\n",
    "# testing_rating = (testing_data[:, 2:3] - test_min)/(test_max-test_min)\n",
    "print(\"users: \", len(len_users))\n",
    "print(\"items: \", len(movies))\n",
    "\n",
    "# generarte one hot encoding\n",
    "bpr = False\n",
    "if bpr:\n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(training_data, len_users, movies)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    train_uij = np.vstack((uij_pos, uij_neg))\n",
    "    test_uij_pos, test_uij_neg = get_uij(testing_data, len_users, movies)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "    one_hot_x, y, add_fake_data = get_uij_one_hot_feature(data,  'user_movie', train_uij, batch_size=100000)\n",
    "else:\n",
    "    one_hot_x, y, add_fake_data = get_one_hot_feature(data,  'user_movie', batch_size=100000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = training_testing_XY(one_hot_x, y, random_state=int(config['model']['random_state']))\n",
    "training_index, test_index, _, _ = training_testing_XY(add_fake_data, y, random_state=int(config['model']['random_state']))\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(one_hot_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140b967-0b12-4efb-8752-75b341b6018f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9291be6-6e04-47d6-af61-f92487ace79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = get_yelp()\n",
    "# str to int\n",
    "user_business = np.array([list(map(int, data)) for data in data['user_business']])\n",
    "# 濾除使用者評分小於三筆的資料\n",
    "filter_data = user_filter(user_business, 0)\n",
    "# user label encoder\n",
    "le = LabelEncoder()\n",
    "filter_data[:, 0] = le.fit_transform(filter_data[:, 0])\n",
    "filter_data[:, 0] += 1\n",
    "# item label encoder\n",
    "ile = LabelEncoder()\n",
    "filter_data[:, 1] = ile.fit_transform(filter_data[:, 1])\n",
    "filter_data[:, 1] += 1\n",
    "# if want to inverse label \n",
    "# le.inverse_transform(yelp_training_encoder)\n",
    "print(f\"使用者評分大於三次的共有：{filter_data.shape}\")\n",
    "# 是否加上假資料\n",
    "fake=True\n",
    "if fake:\n",
    "    # 取得加上使用者未評分的sample假資料\n",
    "    filter_data = get_norating_data(filter_data)\n",
    "\n",
    "# 取得business個數及users個數\n",
    "yelp_users, business = np.unique(filter_data[:,0]), np.unique(filter_data[:,1])\n",
    "# 取得訓練資料及測試資料\n",
    "yelp_training_data,  yelp_testing_data = training_testing(filter_data)\n",
    "users_dict, items_dict, features = get_feature_map(data, 'user_business')\n",
    "yelp_training_df = generate_with_feature(yelp_training_data, users_dict, items_dict, init_col=[\"user\", \"business\", \"rating\"])\n",
    "yelp_testing_df = generate_with_feature(yelp_testing_data, users_dict, items_dict, init_col=[\"user\", \"business\", \"rating\"])\n",
    "\n",
    "print(\"users: \", len(yelp_users))\n",
    "print(\"items: \", len(business))\n",
    "# generarte one hot encoding\n",
    "bpr = False\n",
    "if bpr:\n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(training_data, yelp_users, business)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    train_uij = np.vstack((uij_pos, uij_neg))\n",
    "    test_uij_pos, test_uij_neg = get_uij(testing_data, yelp_users, business)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "    one_hot_x, y, add_fake_data = get_uij_one_hot_feature(data,  'user_business', train_uij)\n",
    "else:\n",
    "    one_hot_x, y, add_fake_data = get_one_hot_feature(data,  'user_business')\n",
    "\n",
    "# generarte one hot encoding\n",
    "X_train_yelp, X_test_yelp, y_train_yelp, y_test_yelp = training_testing_XY(one_hot_x, y, random_state=int(config['model']['random_state']))\n",
    "training_index_yelp, test_index_yelp, _, _ = training_testing_XY(add_fake_data, y, random_state=int(config['model']['random_state']))\n",
    "print(X_train_yelp.shape, X_test_yelp.shape)\n",
    "print(one_hot_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ba6de-2893-4a33-b9c2-e5a77953b129",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01661c74-3b39-49c2-a121-7002680d2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = get_douban()\n",
    "# str to int\n",
    "user_book = np.array([list(map(int, data)) for data in data['user_book']])\n",
    "# 濾除使用者評分小於三筆的資料\n",
    "filter_data = user_filter(user_book, 0)\n",
    "# user label encoder\n",
    "le = LabelEncoder()\n",
    "filter_data[:, 0] = le.fit_transform(filter_data[:, 0])\n",
    "filter_data[:, 0] += 1\n",
    "# item label encoder\n",
    "ile = LabelEncoder()\n",
    "filter_data[:, 1] = ile.fit_transform(filter_data[:, 1])\n",
    "filter_data[:, 1] += 1\n",
    "print(f\"使用者評分大於三次的共有：{filter_data.shape}\")\n",
    "# 是否加上假資料\n",
    "fake=True\n",
    "if fake:\n",
    "    # 取得加上使用者未評分的sample假資料\n",
    "    filter_data = get_norating_data(filter_data)\n",
    "\n",
    "# 取得business個數及users個數\n",
    "douban_users, books = np.unique(filter_data[:,0]), np.unique(filter_data[:,1])\n",
    "# 取得訓練資料及測試資料\n",
    "douban_training_data,  douban_testing_data = training_testing(filter_data)\n",
    "users_dict, items_dict, features = get_feature_map(data, 'user_book')\n",
    "douban_training_df = generate_with_feature(douban_training_data, users_dict, items_dict, init_col=[\"user\", \"book\", \"rating\"])\n",
    "douban_testing_df = generate_with_feature(douban_testing_data, users_dict, items_dict, init_col=[\"user\", \"book\", \"rating\"])\n",
    "\n",
    "print(\"users: \", len(douban_users))\n",
    "print(\"items: \", len(books))\n",
    "# generarte one hot encoding\n",
    "bpr = False\n",
    "if bpr:\n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(training_data, douban_users, books)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    train_uij = np.vstack((uij_pos, uij_neg))\n",
    "    test_uij_pos, test_uij_neg = get_uij(testing_data, douban_users, books)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "    one_hot_x, y, add_fake_data = get_uij_one_hot_feature(data,  'user_book', train_uij)\n",
    "else:\n",
    "    one_hot_x, y, add_fake_data = get_one_hot_feature(data,  'user_book')\n",
    "\n",
    "# generarte one hot encoding\n",
    "X_train_douban, X_test_douban, y_train_douban, y_test_douban = training_testing_XY(one_hot_x, y, random_state=int(config['model']['random_state']))\n",
    "training_index_douban, test_index_douban, _, _ = training_testing_XY(add_fake_data, y, random_state=int(config['model']['random_state']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100878b3-d40a-4d90-a916-6cdde0b47339",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. User-based Collaborative Filtering (U-CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550a514-2c1a-4a63-933f-ec3210319308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import copy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7207d08-17cf-46cc-836c-2a2928438f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def user_sim_score(users, items, train_data, test_data, k=int(config['CF']['user_K'])):\n",
    "    # make matrix\n",
    "    user_matrix = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "    # 計算bias\n",
    "    bias_matrix = util.get_bias(user_matrix, users, items)\n",
    "    # 計算相似度\n",
    "#     cos, pcc = util.get_sim_array(user_matrix)\n",
    "#     cosine_dis = cos -  np.identity(len(users))\n",
    "#     pcc_dis = pcc -  np.identity(len(users))\n",
    "    \n",
    "#     sim = {\"cos\":cosine_dis, \"pcc\":pcc_dis}\n",
    "    sim = [\"cos\", \"pcc\"]\n",
    "    evaluation = dict()\n",
    "    for s in sim:\n",
    "        delta_list = list()\n",
    "        predict_array = np.zeros((test_matrix.shape))\n",
    "        # sim_dis = sim[s]\n",
    "        sim_array = util.get_sim_array(user_matrix, sim=s)\n",
    "        sim_dis = sim_array -  np.identity(len(users))\n",
    "        for i in tqdm(range(len(users)), desc=f\"UCF predicting {s} score with {k}\"):\n",
    "            # Suv: 取出前K個最相似的使用者相似度 ex:K=3, output=[0.378, 0.353, 0.336]\n",
    "            Suv = heapq.nlargest(k ,sim_dis[i])\n",
    "            # 若i不存在，則跳過\n",
    "            if np.isnan(sim_dis[i]).all():\n",
    "                continue\n",
    "            # top_sim_index: 取出與使用者i最為相似的前K個使用者 ex:K=3, output=[915, 406, 214]\n",
    "            sim_dis_idx = sim_dis[i].tolist()\n",
    "            top_sim_index = list(map(sim_dis_idx.index, heapq.nlargest(k,sim_dis[i])))\n",
    "            # recall\n",
    "            prediction = list()\n",
    "            # 計算相似使用者與使用者i的評分誤差\n",
    "            for item_idx in range(len(items)):\n",
    "                # 取得使用者i的評分(ground truth)\n",
    "                rth = test_matrix[i, item_idx]\n",
    "                # 如果使用者i有進行評分，則才納入計算RMSE\n",
    "                if rth != 0:\n",
    "                    # 之後需剔除對電影m未評分的相似使用者，因此先進行複製，才不會影響下一部電影的計算\n",
    "                    copy_Suv = copy.deepcopy(Suv)\n",
    "                    # R: 若相似使用者對電影 m 有評分則進行調整\n",
    "                    R = list()\n",
    "                    # 判斷相似使用者是否對電影ｍ有評分，若有評分則將原始評分減去該使用者對電影m的bias\n",
    "                    for c, j in enumerate(top_sim_index):\n",
    "                        if  test_matrix[j, item_idx] == 0:\n",
    "                            R.append(0)\n",
    "                            copy_Suv[c] = 0\n",
    "                        else:\n",
    "                            R.append(test_matrix[j, item_idx] - bias_matrix[j, item_idx])\n",
    "                    # 如果所有相似使用者都沒評分則跳過此次計算\n",
    "                    if sum(R) != 0:\n",
    "                        # 預測使用者i對於第m部電影的評分 + 使用者i對電影m的偏差\n",
    "                        Rui = predict(copy_Suv, R) + bias_matrix[i, item_idx]\n",
    "                        # 計算square error\n",
    "                        delta_list.append(util.se(rth, Rui))\n",
    "                        # 儲存預測結果, 並取四捨五入\n",
    "                        predict_array[i, item_idx] = Rui\n",
    "        # 各評估指標\n",
    "        evaluation[f'{s}_rmse']= util.rmse(delta_list)\n",
    "        evaluation[f'{s}_recall@10'] = recall_k(test_matrix, predict_array) \n",
    "        evaluation[f'{s}_NDCG@10']=ndcg_score(test_matrix, predict_array, k=10)\n",
    "        \n",
    "    return evaluation\n",
    "\n",
    "\n",
    "print(\"==========\\nMovielens:\\n==========\")\n",
    "wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"UCF\")\n",
    "wandb_log = WandbLog()\n",
    "movie_reuslt = user_sim_score(len_users, movies, training_data, testing_data)\n",
    "wandb_log.log_evaluation(movie_reuslt)\n",
    "print(movie_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"UCF\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = user_sim_score(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "wandb.init(project=config['general']['douban'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"UCF\")\n",
    "wandb_log = WandbLog()\n",
    "douban_reuslt = user_sim_score(douban_users, books, douban_training_data, douban_testing_data)\n",
    "wandb_log.log_evaluation(douban_reuslt)\n",
    "print(douban_reuslt)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76ff5f-9a67-4ed0-9a0f-f4f94add8de9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Item-based Collaborative Filtering (I-CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b2f05-9860-4be9-b6be-88fb7e345438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from util.mywandb import WandbLog\n",
    "\n",
    "def item_sim_score(users, items, train_data, test_data, k=int(config['CF']['user_K'])):\n",
    "    # make matrix\n",
    "    user_matrix = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "    item_matrix = user_matrix.T \n",
    "    item_test = test_matrix.T\n",
    "    #item_test = sparse.csr_matrix(item_test)\n",
    "    del test_matrix\n",
    "    \n",
    "    # 計算bias\n",
    "    bias_matrix = util.get_bias(user_matrix, users, items)\n",
    "    item_bias = bias_matrix.T\n",
    "    del bias_matrix\n",
    "    del user_matrix\n",
    "    \n",
    "    # 計算相似度\n",
    "    #cos, pcc = util.get_sim_array(item_matrix)\n",
    "    #cosine_dis = cos -  np.identity(len(items))\n",
    "    #cosine_dis = sparse.csr_matrix(cosine_dis)\n",
    "    #pcc_dis = pcc -  np.identity(len(items))\n",
    "    #pcc_dis = sparse.csr_matrix(pcc_dis)\n",
    "    #sim = {\"cos\":cosine_dis, \"pcc\":pcc_dis}\n",
    "    sim = [\"cos\", \"pcc\"]\n",
    "    evaluation = dict()\n",
    "    for s in sim:\n",
    "        delta_list = list()\n",
    "        predict_array = np.zeros((item_test.shape))\n",
    "        # predict array to spase\n",
    "        predict_array = sparse.csr_matrix(predict_array)\n",
    "        sim_array = util.get_sim_array(item_matrix, sim=s)\n",
    "        sim_dis = sim_array -  np.identity(len(items))\n",
    "        # sim_dis = sim[s]\n",
    "        for i in tqdm(range(len(items)), desc=f\"ICF predicting {s} score with {k}\"):\n",
    "            # Siv: 取出前K個最相似的使用者相似度 ex:K=3, output=[0.378, 0.353, 0.336]\n",
    "            Siv = heapq.nlargest(k ,sim_dis[i])\n",
    "            # 若i不存在，則跳過\n",
    "            if np.isnan(sim_dis[i]).all():\n",
    "                continue\n",
    "            sim_dis[i][np.isnan(sim_dis[i])] = 0\n",
    "            # top_sim_index: 取出與使用者i最為相似的前K個使用者 ex:K=3, output=[915, 406, 214]\n",
    "            sim_dis_idx = sim_dis[i].tolist()\n",
    "            top_sim_index = list(map(sim_dis_idx.index, heapq.nlargest(k,sim_dis[i])))\n",
    "            # recall\n",
    "            prediction = list()\n",
    "            # 計算相似電影與電影i的評分誤差\n",
    "            for user_idx in range(len(users)):\n",
    "                # 取得項目i的評分(ground truth)\n",
    "                rth = item_test[i, user_idx]\n",
    "                # 如果使用者i有進行評分，則才納入計算RMSE\n",
    "                if rth != 0:\n",
    "                    # 之後需剔除對電影m未評分的相似使用者，因此先進行複製，才不會影響下一部電影的計算\n",
    "                    copy_Siv = copy.deepcopy(Siv)\n",
    "                    # R: 若相似使用者對電影 m 有評分則進行調整\n",
    "                    R = list()\n",
    "                    # 判斷相似使用者是否對電影ｍ有評分，若有評分則將原始評分減去該使用者對電影m的bias\n",
    "                    for c, j in enumerate(top_sim_index):\n",
    "                        if  item_test[j, user_idx] == 0:\n",
    "                            R.append(0)\n",
    "                            copy_Siv[c] = 0\n",
    "                        else:\n",
    "                            R.append(item_test[j, user_idx] - item_bias[j, user_idx])\n",
    "                    # 如果所有相似使用者都沒評分則跳過此次計算\n",
    "                    if sum(R) != 0:\n",
    "                        # 預測使用者i對於第m部電影的評分 + 使用者i對電影m的偏差\n",
    "                        Rui = predict(copy_Siv, R) + item_bias[i, user_idx]\n",
    "                        # 計算square error\n",
    "                        delta_list.append(util.se(rth, Rui))\n",
    "                        # 儲存預測結果, 並取四捨五入\n",
    "                        if np.isnan(Rui):\n",
    "                            Rui=0\n",
    "                        predict_array[i, user_idx] = Rui\n",
    "        \n",
    "        \n",
    "        # 各評估指標\n",
    "        delta_list = pd.Series(delta_list, dtype=object).fillna(0).tolist()\n",
    "        evaluation[f'{s}_rmse']= util.rmse(delta_list)\n",
    "        evaluation[f'{s}_recall@10'] = recall_k(item_test, predict_array) \n",
    "        evaluation[f'{s}_NDCG@10']=ndcg_score(item_test, predict_array.toarray(), k=10)\n",
    "        \n",
    "    return evaluation\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"ICF\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = item_sim_score(len_users, movies, training_data, testing_data)\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# print(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"ICF\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = item_sim_score(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"ICF\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = item_sim_score(douban_users, books, douban_training_data, douban_testing_data)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555705a2-5424-4878-8f2d-d0c87a5de4d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e38937-3e80-412a-9a71-4e68c459cf54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from util.mywandb import WandbLog\n",
    "\n",
    "# 進行測試資料驗證評估\n",
    "def test(test_data, p, q, gu=False, bu=False, bi=False):\n",
    "    rmse_test = list()\n",
    "\n",
    "    for test in test_data:\n",
    "        user = test[0] - 1\n",
    "        movie = test[1] - 1\n",
    "        # 判斷是否有bias\n",
    "        if gu and bu.any() and bi.any():\n",
    "            rmse_test.append(util.se(test[2], (np.dot(p[user], q[movie]) + gu + bu[user] + bi[movie])))\n",
    "        else:\n",
    "            rmse_test.append(util.se(test[2], (np.dot(p[user], q[movie]))))\n",
    "    return util.rmse(rmse_test)\n",
    "\n",
    "def execute_matrix_factorization(users, items, train_data, test_data):\n",
    "    # 存放測試資料集的rmse結果\n",
    "    MF_bias_testing = list()\n",
    "    # init evaluation\n",
    "    evaluation = dict()\n",
    "    user_item = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "\n",
    "    # init setting global mean\n",
    "    gu= util.get_u(user_item)\n",
    "    # init setting user mean as bias\n",
    "    bu = np.array([util.get_ubias(user_item, i) - gu for i in range(len(users))])\n",
    "    # init setting items mean as bias\n",
    "    bi = np.array([util.get_ibias(user_item, m) - gu for m in range(len(items))])\n",
    "\n",
    "    # init lentent vector\n",
    "    K = int(config[\"MF\"][\"latent_vector_number\"])\n",
    "    # init user lentent matrix\n",
    "    P = np.random.uniform(low=0, high=3, size=(users.max(), K))\n",
    "    # init items lentent matrix\n",
    "    Q = np.random.uniform(low=0, high=3, size=(items.max(), K))\n",
    "\n",
    "    # parameter\n",
    "    epochs = int(config[\"MF\"][\"epochs\"])\n",
    "    alpha = float(config[\"MF\"][\"alpha\"])\n",
    "    l = float(config[\"MF\"][\"learning_rate\"])\n",
    "\n",
    "    # 更新次數, init=100\n",
    "    for epoch in range(epochs):\n",
    "        # 存放 spuare error 結果\n",
    "        se_list = list()\n",
    "        # 針對user有評分過的rating位置進行更新(User Latent Matrix)\n",
    "        for j in range(len(users)):\n",
    "            # 找出被使用者j評分過的電影\n",
    "            # movie_index = [i for i, e in enumerate(user_item[j]) if e != 0]\n",
    "            movie_index = np.nonzero(user_item[j])[0]\n",
    "            for m in movie_index:\n",
    "                # 對u 做偏微分進行ＳＧＤ更新\n",
    "                tmp_gu = gu - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) + l*(gu))\n",
    "                # 對bu 做偏微分進行ＳＧＤ更新\n",
    "                tmp_bu = bu[j] - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) + l*(bu[j]))\n",
    "                # 對bi 做偏微分進行ＳＧＤ更新\n",
    "                tmp_bi = bi[m] - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) + l*(bi[m]))\n",
    "                # 若user item 有值則對Q的相對欄位進行SGD更新, 將更新後user latent matrix先暫存\n",
    "                tmp = Q[m] - alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) * P[j] + l*(Q[m]))\n",
    "                # 更新 movie latent matrix\n",
    "                P[j] -= alpha * (((np.dot(P[j], Q[m]) + gu + bu[j] + bi[m]) - user_item[j,m]) * Q[m] + l*(P[j]))\n",
    "                # 更新 user latent matrix\n",
    "                Q[m] = tmp\n",
    "                # 更新bias\n",
    "                gu = tmp_gu\n",
    "                bu[j] = tmp_bu\n",
    "                bi[m] = tmp_bi\n",
    "                # 計算ＳＥ\n",
    "                se_list.append(util.se(user_item[j, m], (np.dot(P[j], Q[m]) + gu + bu[j] + bi[m])))\n",
    "                \n",
    "        # 進行驗證資料測試\n",
    "        MF_bias_testing.append(test(test_data, P, Q, gu, bu, bi))\n",
    "        if epoch % 9 == 0:\n",
    "            print(f\"[{epoch}/{epochs}] gu={gu}, bu={np.mean(bu)}, bi={np.mean(bi)}, testing error={MF_bias_testing[-1]}\")\n",
    "\n",
    "    # 各評估指標\n",
    "    evaluation['rmse']= MF_bias_testing[-1]\n",
    "    evaluation['recall@10'] = recall_k(test_matrix, np.dot(P, Q.T))\n",
    "    evaluation['NDCG@10'] = ndcg_score(test_matrix, np.dot(P, Q.T))\n",
    "    \n",
    "    return evaluation\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"MF\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = execute_matrix_factorization(len_users, movies, training_data, testing_data)\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# print(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nYelp:\\n==========\")\n",
    "wandb.init(project=config['general']['yelp'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"MF\")\n",
    "wandb_log = WandbLog()\n",
    "yelp_reuslt = execute_matrix_factorization(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "wandb_log.log_evaluation(yelp_reuslt)\n",
    "print(yelp_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "wandb.init(project=config['general']['douban'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"MF\")\n",
    "wandb_log = WandbLog()\n",
    "douban_reuslt = execute_matrix_factorization(douban_users, books, douban_training_data, douban_testing_data)\n",
    "wandb_log.log_evaluation(douban_reuslt)\n",
    "print(douban_reuslt)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345f5f0-cb98-436a-bc18-3d33e399f6cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. BPR-MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed929932-c906-4d20-b84c-3c8329c6d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Movielens:\n",
      "==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3rn2yi43) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ruby-leaf-160</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/3rn2yi43\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_movielens/runs/3rn2yi43</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220429_231524-3rn2yi43/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3rn2yi43). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/baron/HW/Recommender_System/notebook/wandb/run-20220429_232645-1pj7lz2y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/1pj7lz2y\" target=\"_blank\">glorious-snowball-161</a></strong> to <a href=\"https://wandb.ai/baron/recommendation-system_movielens\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data transfer user matrix: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 943/943 [00:00<00:00, 2353.96it/s]\n",
      "data transfer user matrix: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 943/943 [00:00<00:00, 8973.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/943] uij_pos: (239, 4), uij_neg: (238, 4)\n",
      "[300/943] uij_pos: (28185, 4), uij_neg: (27998, 4)\n",
      "[600/943] uij_pos: (59223, 4), uij_neg: (58840, 4)\n",
      "[900/943] uij_pos: (85840, 4), uij_neg: (85286, 4)\n",
      "uij_positive: (89267, 4), uij_negative: (88690, 4)\n",
      "[0/943] uij_pos: (44, 4), uij_neg: (44, 4)\n",
      "[300/943] uij_pos: (7471, 4), uij_neg: (7316, 4)\n",
      "[600/943] uij_pos: (15455, 4), uij_neg: (15150, 4)\n",
      "[900/943] uij_pos: (22434, 4), uij_neg: (21972, 4)\n",
      "testing uij_positive: (23270, 4), testing uij_negative: (22786, 4)\n",
      "[0/100] testing error=0.5530065562885556\n",
      "[9/100] testing error=0.5530065399186914\n",
      "[18/100] testing error=0.5530065492137272\n",
      "[27/100] testing error=0.5530065526123277\n",
      "[36/100] testing error=0.5530065536114757\n",
      "[45/100] testing error=0.5530065539055203\n",
      "[54/100] testing error=0.5530065539935322\n",
      "[63/100] testing error=0.5530065540197368\n",
      "[72/100] testing error=0.553006554027163\n",
      "[81/100] testing error=0.5530065540289968\n",
      "[90/100] testing error=0.5530065540292651\n",
      "[99/100] testing error=0.5530065540291795\n",
      "943 user like item816 more than item768, score is 1.6077519788196017e-11: \n",
      "{'rmse': 0.5530065540291795, 'recall@10': 0.0004220651434499046, 'NDCG@10': 0.24915501459443967}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>NDCG@10</td><td>0.24916</td></tr><tr><td>recall@10</td><td>0.00042</td></tr><tr><td>rmse</td><td>0.55301</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glorious-snowball-161</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/1pj7lz2y\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_movielens/runs/1pj7lz2y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220429_232645-1pj7lz2y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from util.mywandb import WandbLog\n",
    "\n",
    "# 進行測試資料驗證評估\n",
    "def test(test_uij, users, items, p, q, gu=False, bu=False, bi=False):\n",
    "    rmse_test = list()\n",
    "    \n",
    "    \n",
    "    for u, i, j, rank in test_uij:\n",
    "        u_idx = u - 1\n",
    "        i_idx = i - 1\n",
    "        j_idx = j - 1\n",
    "        rui = np.dot(p[u_idx], q[i_idx])\n",
    "        ruj = np.dot(p[u_idx], q[j_idx])\n",
    "        x_uij =  rui - ruj\n",
    "        # sigmoid\n",
    "        exp_x = np.exp(-x_uij)\n",
    "        y_hat = 1/(1 + np.exp(exp_x))\n",
    "        \n",
    "        rmse_test.append(util.se(y_hat, rank))\n",
    "        \n",
    "    return util.rmse(rmse_test)\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "def execute_bpr_matrix_factorization(users, items, train_data, test_data):\n",
    "    # 存放測試資料集的rmse結果\n",
    "    MF_bias_testing = list()\n",
    "    # init evaluation\n",
    "    evaluation = dict()\n",
    "    user_item = get_user_item_matrix(train_data, users, items)\n",
    "    test_matrix = get_user_item_matrix(test_data, users, items)\n",
    "\n",
    "    # init setting global mean\n",
    "    gu= util.get_u(user_item)\n",
    "    # init setting user mean as bias\n",
    "    bu = np.array([util.get_ubias(user_item, i) - gu for i in range(len(users))])\n",
    "    # init setting items mean as bias\n",
    "    bi = np.array([util.get_ibias(user_item, m) - gu for m in range(len(items))])\n",
    "\n",
    "    # init lentent vector\n",
    "    K = int(config[\"MF\"][\"latent_vector_number\"])\n",
    "    # init user lentent matrix\n",
    "    # P = np.random.uniform(low=0, high=3, size=(users.max(), K))\n",
    "    P = np.random.randn(users.max(), K)/10\n",
    "    # init items lentent matrix\n",
    "    # Q = np.random.uniform(low=0, high=3, size=(items.max(), K))\n",
    "    Q = np.random.randn(items.max(), K)/10\n",
    "    \n",
    "    # get uij index\n",
    "    uij_pos, uij_neg = get_uij(train_data, users, items)\n",
    "    print(\"uij_positive: {}, uij_negative: {}\".format(uij_pos.shape, uij_neg.shape))\n",
    "    # uij = np.vstack(uij_pos, uij_neg)\n",
    "    test_uij_pos, test_uij_neg = get_uij(test_data, users, items)\n",
    "    print(\"testing uij_positive: {}, testing uij_negative: {}\".format(test_uij_pos.shape, test_uij_neg.shape))\n",
    "    test_uij = np.vstack((test_uij_pos, test_uij_neg))\n",
    "\n",
    "    # parameter\n",
    "    epochs = int(config[\"MF\"][\"epochs\"])\n",
    "    alpha = float(config[\"MF\"][\"alpha\"])\n",
    "    l = float(config[\"MF\"][\"learning_rate\"])\n",
    "\n",
    "    # 更新次數, init=100\n",
    "    for epoch in range(epochs):\n",
    "        # 針對user有評分過的rating位置進行更新(User Latent Matrix)\n",
    "        for u, i, j, rank in uij_pos:\n",
    "            # 計算x_uij\n",
    "            # rui = np.dot(P[u], Q[i]) + gu + bu[u] + bi[i]\n",
    "            # ruj = np.dot(P[u], Q[j]) + gu + bu[u] + bi[j]\n",
    "            i_idx = i-1\n",
    "            j_idx = j-1\n",
    "            u_idx = u-1\n",
    "            rui = np.dot(P[u_idx], Q[i_idx])\n",
    "            ruj = np.dot(P[u_idx], Q[j_idx])\n",
    "            x_uij =  rui - ruj\n",
    "            \n",
    "            # sigmoid\n",
    "            exp_x = np.exp(-x_uij)\n",
    "            partial_BPR = 1/(1 + np.exp(exp_x))\n",
    "            \n",
    "            # 更新 user latent matrix\n",
    "            New_P= alpha * (partial_BPR*(Q[i_idx]-Q[j_idx]) + l*(P[u_idx]))\n",
    "            # 若user item 有值則對Q的相對欄位進行SGD更新, 將更新後user latent matrix先暫存\n",
    "            Q[i_idx] -=  alpha * (partial_BPR*P[u_idx] + l*(Q[i_idx]))\n",
    "            Q[j_idx] -=  alpha * (partial_BPR*-P[u_idx] + l*(Q[j_idx]))\n",
    "            # 更新 user latent matrix\n",
    "            P[u_idx] = New_P\n",
    "            # # 更新bias\n",
    "            # # 對u 做偏微分進行ＳＧＤ更新\n",
    "            # gu = gu - alpha * ((rui - user_item[j,m]) + l*(gu))\n",
    "            # # 對bu 做偏微分進行ＳＧＤ更新\n",
    "            # bu[j] = bu[j] - alpha * ((rui - user_item[j,m]) + l*(bu[j]))\n",
    "            # # 對bi 做偏微分進行ＳＧＤ更新\n",
    "            # bi[m] = bi[m] - alpha * ((rui - user_item[j,m]) + l*(bi[m]))\n",
    "            \n",
    "\n",
    "                \n",
    "        # 進行驗證資料測試\n",
    "        MF_bias_testing.append(test(test_uij, users, items, P, Q))\n",
    "        if epoch % 9 == 0:\n",
    "            print(f\"[{epoch}/{epochs}] testing error={MF_bias_testing[-1]}\")\n",
    "    \n",
    "    rui = np.dot(P[u_idx], Q[i_idx])\n",
    "    ruj = np.dot(P[u_idx], Q[j_idx])\n",
    "    x_uij =  rui - ruj\n",
    "    print(\"{} user like item{} more than item{}, score is {}: \".format(u, i, j, x_uij))\n",
    "    # 各評估指標\n",
    "    evaluation['rmse']= MF_bias_testing[-1]\n",
    "    evaluation['recall@10'] = recall_k(test_matrix, np.dot(P, Q.T))\n",
    "    evaluation['NDCG@10'] = ndcg_score(test_matrix, np.dot(P, Q.T))\n",
    "    \n",
    "    return evaluation, P, Q\n",
    "\n",
    "print(\"==========\\nMovielens:\\n==========\")\n",
    "wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"BPR-MF\")\n",
    "wandb_log = WandbLog()\n",
    "movie_reuslt, P, Q = execute_bpr_matrix_factorization(len_users, movies, training_data, testing_data)\n",
    "print(movie_reuslt)\n",
    "wandb_log.log_evaluation(movie_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# wandb.init(project=config['general']['yelp'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"MF\")\n",
    "# wandb_log = WandbLog()\n",
    "# yelp_reuslt = execute_matrix_factorization(yelp_users, business, yelp_training_data, yelp_testing_data)\n",
    "# wandb_log.log_evaluation(yelp_reuslt)\n",
    "# print(yelp_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"MF\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_matrix_factorization(douban_users, books, douban_training_data, douban_testing_data)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282af117-a92e-423b-9046-37d7649708f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5. FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac852f2d-998e-4559-a13e-6918187bde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywFM\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_factorization_machine(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} FM Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "\n",
    "        # reshape y\n",
    "        y_train = y_train.reshape(1, -1)[0]\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        fm = pywFM.FM(task='regression')\n",
    "\n",
    "        model = fm.run(X_train, y_train, X_val, y_val)\n",
    "        predict_values = model.predictions\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        kfold.append(util.rmse(predict_values - y_val))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# wandb.init(project=config['general']['movielens'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# movie_reuslt = execute_factorization_machine(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "\n",
    "# wandb_log.log_evaluation(movie_reuslt)\n",
    "# print(movie_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# wandb.init(project=config['general']['yelp'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# yelp_reuslt = execute_factorization_machine(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "# wandb_log.log_evaluation(yelp_reuslt)\n",
    "# print(yelp_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "print(\"==========\\nDouban Book:\\n==========\")\n",
    "wandb.init(project=config['general']['douban'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"FM\")\n",
    "wandb_log = WandbLog()\n",
    "douban_reuslt = execute_factorization_machine(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "wandb_log.log_evaluation(douban_reuslt)\n",
    "print(douban_reuslt)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa178ba6-8d9b-49d5-8ffc-c6df7c4190b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6. BPR-FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d92308f-b439-47b8-8d2f-47936b751813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.7123524561238528, 'recall@10': 0.04213040476104326, 'NDCG@10': 0.29914077644948034}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>NDCG@10</td><td>0.29914</td></tr><tr><td>recall@10</td><td>0.04213</td></tr><tr><td>rmse</td><td>0.71235</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glowing-dream-162</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/bfvwamad\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_movielens/runs/bfvwamad</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220429_233543-bfvwamad/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pywFM\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_bpr_factorization_machine(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} FM Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        \n",
    "        # reshape y\n",
    "        y_train = y_train.reshape(1, -1)[0]\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        fm = pywFM.FM(task='classification')\n",
    "\n",
    "        model = fm.run(X_train, y_train, X_val, y_val)\n",
    "        predict_values = model.predictions\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        print(predict_values - y_val)\n",
    "        kfold.append(util.rmse(list(map(abs, predict_values - y_val))))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"==========\\nMovielens:\\n==========\")\n",
    "wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"BPR-FM\")\n",
    "wandb_log = WandbLog()\n",
    "movie_reuslt = execute_bpr_factorization_machine(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "\n",
    "wandb_log.log_evaluation(movie_reuslt)\n",
    "print(movie_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# wandb.init(project=config['general']['yelp'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# yelp_reuslt = execute_factorization_machine(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "# wandb_log.log_evaluation(yelp_reuslt)\n",
    "# print(yelp_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_factorization_machine(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460fc07-b61b-4a62-b5bc-df381606ea0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 7.GBDT+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "159f1913-085a-46f4-8cae-607b071f536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 1.3435173759332357, 'recall@10': 0.017182727960031178, 'NDCG@10': 0.2678576171164622}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>NDCG@10</td><td>0.26786</td></tr><tr><td>recall@10</td><td>0.01718</td></tr><tr><td>rmse</td><td>1.34352</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">blooming-donkey-164</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/2w2x9hlz\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_movielens/runs/2w2x9hlz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220430_021835-2w2x9hlz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sktools import GradientBoostingFeatureGenerator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_gbdt_lr(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} GBDT+LR Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        \n",
    "        # reshape y\n",
    "        y_train = y_train.ravel()\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        gbf = GradientBoostingFeatureGenerator(regression=True)\n",
    "        lr = LogisticRegression()\n",
    "        pipe = Pipeline([(\"gb_features\", gbf), (\"logistic\", lr)])\n",
    "        \n",
    "        pipe.fit(X_train.toarray(), y_train)\n",
    "\n",
    "        predict_values = pipe.predict(X_val.toarray())\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        kfold.append(util.rmse(list(map(abs, predict_values - y_val))))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"==========\\nMovielens:\\n==========\")\n",
    "wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"GBDT_LR\")\n",
    "wandb_log = WandbLog()\n",
    "movie_reuslt = execute_gbdt_lr(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "print(movie_reuslt)\n",
    "wandb_log.log_evaluation(movie_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# wandb.init(project=config['general']['yelp'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# yelp_reuslt = execute_factorization_machine(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "# wandb_log.log_evaluation(yelp_reuslt)\n",
    "# print(yelp_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_factorization_machine(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee77f90-24a7-4de4-bdb5-e863d29b7a2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 8. XGB-LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3d45a75-fe62-49a0-9e90-0b917edb4158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 1.3514107576601617, 'recall@10': 0.017182727960031178, 'NDCG@10': 0.2678576171164622}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>NDCG@10</td><td>0.26786</td></tr><tr><td>recall@10</td><td>0.01718</td></tr><tr><td>rmse</td><td>1.35141</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silvery-glitter-165</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/2qzhlcen\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_movielens/runs/2qzhlcen</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220430_040000-2qzhlcen/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_xgb_lr(X, y, X_test, y_test, training_index, test_index, users, items):\n",
    "    rating_testing_array = generate_eval_array(y_test, test_index, users, items)\n",
    "    \n",
    "    # kfold = 5\n",
    "    kfold = list()\n",
    "    recall = list()\n",
    "    ndcg = list()\n",
    "    result = dict()\n",
    "    sum_predict_values = 0 \n",
    "    for i in range(5):\n",
    "        print(f\"Start {i} XGB+LR Cross-Validation\")\n",
    "        random_state = random.randint(0, 50)\n",
    "        X_train, X_val, y_train, y_val = training_testing_XY(X, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        _, val_index, _, _ = training_testing_XY(training_index, y, test_size=float(config[\"model\"][\"val_rate\"]), random_state=random_state)\n",
    "        \n",
    "        # reshape y\n",
    "        y_train = y_train.ravel()\n",
    "        y_test = y_test.reshape(1, -1)[0]\n",
    "        y_val = y_val.reshape(1, -1)[0]\n",
    "\n",
    "        # define model\n",
    "        gbf = SelectFromModel(estimator=XGBRegressor(), max_features=100, threshold=-np.inf)\n",
    "        lr = LogisticRegression()\n",
    "        pipe = Pipeline([(\"xgb_features\", gbf), (\"logistic\", lr)])\n",
    "        \n",
    "        pipe.fit(X_train.toarray(), y_train)\n",
    "\n",
    "        predict_values = pipe.predict(X_val.toarray())\n",
    "        predict = generate_eval_array(predict_values, val_index, users, items)\n",
    "        kfold.append(util.rmse(list(map(abs, predict_values - y_val))))\n",
    "        recall.append(recall_k(rating_testing_array, predict))\n",
    "        ndcg.append(ndcg_score(rating_testing_array, predict))\n",
    "        #sum_predict_values += predict_values\n",
    "        clear_output()\n",
    "\n",
    "    result['rmse'] = sum(kfold)/len(kfold) \n",
    "    result['recall@10'] = sum(recall)/len(recall)\n",
    "    result['NDCG@10'] = sum(ndcg)/len(ndcg)\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"==========\\nMovielens:\\n==========\")\n",
    "wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"XGB_LR\")\n",
    "wandb_log = WandbLog()\n",
    "movie_reuslt = execute_xgb_lr(X_train, y_train, X_test, y_test, training_index, test_index, len_users, movies)\n",
    "print(movie_reuslt)\n",
    "wandb_log.log_evaluation(movie_reuslt)\n",
    "wandb.finish()\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# wandb.init(project=config['general']['yelp'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# yelp_reuslt = execute_factorization_machine(X_train_yelp, y_train_yelp, X_test_yelp, y_test_yelp, training_index_yelp, test_index_yelp, yelp_users, business)\n",
    "\n",
    "# wandb_log.log_evaluation(yelp_reuslt)\n",
    "# print(yelp_reuslt)\n",
    "# wandb.finish()\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# wandb.init(project=config['general']['douban'],\n",
    "#                         entity=config['general']['entity'],\n",
    "#                         group=\"BPR-FM\")\n",
    "# wandb_log = WandbLog()\n",
    "# douban_reuslt = execute_factorization_machine(X_train_douban, y_train_douban, X_test_douban, y_test_douban, training_index_douban, test_index_douban, douban_users, books)\n",
    "# wandb_log.log_evaluation(douban_reuslt)\n",
    "# print(douban_reuslt)\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fd429-f996-4335-a26f-338efe74ee54",
   "metadata": {},
   "source": [
    "## 9. NN-based RecSys Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978674b1-f0e1-44c7-b8ac-7e12b7989bb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08cd156a-7d29-43ae-94fb-423513aacc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nn_based_models import DeepCTRModel\n",
    "\n",
    "\n",
    "def deepfm(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"DeepFM\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.DeepFM(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"DeepFM={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def nfm(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"NFM\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.NFM(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"NFM={result}\")\n",
    "    run.finish()\n",
    "    \n",
    "def dcn(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"DCN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.DCN(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"DCN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def wd(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"W&D\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.WD(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"W&D={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def ccpm(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"CCPM\",\n",
    "                        reinit=True)\n",
    "    # no suppot dense\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation', 'user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.CCPM(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"CCPM={result}\")\n",
    "    run.finish()\n",
    "    \n",
    "def fnn(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"FNN\",\n",
    "                        reinit=True)\n",
    "    deer= DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result, _ = deer.FNN(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"FNN={result}\")\n",
    "\n",
    "    run.finish()\n",
    "\n",
    "def ipnn(dataframe, testing_data, test_index, users, movies, inner=True, outter=False):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"IPNN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result, _ = deer.PNN(dataframe, testing_data, test_index, users, movies, inner=inner, outter=outter)\n",
    "    clear_output()\n",
    "    print(f\"IPNN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def opnn(dataframe, testing_data, test_index, users, movies, inner=False, outter=True):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"OPNN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result, _ = deer.PNN(dataframe, testing_data, test_index, users, movies, inner=inner, outter=outter)\n",
    "    clear_output()\n",
    "    print(f\"OPNN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def pin(dataframe, testing_data, test_index, users, movies, inner=True, outter=True):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"PIN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.PNN(dataframe, testing_data, test_index, users, movies, inner=inner, outter=outter)\n",
    "    clear_output()\n",
    "    print(f\"PIN={result}\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4efb099-3ab2-443d-a617-f8f967e03c67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf7981ea-1c09-4332-9a81-bd52e6f3fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPNN={'rmse': 1.6064180360597908, 'recall@10': 0.4741394704996155, 'ndcg@10': 0.8669920862707722}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ndcg@10</td><td>0.86699</td></tr><tr><td>recall@10</td><td>0.47414</td></tr><tr><td>rmse</td><td>1.60642</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-fog-179</strong>: <a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/30xjzh6w\" target=\"_blank\">https://wandb.ai/baron/recommendation-system_movielens/runs/30xjzh6w</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220430_134350-30xjzh6w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 13:56:13.409534: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-04-30 13:56:13.409578: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/baron/HW/Recommender_System/notebook/wandb/run-20220430_135611-37w6y2lw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/recommendation-system_movielens/runs/37w6y2lw\" target=\"_blank\">jolly-moon-180</a></strong> to <a href=\"https://wandb.ai/baron/recommendation-system_movielens\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/438 - 4s - loss: 2.8098 - mse: 2.8097 - val_loss: 2.2331 - val_mse: 2.2328\n",
      "Epoch 2/100\n",
      "438/438 - 2s - loss: 2.2150 - mse: 2.2146 - val_loss: 2.1938 - val_mse: 2.1934\n",
      "Epoch 3/100\n",
      "438/438 - 2s - loss: 2.1422 - mse: 2.1418 - val_loss: 2.1339 - val_mse: 2.1334\n",
      "Epoch 4/100\n",
      "438/438 - 2s - loss: 2.0594 - mse: 2.0588 - val_loss: 2.0999 - val_mse: 2.0992\n",
      "Epoch 5/100\n",
      "438/438 - 2s - loss: 1.9994 - mse: 1.9987 - val_loss: 2.0796 - val_mse: 2.0788\n",
      "Epoch 6/100\n",
      "438/438 - 2s - loss: 1.9492 - mse: 1.9483 - val_loss: 2.0532 - val_mse: 2.0523\n",
      "Epoch 7/100\n",
      "438/438 - 2s - loss: 1.4777 - mse: 1.4731 - val_loss: 2.1833 - val_mse: 2.1787\n",
      "Epoch 49/100\n",
      "438/438 - 2s - loss: 1.4743 - mse: 1.4696 - val_loss: 2.1766 - val_mse: 2.1719\n",
      "Epoch 50/100\n",
      "438/438 - 2s - loss: 1.4730 - mse: 1.4682 - val_loss: 2.1810 - val_mse: 2.1761\n",
      "Epoch 51/100\n",
      "438/438 - 2s - loss: 1.4648 - mse: 1.4599 - val_loss: 2.2161 - val_mse: 2.2112\n",
      "Epoch 52/100\n",
      "438/438 - 2s - loss: 1.4602 - mse: 1.4553 - val_loss: 2.1833 - val_mse: 2.1783\n",
      "Epoch 53/100\n",
      "438/438 - 2s - loss: 1.4552 - mse: 1.4502 - val_loss: 2.1762 - val_mse: 2.1712\n",
      "Epoch 54/100\n",
      "438/438 - 2s - loss: 1.4548 - mse: 1.4497 - val_loss: 2.2179 - val_mse: 2.2128\n",
      "Epoch 55/100\n",
      "438/438 - 2s - loss: 1.4504 - mse: 1.4453 - val_loss: 2.1881 - val_mse: 2.1829\n",
      "Epoch 56/100\n",
      "438/438 - 2s - loss: 1.4472 - mse: 1.4420 - val_loss: 2.1943 - val_mse: 2.1890\n",
      "Epoch 57/100\n",
      "438/438 - 2s - loss: 1.4429 - mse: 1.4376 - val_loss: 2.2196 - val_mse: 2.2143\n",
      "Epoch 58/100\n",
      "438/438 - 2s - loss: 1.4408 - mse: 1.4355 - val_loss: 2.2043 - val_mse: 2.1989\n",
      "Epoch 59/100\n",
      "438/438 - 2s - loss: 1.4382 - mse: 1.4327 - val_loss: 2.1963 - val_mse: 2.1908\n",
      "Epoch 60/100\n",
      "438/438 - 2s - loss: 1.4338 - mse: 1.4283 - val_loss: 2.1858 - val_mse: 2.1803\n",
      "Epoch 61/100\n",
      "438/438 - 2s - loss: 1.4321 - mse: 1.4265 - val_loss: 2.2073 - val_mse: 2.2017\n",
      "Epoch 62/100\n",
      "438/438 - 2s - loss: 1.4298 - mse: 1.4242 - val_loss: 2.2219 - val_mse: 2.2163\n",
      "Epoch 63/100\n",
      "438/438 - 2s - loss: 1.4262 - mse: 1.4205 - val_loss: 2.2052 - val_mse: 2.1995\n",
      "Epoch 64/100\n",
      "438/438 - 2s - loss: 1.4223 - mse: 1.4165 - val_loss: 2.2334 - val_mse: 2.2276\n",
      "Epoch 65/100\n",
      "438/438 - 2s - loss: 1.4207 - mse: 1.4149 - val_loss: 2.2112 - val_mse: 2.2054\n",
      "Epoch 66/100\n",
      "438/438 - 2s - loss: 1.4158 - mse: 1.4099 - val_loss: 2.2332 - val_mse: 2.2273\n",
      "Epoch 67/100\n",
      "438/438 - 2s - loss: 1.4154 - mse: 1.4094 - val_loss: 2.2268 - val_mse: 2.2209\n",
      "Epoch 68/100\n",
      "438/438 - 2s - loss: 1.4128 - mse: 1.4068 - val_loss: 2.2358 - val_mse: 2.2298\n",
      "Epoch 69/100\n",
      "438/438 - 2s - loss: 1.4085 - mse: 1.4024 - val_loss: 2.2468 - val_mse: 2.2407\n",
      "Epoch 70/100\n",
      "438/438 - 2s - loss: 1.4058 - mse: 1.3997 - val_loss: 2.2642 - val_mse: 2.2580\n",
      "Epoch 71/100\n",
      "438/438 - 2s - loss: 1.4011 - mse: 1.3949 - val_loss: 2.2190 - val_mse: 2.2127\n",
      "Epoch 72/100\n",
      "438/438 - 2s - loss: 1.4010 - mse: 1.3947 - val_loss: 2.2134 - val_mse: 2.2071\n",
      "Epoch 73/100\n",
      "438/438 - 2s - loss: 1.3986 - mse: 1.3923 - val_loss: 2.2729 - val_mse: 2.2665\n",
      "Epoch 74/100\n",
      "438/438 - 2s - loss: 1.3951 - mse: 1.3887 - val_loss: 2.2729 - val_mse: 2.2665\n",
      "Epoch 75/100\n",
      "438/438 - 2s - loss: 1.3914 - mse: 1.3849 - val_loss: 2.2603 - val_mse: 2.2538\n",
      "Epoch 76/100\n",
      "438/438 - 2s - loss: 1.3913 - mse: 1.3848 - val_loss: 2.2872 - val_mse: 2.2807\n",
      "Epoch 77/100\n",
      "438/438 - 2s - loss: 1.3855 - mse: 1.3789 - val_loss: 2.2800 - val_mse: 2.2734\n",
      "Epoch 78/100\n",
      "438/438 - 2s - loss: 1.3855 - mse: 1.3788 - val_loss: 2.2857 - val_mse: 2.2790\n",
      "Epoch 79/100\n",
      "438/438 - 2s - loss: 1.3815 - mse: 1.3748 - val_loss: 2.2841 - val_mse: 2.2774\n",
      "Epoch 80/100\n",
      "438/438 - 2s - loss: 1.3804 - mse: 1.3737 - val_loss: 2.2666 - val_mse: 2.2598\n",
      "Epoch 81/100\n",
      "438/438 - 2s - loss: 1.3796 - mse: 1.3727 - val_loss: 2.3003 - val_mse: 2.2935\n",
      "Epoch 82/100\n",
      "438/438 - 2s - loss: 1.3721 - mse: 1.3652 - val_loss: 2.2920 - val_mse: 2.2850\n",
      "Epoch 83/100\n",
      "438/438 - 2s - loss: 1.3706 - mse: 1.3636 - val_loss: 2.3131 - val_mse: 2.3061\n",
      "Epoch 84/100\n",
      "438/438 - 2s - loss: 1.3726 - mse: 1.3656 - val_loss: 2.2999 - val_mse: 2.2929\n",
      "Epoch 85/100\n",
      "438/438 - 2s - loss: 1.3679 - mse: 1.3608 - val_loss: 2.3398 - val_mse: 2.3327\n",
      "Epoch 86/100\n",
      "438/438 - 2s - loss: 1.3650 - mse: 1.3578 - val_loss: 2.3015 - val_mse: 2.2943\n",
      "Epoch 87/100\n",
      "438/438 - 2s - loss: 1.3606 - mse: 1.3534 - val_loss: 2.3132 - val_mse: 2.3060\n",
      "Epoch 88/100\n",
      "438/438 - 2s - loss: 1.3606 - mse: 1.3533 - val_loss: 2.2971 - val_mse: 2.2898\n",
      "Epoch 89/100\n",
      "438/438 - 2s - loss: 1.3598 - mse: 1.3525 - val_loss: 2.2794 - val_mse: 2.2721\n",
      "Epoch 90/100\n",
      "438/438 - 2s - loss: 1.3588 - mse: 1.3514 - val_loss: 2.3316 - val_mse: 2.3242\n",
      "Epoch 91/100\n",
      "438/438 - 2s - loss: 1.3561 - mse: 1.3487 - val_loss: 2.3114 - val_mse: 2.3039\n",
      "Epoch 92/100\n",
      "438/438 - 2s - loss: 1.3513 - mse: 1.3438 - val_loss: 2.3347 - val_mse: 2.3272\n",
      "Epoch 93/100\n",
      "438/438 - 2s - loss: 1.3495 - mse: 1.3419 - val_loss: 2.3176 - val_mse: 2.3100\n",
      "Epoch 94/100\n",
      "438/438 - 2s - loss: 1.3448 - mse: 1.3371 - val_loss: 2.3203 - val_mse: 2.3127\n",
      "Epoch 95/100\n",
      "438/438 - 2s - loss: 1.3447 - mse: 1.3370 - val_loss: 2.3082 - val_mse: 2.3004\n",
      "Epoch 96/100\n",
      "438/438 - 2s - loss: 1.3423 - mse: 1.3345 - val_loss: 2.3800 - val_mse: 2.3723\n",
      "Epoch 97/100\n",
      "438/438 - 2s - loss: 1.3443 - mse: 1.3365 - val_loss: 2.3174 - val_mse: 2.3096\n",
      "Epoch 98/100\n",
      "438/438 - 2s - loss: 1.3404 - mse: 1.3325 - val_loss: 2.3141 - val_mse: 2.3062\n",
      "Epoch 99/100\n",
      "438/438 - 2s - loss: 1.3348 - mse: 1.3269 - val_loss: 2.3411 - val_mse: 2.3332\n",
      "Epoch 100/100\n",
      "438/438 - 2s - loss: 1.3332 - mse: 1.3252 - val_loss: 2.3764 - val_mse: 2.3684\n",
      "Epoch 1/100\n",
      "438/438 - 4s - loss: 2.8840 - mse: 2.8839 - val_loss: 2.2904 - val_mse: 2.2902\n",
      "Epoch 2/100\n",
      "438/438 - 2s - loss: 2.2265 - mse: 2.2262 - val_loss: 2.2079 - val_mse: 2.2075\n",
      "Epoch 3/100\n",
      "438/438 - 2s - loss: 2.1564 - mse: 2.1560 - val_loss: 2.1924 - val_mse: 2.1919\n",
      "Epoch 4/100\n",
      "438/438 - 2s - loss: 2.1056 - mse: 2.1050 - val_loss: 2.1640 - val_mse: 2.1634\n",
      "Epoch 5/100\n",
      "438/438 - 2s - loss: 2.0525 - mse: 2.0518 - val_loss: 2.1333 - val_mse: 2.1326\n",
      "Epoch 6/100\n",
      "438/438 - 2s - loss: 2.0060 - mse: 2.0052 - val_loss: 2.1337 - val_mse: 2.1328\n",
      "Epoch 7/100\n",
      "438/438 - 2s - loss: 1.9647 - mse: 1.9638 - val_loss: 2.1624 - val_mse: 2.1614\n",
      "Epoch 8/100\n",
      "438/438 - 2s - loss: 1.9310 - mse: 1.9301 - val_loss: 2.1100 - val_mse: 2.1090\n",
      "Epoch 9/100\n",
      "438/438 - 2s - loss: 1.9063 - mse: 1.9052 - val_loss: 2.1321 - val_mse: 2.1309\n",
      "Epoch 10/100\n",
      "438/438 - 2s - loss: 1.8789 - mse: 1.8777 - val_loss: 2.1305 - val_mse: 2.1293\n",
      "Epoch 11/100\n",
      "438/438 - 2s - loss: 1.8522 - mse: 1.8509 - val_loss: 2.1284 - val_mse: 2.1270\n",
      "Epoch 12/100\n",
      "438/438 - 2s - loss: 1.8363 - mse: 1.8349 - val_loss: 2.1284 - val_mse: 2.1270\n",
      "Epoch 13/100\n",
      "438/438 - 2s - loss: 1.8138 - mse: 1.8123 - val_loss: 2.1460 - val_mse: 2.1444\n",
      "Epoch 14/100\n",
      "438/438 - 2s - loss: 1.7977 - mse: 1.7961 - val_loss: 2.1513 - val_mse: 2.1497\n",
      "Epoch 15/100\n",
      "438/438 - 2s - loss: 1.7790 - mse: 1.7773 - val_loss: 2.1459 - val_mse: 2.1442\n",
      "Epoch 16/100\n",
      "438/438 - 2s - loss: 1.7674 - mse: 1.7656 - val_loss: 2.1496 - val_mse: 2.1477\n",
      "Epoch 17/100\n",
      "438/438 - 2s - loss: 1.7572 - mse: 1.7553 - val_loss: 2.1821 - val_mse: 2.1802\n",
      "Epoch 18/100\n",
      "438/438 - 2s - loss: 1.7444 - mse: 1.7424 - val_loss: 2.1924 - val_mse: 2.1904\n",
      "Epoch 19/100\n",
      "438/438 - 2s - loss: 1.7295 - mse: 1.7274 - val_loss: 2.1608 - val_mse: 2.1587\n",
      "Epoch 20/100\n",
      "438/438 - 2s - loss: 1.7170 - mse: 1.7148 - val_loss: 2.2239 - val_mse: 2.2217\n",
      "Epoch 21/100\n",
      "438/438 - 2s - loss: 1.7073 - mse: 1.7051 - val_loss: 2.1832 - val_mse: 2.1809\n",
      "Epoch 22/100\n",
      "438/438 - 2s - loss: 1.6982 - mse: 1.6959 - val_loss: 2.2060 - val_mse: 2.2036\n",
      "Epoch 23/100\n",
      "438/438 - 2s - loss: 1.6902 - mse: 1.6878 - val_loss: 2.2462 - val_mse: 2.2437\n",
      "Epoch 24/100\n",
      "438/438 - 2s - loss: 1.6831 - mse: 1.6806 - val_loss: 2.2042 - val_mse: 2.2016\n",
      "Epoch 25/100\n",
      "438/438 - 2s - loss: 1.6746 - mse: 1.6720 - val_loss: 2.2296 - val_mse: 2.2269\n",
      "Epoch 26/100\n",
      "438/438 - 2s - loss: 1.6624 - mse: 1.6597 - val_loss: 2.2444 - val_mse: 2.2417\n",
      "Epoch 27/100\n",
      "438/438 - 2s - loss: 1.6579 - mse: 1.6551 - val_loss: 2.2294 - val_mse: 2.2265\n",
      "Epoch 28/100\n",
      "438/438 - 2s - loss: 1.6541 - mse: 1.6512 - val_loss: 2.2420 - val_mse: 2.2391\n",
      "Epoch 29/100\n",
      "438/438 - 2s - loss: 1.6397 - mse: 1.6367 - val_loss: 2.2312 - val_mse: 2.2282\n",
      "Epoch 30/100\n",
      "438/438 - 2s - loss: 1.6364 - mse: 1.6333 - val_loss: 2.2356 - val_mse: 2.2325\n",
      "Epoch 31/100\n",
      "438/438 - 2s - loss: 1.6317 - mse: 1.6286 - val_loss: 2.2432 - val_mse: 2.2400\n",
      "Epoch 32/100\n",
      "438/438 - 2s - loss: 1.6247 - mse: 1.6215 - val_loss: 2.2564 - val_mse: 2.2532\n",
      "Epoch 33/100\n",
      "438/438 - 2s - loss: 1.6180 - mse: 1.6147 - val_loss: 2.2554 - val_mse: 2.2521\n",
      "Epoch 34/100\n",
      "438/438 - 2s - loss: 1.6137 - mse: 1.6103 - val_loss: 2.2463 - val_mse: 2.2429\n",
      "Epoch 35/100\n",
      "438/438 - 2s - loss: 1.6061 - mse: 1.6027 - val_loss: 2.2737 - val_mse: 2.2703\n",
      "Epoch 36/100\n",
      "438/438 - 2s - loss: 1.6048 - mse: 1.6013 - val_loss: 2.2786 - val_mse: 2.2751\n",
      "Epoch 37/100\n",
      "438/438 - 2s - loss: 1.5982 - mse: 1.5946 - val_loss: 2.2739 - val_mse: 2.2703\n",
      "Epoch 38/100\n",
      "438/438 - 2s - loss: 1.5941 - mse: 1.5905 - val_loss: 2.2737 - val_mse: 2.2700\n",
      "Epoch 39/100\n",
      "438/438 - 2s - loss: 1.5882 - mse: 1.5845 - val_loss: 2.2539 - val_mse: 2.2502\n",
      "Epoch 40/100\n",
      "438/438 - 2s - loss: 1.5825 - mse: 1.5787 - val_loss: 2.2750 - val_mse: 2.2712\n",
      "Epoch 41/100\n",
      "438/438 - 2s - loss: 1.5789 - mse: 1.5751 - val_loss: 2.2987 - val_mse: 2.2948\n",
      "Epoch 42/100\n",
      "438/438 - 2s - loss: 1.5756 - mse: 1.5716 - val_loss: 2.3056 - val_mse: 2.3016\n",
      "Epoch 43/100\n",
      "438/438 - 2s - loss: 1.5683 - mse: 1.5642 - val_loss: 2.3137 - val_mse: 2.3096\n",
      "Epoch 44/100\n",
      "438/438 - 2s - loss: 1.5655 - mse: 1.5614 - val_loss: 2.3058 - val_mse: 2.3017\n",
      "Epoch 45/100\n",
      "438/438 - 2s - loss: 1.5598 - mse: 1.5557 - val_loss: 2.3240 - val_mse: 2.3198\n",
      "Epoch 46/100\n",
      "438/438 - 2s - loss: 1.5567 - mse: 1.5525 - val_loss: 2.2828 - val_mse: 2.2785\n",
      "Epoch 47/100\n",
      "438/438 - 2s - loss: 1.5531 - mse: 1.5488 - val_loss: 2.3240 - val_mse: 2.3197\n",
      "Epoch 48/100\n",
      "438/438 - 2s - loss: 1.5538 - mse: 1.5494 - val_loss: 2.3080 - val_mse: 2.3036\n",
      "Epoch 49/100\n",
      "438/438 - 2s - loss: 1.5448 - mse: 1.5404 - val_loss: 2.3020 - val_mse: 2.2976\n",
      "Epoch 50/100\n",
      "438/438 - 2s - loss: 1.5403 - mse: 1.5358 - val_loss: 2.3208 - val_mse: 2.3162\n",
      "Epoch 51/100\n",
      "438/438 - 2s - loss: 1.5352 - mse: 1.5306 - val_loss: 2.3469 - val_mse: 2.3423\n",
      "Epoch 52/100\n",
      "438/438 - 2s - loss: 1.5360 - mse: 1.5314 - val_loss: 2.3156 - val_mse: 2.3110\n",
      "Epoch 53/100\n",
      "438/438 - 2s - loss: 1.5342 - mse: 1.5295 - val_loss: 2.3396 - val_mse: 2.3349\n",
      "Epoch 54/100\n",
      "438/438 - 2s - loss: 1.5278 - mse: 1.5230 - val_loss: 2.3695 - val_mse: 2.3647\n",
      "Epoch 55/100\n",
      "438/438 - 2s - loss: 1.5250 - mse: 1.5202 - val_loss: 2.3374 - val_mse: 2.3325\n",
      "Epoch 56/100\n",
      "438/438 - 2s - loss: 1.5169 - mse: 1.5120 - val_loss: 2.3300 - val_mse: 2.3251\n",
      "Epoch 57/100\n",
      "438/438 - 2s - loss: 1.5191 - mse: 1.5142 - val_loss: 2.3438 - val_mse: 2.3389\n",
      "Epoch 58/100\n",
      "438/438 - 2s - loss: 1.5137 - mse: 1.5087 - val_loss: 2.3500 - val_mse: 2.3449\n",
      "Epoch 59/100\n",
      "438/438 - 2s - loss: 1.5107 - mse: 1.5056 - val_loss: 2.3267 - val_mse: 2.3215\n",
      "Epoch 60/100\n",
      "438/438 - 2s - loss: 1.5050 - mse: 1.4999 - val_loss: 2.3536 - val_mse: 2.3484\n",
      "Epoch 61/100\n",
      "438/438 - 2s - loss: 1.5021 - mse: 1.4969 - val_loss: 2.3376 - val_mse: 2.3324\n",
      "Epoch 62/100\n",
      "438/438 - 2s - loss: 1.4996 - mse: 1.4943 - val_loss: 2.3685 - val_mse: 2.3632\n",
      "Epoch 63/100\n",
      "438/438 - 2s - loss: 1.4965 - mse: 1.4911 - val_loss: 2.3905 - val_mse: 2.3851\n",
      "Epoch 64/100\n",
      "438/438 - 2s - loss: 1.4909 - mse: 1.4855 - val_loss: 2.3826 - val_mse: 2.3772\n",
      "Epoch 65/100\n",
      "438/438 - 2s - loss: 1.4922 - mse: 1.4867 - val_loss: 2.3840 - val_mse: 2.3785\n",
      "Epoch 66/100\n",
      "438/438 - 2s - loss: 1.4849 - mse: 1.4793 - val_loss: 2.3742 - val_mse: 2.3686\n",
      "Epoch 67/100\n",
      "438/438 - 2s - loss: 1.4884 - mse: 1.4828 - val_loss: 2.3691 - val_mse: 2.3634\n",
      "Epoch 68/100\n",
      "438/438 - 2s - loss: 1.4799 - mse: 1.4742 - val_loss: 2.3943 - val_mse: 2.3887\n",
      "Epoch 69/100\n",
      "438/438 - 2s - loss: 1.4777 - mse: 1.4720 - val_loss: 2.3935 - val_mse: 2.3877\n",
      "Epoch 70/100\n",
      "438/438 - 2s - loss: 1.4771 - mse: 1.4714 - val_loss: 2.3734 - val_mse: 2.3676\n",
      "Epoch 71/100\n",
      "438/438 - 2s - loss: 1.4698 - mse: 1.4639 - val_loss: 2.3841 - val_mse: 2.3783\n",
      "Epoch 72/100\n",
      "438/438 - 2s - loss: 1.4673 - mse: 1.4614 - val_loss: 2.3838 - val_mse: 2.3778\n",
      "Epoch 73/100\n",
      "438/438 - 2s - loss: 1.4687 - mse: 1.4627 - val_loss: 2.3633 - val_mse: 2.3573\n",
      "Epoch 74/100\n",
      "438/438 - 2s - loss: 1.4613 - mse: 1.4552 - val_loss: 2.3903 - val_mse: 2.3843\n",
      "Epoch 75/100\n",
      "438/438 - 2s - loss: 1.4670 - mse: 1.4610 - val_loss: 2.3680 - val_mse: 2.3619\n",
      "Epoch 76/100\n",
      "438/438 - 2s - loss: 1.4569 - mse: 1.4508 - val_loss: 2.3754 - val_mse: 2.3693\n",
      "Epoch 77/100\n",
      "438/438 - 2s - loss: 1.4538 - mse: 1.4476 - val_loss: 2.4392 - val_mse: 2.4330\n",
      "Epoch 78/100\n",
      "438/438 - 2s - loss: 1.4514 - mse: 1.4451 - val_loss: 2.4000 - val_mse: 2.3937\n",
      "Epoch 79/100\n",
      "438/438 - 2s - loss: 1.4476 - mse: 1.4413 - val_loss: 2.4108 - val_mse: 2.4045\n",
      "Epoch 80/100\n",
      "438/438 - 2s - loss: 1.4451 - mse: 1.4388 - val_loss: 2.4240 - val_mse: 2.4176\n",
      "Epoch 81/100\n",
      "438/438 - 2s - loss: 1.4482 - mse: 1.4417 - val_loss: 2.4574 - val_mse: 2.4510\n",
      "Epoch 82/100\n",
      "438/438 - 2s - loss: 1.4426 - mse: 1.4361 - val_loss: 2.4332 - val_mse: 2.4267\n",
      "Epoch 83/100\n",
      "438/438 - 2s - loss: 1.4407 - mse: 1.4341 - val_loss: 2.4182 - val_mse: 2.4116\n",
      "Epoch 84/100\n",
      "438/438 - 2s - loss: 1.4372 - mse: 1.4306 - val_loss: 2.3799 - val_mse: 2.3733\n",
      "Epoch 85/100\n",
      "438/438 - 2s - loss: 1.4356 - mse: 1.4290 - val_loss: 2.4155 - val_mse: 2.4088\n",
      "Epoch 86/100\n",
      "438/438 - 2s - loss: 1.4324 - mse: 1.4257 - val_loss: 2.4465 - val_mse: 2.4398\n",
      "Epoch 87/100\n",
      "438/438 - 2s - loss: 1.4302 - mse: 1.4235 - val_loss: 2.4100 - val_mse: 2.4032\n",
      "Epoch 88/100\n",
      "438/438 - 2s - loss: 1.4259 - mse: 1.4191 - val_loss: 2.4605 - val_mse: 2.4536\n",
      "Epoch 89/100\n",
      "438/438 - 2s - loss: 1.4269 - mse: 1.4201 - val_loss: 2.4557 - val_mse: 2.4488\n",
      "Epoch 90/100\n",
      "438/438 - 2s - loss: 1.4216 - mse: 1.4146 - val_loss: 2.4330 - val_mse: 2.4260\n",
      "Epoch 91/100\n",
      "438/438 - 2s - loss: 1.4194 - mse: 1.4124 - val_loss: 2.4414 - val_mse: 2.4344\n",
      "Epoch 92/100\n",
      "438/438 - 2s - loss: 1.4150 - mse: 1.4080 - val_loss: 2.4269 - val_mse: 2.4198\n",
      "Epoch 93/100\n",
      "438/438 - 2s - loss: 1.4172 - mse: 1.4101 - val_loss: 2.4422 - val_mse: 2.4351\n",
      "Epoch 94/100\n",
      "438/438 - 2s - loss: 1.4132 - mse: 1.4061 - val_loss: 2.4583 - val_mse: 2.4511\n",
      "Epoch 95/100\n",
      "438/438 - 2s - loss: 1.4107 - mse: 1.4034 - val_loss: 2.4413 - val_mse: 2.4340\n",
      "Epoch 96/100\n",
      "438/438 - 2s - loss: 1.4069 - mse: 1.3996 - val_loss: 2.4799 - val_mse: 2.4725\n",
      "Epoch 97/100\n",
      "438/438 - 2s - loss: 1.4034 - mse: 1.3961 - val_loss: 2.4541 - val_mse: 2.4467\n",
      "Epoch 98/100\n",
      "438/438 - 2s - loss: 1.4005 - mse: 1.3931 - val_loss: 2.4655 - val_mse: 2.4581\n",
      "Epoch 99/100\n",
      "438/438 - 2s - loss: 1.3995 - mse: 1.3921 - val_loss: 2.4661 - val_mse: 2.4587\n",
      "Epoch 100/100\n",
      "438/438 - 2s - loss: 1.3989 - mse: 1.3914 - val_loss: 2.4824 - val_mse: 2.4749\n",
      "Epoch 1/100\n",
      "438/438 - 4s - loss: 2.9821 - mse: 2.9819 - val_loss: 2.2721 - val_mse: 2.2718\n",
      "Epoch 2/100\n",
      "438/438 - 2s - loss: 2.2251 - mse: 2.2248 - val_loss: 2.2023 - val_mse: 2.2019\n",
      "Epoch 3/100\n",
      "438/438 - 2s - loss: 2.1568 - mse: 2.1564 - val_loss: 2.1799 - val_mse: 2.1795\n",
      "Epoch 4/100\n",
      "438/438 - 2s - loss: 2.1034 - mse: 2.1029 - val_loss: 2.1640 - val_mse: 2.1634\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m opnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 3. Convolutional Click Prediction Model \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mccpm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovielens_training_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovielens_testing_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlen_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 4. neumf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 5. Wide&Deep\u001b[39;00m\n\u001b[1;32m     10\u001b[0m wd(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mccpm\u001b[0;34m(dataframe, testing_data, test_index, users, movies)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# no suppot dense\u001b[39;00m\n\u001b[1;32m     62\u001b[0m deer \u001b[38;5;241m=\u001b[39m DeepCTRModel(sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_genre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_occupation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_age\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     63\u001b[0m                     y\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 64\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdeer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCCPM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m clear_output()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCPM=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/HW/Recommender_System/models/nn_based_models.py:185\u001b[0m, in \u001b[0;36mCCPM\u001b[0;34m(self, dataframe, test_df, test_index, users, items)\u001b[0m\n\u001b[1;32m    182\u001b[0m val_model_input \u001b[38;5;241m=\u001b[39m {name:val[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m feature_names}\n\u001b[1;32m    184\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__models\u001b[38;5;241m.\u001b[39mCCPM(linear_feature_columns, dnn_feature_columns, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 185\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    186\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m], )\n\u001b[1;32m    187\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_model_input, train[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__target]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m    188\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__training_epochs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, )\n\u001b[1;32m    189\u001b[0m pred_ans \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_model_input, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1131\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1117\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_frame \u001b[38;5;241m=\u001b[39m tf_inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\n\u001b[1;32m   1118\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mDataHandler(\n\u001b[1;32m   1119\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1120\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1130\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1143\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1388\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1389\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1391\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:862\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(\"==========\\nMovielens:\\n==========\")\n",
    "# # 1. FM-supported Neural Networks\n",
    "# fnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 2. Product-based Neural Networks\n",
    "# ipnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# opnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# 3. Convolutional Click Prediction Model \n",
    "ccpm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# 4. neumf\n",
    "# 5. Wide&Deep\n",
    "wd(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# 6. Deep Drossing\n",
    "dcn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# 7. Neural Factorization Machine\n",
    "nfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# 8. Deep Factorization Machine\n",
    "deepfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "\n",
    "# print(\"==========\\nYelp:\\n==========\")\n",
    "# # 1. FM-supported Neural Networks\n",
    "# fnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 2. Product-based Neural Networks\n",
    "# ipnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# opnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 3. Convolutional Click Prediction Model \n",
    "# ccpm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 4. neumf\n",
    "# # 5. Wide&Deep\n",
    "# wd(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 6. Deep Drossing\n",
    "# dcn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 7. Neural Factorization Machine\n",
    "# nfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 8. Deep Factorization Machine\n",
    "# deepfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "\n",
    "# print(\"==========\\nDouban Book:\\n==========\")\n",
    "# # 1. FM-supported Neural Networks\n",
    "# fnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 2. Product-based Neural Networks\n",
    "# ipnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# opnn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 3. Convolutional Click Prediction Model \n",
    "# ccpm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 4. neumf\n",
    "# # 5. Wide&Deep\n",
    "# wd(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 6. Deep Drossing\n",
    "# dcn(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 7. Neural Factorization Machine\n",
    "# nfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 8. Deep Factorization Machine\n",
    "# deepfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f83b5-a90d-4570-b030-70937d006dfe",
   "metadata": {},
   "source": [
    "## 10. Recent NN-based RecSys Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5eaab9-115a-4f2b-bd71-7bb692e6c27d",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9cdc365-b79b-4928-9119-e1eb0723d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nn_based_models import DeepCTRModel\n",
    "\n",
    "def din(train_df, test_df, test_index, users, movies, watch_history = ['movie', 'movie_genre'], target=\"rating\"):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"DIN\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.DIN(train_df, test_df, test_index, users, movies, watch_history, target)\n",
    "    clear_output()\n",
    "    print(f\"DIN={result}\")\n",
    "    run.finish()\n",
    "\n",
    "def xdeepfm(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"xDeepFM\",\n",
    "                        reinit=True)\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation'],\n",
    "                        dense=['user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.xDeepFM(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"xDeepFM={result}\")\n",
    "    run.finish()\n",
    "    \n",
    "def afm(dataframe, testing_data, test_index, users, movies):\n",
    "    run = wandb.init(project=config['general']['movielens'],\n",
    "                        entity=config['general']['entity'],\n",
    "                        group=\"AFM\",\n",
    "                        reinit=True)\n",
    "    # no dense\n",
    "    deer = DeepCTRModel(sparse=['user', 'movie', 'movie_genre', 'user_occupation', 'user_age'],\n",
    "                        y=['rating'])\n",
    "    result = deer.AFM(dataframe, testing_data, test_index, users, movies)\n",
    "    clear_output()\n",
    "    print(f\"AFM={result}\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765641d-6037-4366-9e63-a8fb1cbb78c4",
   "metadata": {},
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa6504-66b8-49ab-829b-f4cb09ddd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Attentional Factorization Machines\n",
    "# afm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# # 3. xDeepFM\n",
    "# xdeepfm(movielens_training_df, movielens_testing_df, test_index, len_users, movies)\n",
    "# 4. Deep Interest Network\n",
    "din(movielens_training_df, movielens_testing_df, test_index, len_users, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df43df0-cdcf-498f-bf51-a83351eb0546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
