{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60aa6fb8-85b1-46de-9707-06d4c579f0b1",
   "metadata": {},
   "source": [
    "# 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93391d63-9c0b-44d3-8583-8f1184a95d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5fe571-06f7-4208-85da-b4a59f2edfac",
   "metadata": {},
   "source": [
    "## 0.1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff26504-f3e0-4e8f-98b6-c1392deb1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n",
      "[[      196       242         3 881250949]\n",
      " [      186       302         3 891717742]\n",
      " [       22       377         1 878887116]\n",
      " [      244        51         2 880606923]\n",
      " [      166       346         1 886397596]]\n"
     ]
    }
   ],
   "source": [
    "# 資料位置設置\n",
    "data_path = \"../data/ratings.data\"\n",
    "\n",
    "# 讀取資料\n",
    "data = np.loadtxt(data_path, dtype=int)\n",
    "print(data.shape)\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce71308-9800-4f23-97ba-075fc7d6e476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943,) (1682,)\n"
     ]
    }
   ],
   "source": [
    "# 存取使用者及電影名稱\n",
    "user = np.unique(data[:,0])\n",
    "movie = np.unique(data[:,1])\n",
    "print(user.shape, movie.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc9e6f-0b90-47e0-b4dc-33b147d7f6d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.2. split training data & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ecc1b03-c97a-46f8-8489-549ad1102567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 4) (25000, 4)\n"
     ]
    }
   ],
   "source": [
    "# 將資料切分為訓練資料及測試資料\n",
    "train_data, test_data = train_test_split(data, test_size = 0.25, random_state=42)\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2474969-7a95-4f57-b1a5-0c9c84e8a40a",
   "metadata": {},
   "source": [
    "# 1. Collaborative Filtering (CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93489fd8-4997-4ce2-bdf2-2c20ffdb0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 針對向量非0地方做計算\n",
    "def non_zero_mean(arr):\n",
    "    exist = arr != 0\n",
    "    total = arr.sum(axis = 1)\n",
    "    exist_number = exist.sum(axis=1)\n",
    "    \n",
    "    return np.reshape(total/exist_number, (-1, 1))\n",
    "\n",
    "# 針對單一向量非0地方做計算\n",
    "def non_zero_vec_mean(vec):\n",
    "    exist = vec != 0\n",
    "    total = vec.sum()\n",
    "    if total == 0: return 0\n",
    "    exist_number = exist.sum()\n",
    "    \n",
    "    return total/exist_number\n",
    "\n",
    "\n",
    "# 取得整體平均\n",
    "def get_u():    \n",
    "    return np.mean(user_matrix)\n",
    "    \n",
    "    \n",
    "# 計算向量長度\n",
    "def norm_1(v):\n",
    "    return np.sum(np.absolute(v))\n",
    "\n",
    "# 計算兩個向量的 cosine 相似度\n",
    "def cos_sim(a, b):\n",
    "    return np.inner(a,b) / (norm_1(a)*norm_1(b))\n",
    "\n",
    "# 計算兩個向量的 Pearson Correlation Coefficient 相似度\n",
    "def pcc_sim(a, b):\n",
    "    return np.inner(a-np.mean(a), b-np.mean(b)) /( np.sqrt(np.sum(np.power((a-np.mean(a)), 2))) * np.sqrt(np.sum(np.power((b-np.mean(b)), 2))) )\n",
    "    \n",
    "\n",
    "# 計算兩兩之間的相似度，且自己與自己的相似度調整為0\n",
    "def get_sim_dict(target, arr):\n",
    "    # init 目標相似度名單(cos & pcc)\n",
    "    cos_dict = dict()\n",
    "    pcc_dict = dict()\n",
    "    \n",
    "    for u in tqdm(range(len(target)), desc='caculator u & v similar'):\n",
    "        # init 目標 u 跟 v 的相似度\n",
    "        uv_cos = list()\n",
    "        uv_pcc = list()\n",
    "        for v in range(len(user)):\n",
    "            if u != v:\n",
    "                # 計算使用者u、v的cosine\n",
    "                uv_cos.append(cos_sim(arr[u], arr[v]))\n",
    "                uv_pcc.append(pcc_sim(arr[u], arr[v]))\n",
    "            else:\n",
    "                # 為了保持index不會跑掉，因此在自己的位置不做計算且補0\n",
    "                uv_cos.append(0)\n",
    "                uv_pcc.append(0)\n",
    "        cos_dict[u] = uv_cos\n",
    "        pcc_dict[u] = uv_pcc\n",
    "    \n",
    "    return cos_dict, pcc_dict\n",
    "\n",
    "# 推測評分\n",
    "def predict(S, R):\n",
    "    return np.dot(S,R)/np.sum(S)\n",
    "\n",
    "# Vistualize Result\n",
    "def plot_result(df):\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(15,10))\n",
    "    for c in df.columns:\n",
    "        if c != \"K\":\n",
    "            g = sns.lineplot(data=df, x=\"K\", y=c, label=c)\n",
    "    g.set(ylabel = \"RMSE\")\n",
    "\n",
    "\n",
    "# 偏差修正\n",
    "def get_bias(u, user, item):\n",
    "    bu = get_ubias(user) - u\n",
    "    bi = get_ibias(item) - u\n",
    "    \n",
    "    return u+bu+bi\n",
    "\n",
    "# item bias\n",
    "def get_ibias(i):\n",
    "    return non_zero_vec_mean(user_matrix[:,i]) \n",
    "\n",
    "# user bias\n",
    "def get_ubias(u):\n",
    "    return non_zero_vec_mean(user_matrix[u]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af059e84-c80b-4111-9f9a-c2f366a45877",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. User-based Collaborative Filtering (U-CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84b0fb5-9d73-41f8-8a61-27ccb1737bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data transfer user matrix: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 943/943 [00:13<00:00, 71.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# init user_matrix as zero matrix\n",
    "user_matrix = np.zeros((len(user), len(movie)))\n",
    "\n",
    "for u in tqdm(user, desc='data transfer user matrix'):\n",
    "    '''\n",
    "    train_data[train_data[:,0] == u] : 過濾出u使用者所有的評分資料\n",
    "    train_data[train_data[:,0] == u][:,1]: 取得u使用者所有評分過的電影名稱\n",
    "    '''\n",
    "    rate_index = train_data[train_data[:,0] == u][:,1]\n",
    "    for rate in rate_index:\n",
    "        '''\n",
    "        user_matrix[u-1, rate-1]: 欲設置的rateing位置\n",
    "        train_data[(train_data[:,0] == u) & (train_data[:,1] == rate)]: 取出u使用者對於評論過特定電影的資料\n",
    "        '''\n",
    "        user_matrix[u-1, rate-1] = train_data[(train_data[:,0] == u) & (train_data[:,1] == rate)][:,2].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48102b89-9d5b-4ccc-b806-e907510cd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 計算使用者平均評分\n",
    "# user_mean = non_zero_mean(user_matrix)\n",
    "# # 使用個別使用者平均校正使用者對電影的評分\n",
    "# user_adjust = np.where(user_matrix == 0, user_matrix, user_matrix-user_mean)\n",
    "# print(f\"user_matrix:\\n{user_matrix} \\n\\nafter adjust:\\n{user_adjust}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f5d0fe-8c3d-4612-845a-7aae2f23052a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "caculator u & v similar: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 943/943 [02:17<00:00,  6.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# 取得user間的相似度名單\n",
    "cos_dict, pcc_dict = get_sim_dict(user, user_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9bca1-e79b-4954-a6f2-dfa82368bae7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1.1.  User‐Based CF use Cosine result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745cd8e-2709-46e2-a060-84e6c18232cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predicting K = 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 943/943 [02:33<00:00,  6.14it/s]\n",
      "predicting K = 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 943/943 [03:05<00:00,  5.08it/s]\n",
      "predicting K = 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 943/943 [03:37<00:00,  4.33it/s]\n",
      "predicting K = 6:  31%|████████████████████████████████████████████████▎                                                                                                         | 296/943 [01:18<02:51,  3.77it/s]"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Q: 感覺adjust先減去bias再算sim效果差不多，需驗算。\n",
    "#\n",
    "# 與不同K個使用者相似程度比較\n",
    "K = [3,4,5,6,7,8,9,10,20,30,40,50, 60,70,80,90,100]\n",
    "# 整體平均\n",
    "u = get_u()\n",
    "ucf_cos = list()\n",
    "\n",
    "# 針對不同相似使用者個數進行分析\n",
    "for k in K:\n",
    "    predict_matrix = np.zeros((len(user), len(movie)))\n",
    "    # 取出前K個相似度最大的電影名稱，並設置於N\n",
    "    for i in tqdm(cos_dict.keys(), desc=f\"predicting K = {k}\"):\n",
    "        # Suv: 取出前K個最相似的使用者相似度 ex:K=3, output=[0.378, 0.353, 0.336]\n",
    "        Suv = heapq.nlargest(k,cos_dict[i])\n",
    "        # top_sim_index: 取出前K個最相似的使用者相似度(index) ex:K=3, output=[915, 406, 214]\n",
    "        top_sim_index = list(map(cos_dict[i].index, heapq.nlargest(k,cos_dict[i])))\n",
    "        # 利用相似的使用者對使用者i的每一部電影做評分預測\n",
    "        for m in range(len(movie)):\n",
    "            # R: 相似使用者對調整後電影 m 的評分\n",
    "            R = [user_matrix[:,m][j] - get_bias(u, i, j) for j in top_sim_index]\n",
    "            # 預測使用者u對於第m部電影的評分 + 使用者i及電影m的偏差\n",
    "            Rui = predict(Suv, R) + get_bias(u, i, m)\n",
    "            predict_matrix[i, m] = Rui\n",
    "    ucf_cos.append(mse(user_matrix, predict_matrix, squared = False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65173eef-ddd9-409b-a156-36875ab7e299",
   "metadata": {},
   "source": [
    "### 1.1.2. User‐Based CF use Pearson Correlation Coefficient result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6e2f3-6c7f-4c16-b7d0-7e528557e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 與不同K個使用者相似程度比較\n",
    "K = [3,4,5,6,7,8,9,10,20,30,40,50, 60,70,80,90,100]\n",
    "# 整體平均\n",
    "u = get_u()\n",
    "ucf_pcc = list()\n",
    "\n",
    "# 針對不同相似使用者個數進行分析\n",
    "for k in K:\n",
    "    predict_matrix = np.zeros((len(user), len(movie)))\n",
    "    # 取出前K個相似度最大的電影名稱，並設置於N\n",
    "    for i in tqdm(pcc_dict.keys(), desc=f\"predicting K = {k}\"):\n",
    "        # Suv: 取出前K個最相似的使用者相似度 ex:K=3, output=[0.378, 0.353, 0.336]\n",
    "        Suv = heapq.nlargest(k,pcc_dict[i])\n",
    "        # top_sim_index: 取出前K個最相似的使用者相似度(index) ex:K=3, output=[915, 406, 214]\n",
    "        top_sim_index = list(map(pcc_dict[i].index, heapq.nlargest(k,pcc_dict[i])))\n",
    "        # 利用相似的使用者對使用者u的每一部電影做評分預測\n",
    "        for m in range(len(movie)):\n",
    "            # R: 相似使用者對調整後電影 m 的評分\n",
    "            R = [user_matrix[:,m][j] - get_bias(u, i, j)  for j in top_sim_index]\n",
    "            # 預測使用者u對於第m部電影的評分\n",
    "            Rui = predict(Suv, R) + get_bias(u, i, m)\n",
    "            predict_matrix[i, m] = Rui\n",
    "    ucf_pcc.append(mse(user_matrix, predict_matrix, squared = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42532276-0dea-4692-b327-3b05479b2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將K轉成字串形式\n",
    "str_k = list(map(lambda x:str(x), K))\n",
    "# numpy to pandas\n",
    "df = pd.DataFrame({\"K\": str_k, \"U-CF-cos\":ucf_cos, \"U-CF-pcc\":ucf_pcc})\n",
    "plot_result(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e69f1-de0e-41d9-a4e8-19ee2631b231",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2. Item-based Collaborative Filtering (I-CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9a112-6d6f-454d-b303-3a2bb40a7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose user_matrix as movie_matrix\n",
    "movie_matrix = user_matrix.T\n",
    "movie_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de545a0-ff5b-4be6-9560-ed0f978705b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算電影平均評分\n",
    "movie_mean = non_zero_mean(movie_matrix)\n",
    "# 使用個別電影平均校正電影對使用者的評分\n",
    "movie_adjust = np.where(movie_matrix == 0, movie_matrix, movie_matrix-movie_mean)\n",
    "print(f\"movie_matrix:\\n{movie_matrix} \\n\\nafter adjust:\\n{movie_adjust}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd0751-91f6-4865-a108-9244bd667c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得movie間的相似度名單\n",
    "cos_mdict, pcc_mdict = get_sim_dict(movie, movie_adjust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5af1ae-c013-4413-9a40-c0b9c859b255",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2.1.  Item‐Based CF use Cosine result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d0eca-2199-4f9b-a84b-aa4a56e48ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 與不同K個電影相似程度比較\n",
    "K = [3,4,5,6,7,8,9,10,20,30,40,50, 60,70,80,90,100]\n",
    "icf_cos = list()\n",
    "\n",
    "# 針對不同相似電影個數進行分析\n",
    "for k in K:\n",
    "    predict_matrix = np.zeros((len(movie), len(user)))\n",
    "    # 取出前K個相似度最大的使用者名稱，並設置於N\n",
    "    for i in tqdm(cos_mdict.keys(), desc=f\"predicting K = {k}\"):\n",
    "        # Siv: 取出前K個最相似的電影相似度 ex:K=3, output=[0.378, 0.353, 0.336]\n",
    "        Siv = heapq.nlargest(k,cos_mdict[i])\n",
    "        # top_sim_index: 取出前K個最相似的電影相似度(index) ex:K=3, output=[915, 406, 214]\n",
    "        top_sim_index = list(map(cos_mdict[i].index, heapq.nlargest(k,cos_mdict[i])))\n",
    "        # 利用相似的電影對電影的每一位使用者做評分預測\n",
    "        for u in range(len(user)):\n",
    "            # R: 相似電影對調整後使用者 u 的評分\n",
    "            R = [movie_adjust[:,u][j] for j in top_sim_index]\n",
    "            # 預測使用者u對於第m部電影的評分\n",
    "            Riu = predict(Siv, R)\n",
    "            predict_matrix[i, u] = Riu\n",
    "    icf_cos.append(mse(movie_adjust, predict_matrix, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdbde65-b744-4f73-82ad-5f0314b87f3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.2.2.  Item‐Based CF use Pearson Correlation Coefficient result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
